{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arxiv Title Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:27.155382Z",
     "iopub.status.busy": "2023-03-28T13:31:27.154562Z",
     "iopub.status.idle": "2023-03-28T13:31:36.948244Z",
     "shell.execute_reply": "2023-03-28T13:31:36.946538Z",
     "shell.execute_reply.started": "2023-03-28T13:31:27.155332Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install youtokentome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:36.962098Z",
     "iopub.status.busy": "2023-03-28T13:31:36.961156Z",
     "iopub.status.idle": "2023-03-28T13:31:48.745836Z",
     "shell.execute_reply": "2023-03-28T13:31:48.744777Z",
     "shell.execute_reply.started": "2023-03-28T13:31:36.962054Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import youtokentome as yttm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "\n",
    "import collections\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import heapq\n",
    "\n",
    "def init_random_seed(value=0):\n",
    "    random.seed(value)\n",
    "    np.random.seed(value)\n",
    "    torch.manual_seed(value)\n",
    "    torch.cuda.manual_seed(value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "init_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dev\\jupyter\\projects\\Data Science\\ds_stuff\\Different courses\\Нейронные сети и обработка текста\\venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asttokens==2.2.1\n",
      "backcall==0.2.0\n",
      "blis==0.7.9\n",
      "bokeh==3.0.3\n",
      "catalogue==2.0.8\n",
      "certifi==2022.12.7\n",
      "charset-normalizer==2.1.1\n",
      "click==8.1.3\n",
      "colorama==0.4.6\n",
      "comm==0.1.2\n",
      "confection==0.0.3\n",
      "contourpy==1.0.6\n",
      "cycler==0.11.0\n",
      "cymem==2.0.7\n",
      "Cython==0.29.32\n",
      "DAWG-Python==0.7.2\n",
      "debugpy==1.6.4\n",
      "decorator==5.1.1\n",
      "docopt==0.6.2\n",
      "entrypoints==0.4\n",
      "executing==1.2.0\n",
      "fonttools==4.38.0\n",
      "gensim==3.8.1\n",
      "idna==3.4\n",
      "intervaltree==3.1.0\n",
      "ipykernel==6.19.4\n",
      "ipymarkup==0.9.0\n",
      "ipython==8.7.0\n",
      "ipywidgets==8.0.3\n",
      "jedi==0.18.2\n",
      "Jinja2==3.1.2\n",
      "joblib==1.2.0\n",
      "jupyter_client==7.4.8\n",
      "jupyter_core==5.1.0\n",
      "jupyterlab-widgets==3.0.4\n",
      "kiwisolver==1.4.4\n",
      "langcodes==3.3.0\n",
      "livelossplot==0.5.3\n",
      "lxml==4.9.2\n",
      "MarkupSafe==2.1.1\n",
      "matplotlib==3.6.2\n",
      "matplotlib-inline==0.1.6\n",
      "murmurhash==1.0.9\n",
      "nest-asyncio==1.5.6\n",
      "nltk==3.8\n",
      "numpy==1.24.0\n",
      "packaging==22.0\n",
      "pandas==1.5.2\n",
      "parso==0.8.3\n",
      "pathy==0.10.1\n",
      "pickleshare==0.7.5\n",
      "Pillow==9.3.0\n",
      "pip==22.3.1\n",
      "platformdirs==2.6.0\n",
      "preshed==3.0.8\n",
      "prompt-toolkit==3.0.36\n",
      "psutil==5.9.4\n",
      "pure-eval==0.2.2\n",
      "pyconll==3.1.0\n",
      "pydantic==1.10.2\n",
      "Pygments==2.13.0\n",
      "pymorphy2==0.9.1\n",
      "pymorphy2-dicts-ru==2.4.417127.4579844\n",
      "pyparsing==3.0.9\n",
      "python-dateutil==2.8.2\n",
      "pytz==2022.7\n",
      "pywin32==305\n",
      "PyYAML==6.0\n",
      "pyzmq==24.0.1\n",
      "regex==2022.10.31\n",
      "requests==2.28.1\n",
      "scikit-learn==1.2.0\n",
      "scipy==1.9.3\n",
      "seaborn==0.12.1\n",
      "setuptools==65.6.3\n",
      "six==1.16.0\n",
      "smart-open==6.3.0\n",
      "sortedcontainers==2.4.0\n",
      "spacy==3.4.4\n",
      "spacy-legacy==3.0.10\n",
      "spacy-loggers==1.0.4\n",
      "spacy-udpipe==1.0.0\n",
      "srsly==2.4.5\n",
      "stack-data==0.6.2\n",
      "thinc==8.1.6\n",
      "threadpoolctl==3.1.0\n",
      "torch==1.13.1+cu117\n",
      "torchaudio==0.13.1+cu117\n",
      "torchtext==0.14.1\n",
      "torchvision==0.14.1+cu117\n",
      "tornado==6.2\n",
      "tqdm==4.64.1\n",
      "traitlets==5.8.0\n",
      "typer==0.7.0\n",
      "typing_extensions==4.4.0\n",
      "ufal.udpipe==1.2.0.3\n",
      "urllib3==1.26.13\n",
      "wasabi==0.10.1\n",
      "wcwidth==0.2.5\n",
      "wget==3.2\n",
      "widgetsnbextension==4.0.4\n",
      "xyzservices==2022.9.0\n",
      "youtokentome==1.0.6\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    from pip._internal.operations import freeze\n",
    "except ImportError: # pip < 10.0\n",
    "    from pip.operations import freeze\n",
    "\n",
    "pkgs = freeze.freeze()\n",
    "for pkg in pkgs:\n",
    "    print(pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:48.748265Z",
     "iopub.status.busy": "2023-03-28T13:31:48.747487Z",
     "iopub.status.idle": "2023-03-28T13:31:48.759404Z",
     "shell.execute_reply": "2023-03-28T13:31:48.758314Z",
     "shell.execute_reply.started": "2023-03-28T13:31:48.748225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:48.763012Z",
     "iopub.status.busy": "2023-03-28T13:31:48.762655Z",
     "iopub.status.idle": "2023-03-28T13:31:49.884474Z",
     "shell.execute_reply": "2023-03-28T13:31:49.883374Z",
     "shell.execute_reply.started": "2023-03-28T13:31:48.762970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we consider the problem of utility maximizatio...</td>\n",
       "      <td>on optimal investment with processes of long o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in this paper we provide an explicit formula f...</td>\n",
       "      <td>boolean complexes for ferrers graphs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kinesin-5, also known as eg5 in vertebrates is...</td>\n",
       "      <td>relative velocity of sliding of microtubules b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we discuss the transition paths in a coupled b...</td>\n",
       "      <td>bifurcation of transition paths induced by cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two types of room temperature detectors of ter...</td>\n",
       "      <td>all-electric detectors of the polarization sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  we consider the problem of utility maximizatio...   \n",
       "1  in this paper we provide an explicit formula f...   \n",
       "2  kinesin-5, also known as eg5 in vertebrates is...   \n",
       "3  we discuss the transition paths in a coupled b...   \n",
       "4  two types of room temperature detectors of ter...   \n",
       "\n",
       "                                               title  \n",
       "0  on optimal investment with processes of long o...  \n",
       "1               boolean complexes for ferrers graphs  \n",
       "2  relative velocity of sliding of microtubules b...  \n",
       "3  bifurcation of transition paths induced by cou...  \n",
       "4  all-electric detectors of the polarization sta...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f'{DATA_PATH}/train.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:49.887374Z",
     "iopub.status.busy": "2023-03-28T13:31:49.886448Z",
     "iopub.status.idle": "2023-03-28T13:31:49.984235Z",
     "shell.execute_reply": "2023-03-28T13:31:49.983233Z",
     "shell.execute_reply.started": "2023-03-28T13:31:49.887332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134827, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[~(data['abstract'].apply(len) <= data['title'].apply(len))].reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:49.986054Z",
     "iopub.status.busy": "2023-03-28T13:31:49.985533Z",
     "iopub.status.idle": "2023-03-28T13:31:50.303282Z",
     "shell.execute_reply": "2023-03-28T13:31:50.302233Z",
     "shell.execute_reply.started": "2023-03-28T13:31:49.986001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105463, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates().reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105402, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates('abstract').reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105331, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates('title').reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:50.305773Z",
     "iopub.status.busy": "2023-03-28T13:31:50.305376Z",
     "iopub.status.idle": "2023-03-28T13:31:50.501749Z",
     "shell.execute_reply": "2023-03-28T13:31:50.500776Z",
     "shell.execute_reply.started": "2023-03-28T13:31:50.305734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105209, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[~(data['abstract'].apply(lambda x: 'withdrawn' in x.lower()))].reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31660</th>\n",
       "      <td>we consider evaluating improper priors in a fo...</td>\n",
       "      <td>evaluating default priors with a generalizatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86648</th>\n",
       "      <td>we characterize the gorenstein nilpotent schem...</td>\n",
       "      <td>gorenstein multiple structures on smooth algeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50463</th>\n",
       "      <td>we show that the glauber dynamics on proper 9-...</td>\n",
       "      <td>sampling colourings of the triangular lattice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19251</th>\n",
       "      <td>we study the effect of disorder on the order p...</td>\n",
       "      <td>effect of disorder on a pomeranchuk instability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44100</th>\n",
       "      <td>we determine the z-module structure of the pre...</td>\n",
       "      <td>zeroth hochschild homology of preprojective al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "31660  we consider evaluating improper priors in a fo...   \n",
       "86648  we characterize the gorenstein nilpotent schem...   \n",
       "50463  we show that the glauber dynamics on proper 9-...   \n",
       "19251  we study the effect of disorder on the order p...   \n",
       "44100  we determine the z-module structure of the pre...   \n",
       "\n",
       "                                                   title  \n",
       "31660  evaluating default priors with a generalizatio...  \n",
       "86648  gorenstein multiple structures on smooth algeb...  \n",
       "50463      sampling colourings of the triangular lattice  \n",
       "19251    effect of disorder on a pomeranchuk instability  \n",
       "44100  zeroth hochschild homology of preprojective al...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105176, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[~(data['title'].apply(lambda x: len(x.split(' '))) == 1)].reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105170, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[~(data['abstract'].apply(lambda x: 'no abstract' in x))].reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "171\n",
      "505\n",
      "818\n",
      "1058\n",
      "1275\n",
      "1468\n",
      "1619\n",
      "1741\n",
      "2599\n",
      "2719\n",
      "2865\n",
      "3174\n",
      "3395\n",
      "3679\n",
      "3711\n",
      "4302\n",
      "4541\n",
      "4730\n",
      "5766\n",
      "5794\n",
      "5817\n",
      "5852\n",
      "6075\n",
      "6528\n",
      "6626\n",
      "6646\n",
      "6922\n",
      "6937\n",
      "7024\n",
      "7183\n",
      "7533\n",
      "7624\n",
      "8238\n",
      "8316\n",
      "8592\n",
      "8640\n",
      "8887\n",
      "9512\n",
      "9668\n",
      "9910\n",
      "10118\n",
      "10779\n",
      "11031\n",
      "11062\n",
      "11137\n",
      "11263\n",
      "11329\n",
      "11400\n",
      "11823\n",
      "11916\n",
      "11962\n",
      "12337\n",
      "12420\n",
      "12450\n",
      "13049\n",
      "13374\n",
      "13460\n",
      "13719\n",
      "13777\n",
      "13916\n",
      "13964\n",
      "14258\n",
      "15203\n",
      "15463\n",
      "15534\n",
      "15614\n",
      "16224\n",
      "16909\n",
      "16977\n",
      "17075\n",
      "17082\n",
      "17614\n",
      "17785\n",
      "17957\n",
      "18108\n",
      "18289\n",
      "19028\n",
      "19090\n",
      "19444\n",
      "20014\n",
      "20130\n",
      "20279\n",
      "20421\n",
      "20466\n",
      "20578\n",
      "20754\n",
      "20812\n",
      "20945\n",
      "21405\n",
      "22031\n",
      "22044\n",
      "22294\n",
      "22462\n",
      "22571\n",
      "22675\n",
      "22932\n",
      "23177\n",
      "23178\n",
      "23525\n",
      "23660\n",
      "23699\n",
      "23884\n",
      "24094\n",
      "24279\n",
      "24773\n",
      "24891\n",
      "24905\n",
      "24911\n",
      "24922\n",
      "25719\n",
      "25828\n",
      "26099\n",
      "26258\n",
      "26314\n",
      "26667\n",
      "26979\n",
      "27244\n",
      "27332\n",
      "27703\n",
      "27881\n",
      "28280\n",
      "28384\n",
      "28903\n",
      "28959\n",
      "29004\n",
      "29016\n",
      "29352\n",
      "29408\n",
      "29650\n",
      "29674\n",
      "30096\n",
      "30188\n",
      "30608\n",
      "30815\n",
      "30841\n",
      "31087\n",
      "31106\n",
      "31210\n",
      "31553\n",
      "31656\n",
      "31858\n",
      "32323\n",
      "32523\n",
      "32697\n",
      "33423\n",
      "33445\n",
      "33786\n",
      "33990\n",
      "34082\n",
      "34122\n",
      "34574\n",
      "34831\n",
      "34952\n",
      "35696\n",
      "35831\n",
      "35887\n",
      "36168\n",
      "36305\n",
      "36459\n",
      "36788\n",
      "37038\n",
      "37071\n",
      "37248\n",
      "37781\n",
      "38053\n",
      "38248\n",
      "38374\n",
      "38682\n",
      "38854\n",
      "38914\n",
      "39309\n",
      "39674\n",
      "40120\n",
      "40271\n",
      "40491\n",
      "40574\n",
      "40606\n",
      "40847\n",
      "40971\n",
      "41002\n",
      "41145\n",
      "41357\n",
      "41497\n",
      "41515\n",
      "41620\n",
      "41632\n",
      "41935\n",
      "41943\n",
      "42106\n",
      "42481\n",
      "42526\n",
      "42660\n",
      "42721\n",
      "43479\n",
      "43591\n",
      "43793\n",
      "44076\n",
      "44077\n",
      "44176\n",
      "44758\n",
      "44999\n",
      "45169\n",
      "45201\n",
      "45213\n",
      "45373\n",
      "45559\n",
      "45567\n",
      "45662\n",
      "45745\n",
      "45890\n",
      "45908\n",
      "46687\n",
      "46912\n",
      "47085\n",
      "47439\n",
      "47521\n",
      "47818\n",
      "48491\n",
      "48512\n",
      "48917\n",
      "48919\n",
      "48980\n",
      "49232\n",
      "49567\n",
      "49990\n",
      "50002\n",
      "50395\n",
      "50455\n",
      "50506\n",
      "50509\n",
      "50841\n",
      "50905\n",
      "50913\n",
      "51521\n",
      "51748\n",
      "51806\n",
      "52454\n",
      "52477\n",
      "52626\n",
      "52961\n",
      "53213\n",
      "53280\n",
      "53570\n",
      "53660\n",
      "53710\n",
      "53744\n",
      "53777\n",
      "53790\n",
      "53902\n",
      "54626\n",
      "54825\n",
      "54982\n",
      "54989\n",
      "55120\n",
      "55154\n",
      "55289\n",
      "55740\n",
      "55897\n",
      "55954\n",
      "56160\n",
      "56285\n",
      "56392\n",
      "56750\n",
      "56947\n",
      "57307\n",
      "57609\n",
      "57658\n",
      "58109\n",
      "58354\n",
      "59856\n",
      "59882\n",
      "59885\n",
      "59955\n",
      "59970\n",
      "59989\n",
      "60098\n",
      "60366\n",
      "60764\n",
      "61043\n",
      "61047\n",
      "61189\n",
      "61194\n",
      "61412\n",
      "61809\n",
      "61925\n",
      "62043\n",
      "62292\n",
      "62422\n",
      "62637\n",
      "62841\n",
      "62952\n",
      "62961\n",
      "63081\n",
      "63546\n",
      "63641\n",
      "63709\n",
      "63887\n",
      "64326\n",
      "65061\n",
      "65126\n",
      "65988\n",
      "66037\n",
      "66145\n",
      "66149\n",
      "66222\n",
      "66476\n",
      "66830\n",
      "67056\n",
      "67274\n",
      "67354\n",
      "67480\n",
      "67500\n",
      "67566\n",
      "68003\n",
      "68151\n",
      "68220\n",
      "68391\n",
      "68841\n",
      "69024\n",
      "69037\n",
      "69111\n",
      "69289\n",
      "69335\n",
      "69662\n",
      "69790\n",
      "69826\n",
      "69834\n",
      "69904\n",
      "70020\n",
      "70071\n",
      "70104\n",
      "70689\n",
      "70936\n",
      "70939\n",
      "71089\n",
      "71141\n",
      "71339\n",
      "71348\n",
      "71479\n",
      "71638\n",
      "71872\n",
      "71984\n",
      "72253\n",
      "73515\n",
      "74411\n",
      "74435\n",
      "74612\n",
      "74891\n",
      "75210\n",
      "75350\n",
      "75389\n",
      "75521\n",
      "75622\n",
      "75629\n",
      "75634\n",
      "75641\n",
      "75889\n",
      "76790\n",
      "76877\n",
      "77084\n",
      "77582\n",
      "77608\n",
      "77643\n",
      "77723\n",
      "78062\n",
      "78109\n",
      "78279\n",
      "78340\n",
      "78358\n",
      "78426\n",
      "78469\n",
      "78685\n",
      "79076\n",
      "79079\n",
      "79093\n",
      "79096\n",
      "79447\n",
      "79566\n",
      "79679\n",
      "79733\n",
      "79888\n",
      "79987\n",
      "80010\n",
      "80026\n",
      "80104\n",
      "80350\n",
      "81070\n",
      "81288\n",
      "81623\n",
      "82366\n",
      "82484\n",
      "82496\n",
      "82629\n",
      "82769\n",
      "82779\n",
      "82782\n",
      "82808\n",
      "82841\n",
      "83094\n",
      "83239\n",
      "83257\n",
      "83365\n",
      "83405\n",
      "83498\n",
      "83639\n",
      "83652\n",
      "83847\n",
      "84048\n",
      "84085\n",
      "84134\n",
      "84227\n",
      "84750\n",
      "85082\n",
      "85105\n",
      "85142\n",
      "85174\n",
      "85309\n",
      "85399\n",
      "85606\n",
      "85619\n",
      "85643\n",
      "85976\n",
      "86063\n",
      "86117\n",
      "86177\n",
      "86370\n",
      "86441\n",
      "86477\n",
      "86491\n",
      "86898\n",
      "86926\n",
      "87122\n",
      "87374\n",
      "87652\n",
      "87799\n",
      "88073\n",
      "88223\n",
      "88402\n",
      "88660\n",
      "88714\n",
      "88866\n",
      "89405\n",
      "89529\n",
      "89719\n",
      "89912\n",
      "90384\n",
      "91236\n",
      "91377\n",
      "91490\n",
      "91696\n",
      "91772\n",
      "93099\n",
      "93106\n",
      "93447\n",
      "93562\n",
      "93604\n",
      "93624\n",
      "93673\n",
      "93791\n",
      "93999\n",
      "94167\n",
      "94287\n",
      "94605\n",
      "94703\n",
      "95057\n",
      "95191\n",
      "95300\n",
      "95444\n",
      "95555\n",
      "95768\n",
      "96085\n",
      "96115\n",
      "96138\n",
      "96538\n",
      "96695\n",
      "97124\n",
      "97153\n",
      "97169\n",
      "97215\n",
      "97264\n",
      "97548\n",
      "97567\n",
      "97805\n",
      "97898\n",
      "98199\n",
      "98791\n",
      "98799\n",
      "98880\n",
      "99249\n",
      "99315\n",
      "99493\n",
      "99589\n",
      "99617\n",
      "99850\n",
      "100011\n",
      "100110\n",
      "100827\n",
      "101004\n",
      "101006\n",
      "101066\n",
      "101479\n",
      "101895\n",
      "102580\n",
      "102809\n",
      "102823\n",
      "102828\n",
      "102989\n",
      "102993\n",
      "103362\n",
      "103590\n",
      "103849\n",
      "103890\n",
      "103981\n",
      "103993\n",
      "104150\n",
      "104579\n",
      "104937\n",
      "105009\n",
      "105097\n",
      "CPU times: total: 3.03 s\n",
      "Wall time: 3.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "title_sets = data['title'].apply(lambda x: set(x.split(' ')))\n",
    "abstract_sets = data['abstract'].apply(lambda x: set(x.split(' ')))\n",
    "\n",
    "idxs = []\n",
    "for i, title_set in title_sets.items():\n",
    "    if i and len(title_set.intersection(abstract_sets[i])) == 0:\n",
    "        print(i)\n",
    "        idxs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'consider any dirichlet series sum a_n/n^z with nonnegative coefficients a_n and finite sum function f(z)=f(x+iy) when x is greater than 1. denoting the partial sum a_1+...+a_n by s_n, the paper gives the following necessary and sufficient condition in order that (s_n)/n remain bounded as n goes to infinity. for x tending to 1 from above, the quotient q(x+iy)=f(x+iy)/(x+iy) must converge to a pseudomeasure q(1+iy), the distributional fourier transform of a bounded function. the paper also gives an optimal estimate for (s_n)/n under the \"real condition\" that (1-x)f(x) remain bounded as x tends to 1 from above.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[79888].abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ikehara-type theorem involving boundedness'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[79888].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104650, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(idxs).reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:50.503999Z",
     "iopub.status.busy": "2023-03-28T13:31:50.503614Z",
     "iopub.status.idle": "2023-03-28T13:31:50.530393Z",
     "shell.execute_reply": "2023-03-28T13:31:50.529453Z",
     "shell.execute_reply.started": "2023-03-28T13:31:50.503959Z"
    }
   },
   "outputs": [],
   "source": [
    "init_random_seed(1234)\n",
    "\n",
    "val_ratio = 0.01\n",
    "test_ratio = 0.01\n",
    "\n",
    "val_idx = np.random.choice(a=len(data), size=int(len(data)*(val_ratio+test_ratio)), replace=False)\n",
    "\n",
    "train_data = data.drop(val_idx).copy()\n",
    "val_data = data.iloc[val_idx[:len(val_idx)//2]].copy()\n",
    "test_data = data.iloc[val_idx[len(val_idx)//2:]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:50.532443Z",
     "iopub.status.busy": "2023-03-28T13:31:50.532042Z",
     "iopub.status.idle": "2023-03-28T13:31:50.541681Z",
     "shell.execute_reply": "2023-03-28T13:31:50.540413Z",
     "shell.execute_reply.started": "2023-03-28T13:31:50.532396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73167, 15633, 74851, ..., 67085, 59049, 16476])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:50.546002Z",
     "iopub.status.busy": "2023-03-28T13:31:50.545575Z",
     "iopub.status.idle": "2023-03-28T13:31:50.593011Z",
     "shell.execute_reply": "2023-03-28T13:31:50.591939Z",
     "shell.execute_reply.started": "2023-03-28T13:31:50.545964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# check if there's no intersection among sets\n",
    "print(set(train_data.index).intersection(set(val_data.index)))\n",
    "print(set(train_data.index).intersection(set(test_data.index)))\n",
    "print(set(val_data.index).intersection(set(test_data.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:50.595329Z",
     "iopub.status.busy": "2023-03-28T13:31:50.594313Z",
     "iopub.status.idle": "2023-03-28T13:31:50.602327Z",
     "shell.execute_reply": "2023-03-28T13:31:50.601309Z",
     "shell.execute_reply.started": "2023-03-28T13:31:50.595270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('we consider the problem of utility maximization for investors with power utility functions. building on the earlier work larsen et al. (2016), we prove that the value of the problem is a frechet-differentiable function of the drift of the price process, provided that this drift lies in a suitable banach space.   we then study optimal investment problems with non-markovian driving processes. in such models there is no hope to get a formula for the achievable maximal utility. applying results of the first part of the paper we provide first order expansions for certain problems involving fractional brownian motion either in the drift or in the volatility. we also point out how asymptotic results can be derived for models with strong mean reversion.',\n",
       " 'on optimal investment with processes of long or negative memory')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.values[0][0], train_data.values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:57.019209Z",
     "iopub.status.busy": "2023-03-28T13:31:57.018259Z",
     "iopub.status.idle": "2023-03-28T13:31:57.026021Z",
     "shell.execute_reply": "2023-03-28T13:31:57.024881Z",
     "shell.execute_reply.started": "2023-03-28T13:31:57.019167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"we present a feature engineering pipeline for the construction of musical signal characteristics, to be used for the design of a supervised model for musical genre identification. the key idea is to extend the traditional two-step process of extraction and classification with additive stand-alone phases which are no longer organized in a waterfall scheme. the whole system is realized by traversing backtrack arrows and cycles between various stages. in order to give a compact and effective representation of the features, the standard early temporal integration is combined with other selection and extraction phases: on the one hand, the selection of the most meaningful characteristics based on information gain, and on the other hand, the inclusion of the nonlinear correlation between this subset of features, determined by an autoencoder. the results of the experiments conducted on gtzan dataset reveal a noticeable contribution of this methodology towards the model's performance in classification task.\",\n",
       "       'extended pipeline for content-based feature engineering in music genre   recognition'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:02.128555Z",
     "iopub.status.busy": "2023-03-28T13:32:02.127980Z",
     "iopub.status.idle": "2023-03-28T13:32:02.133635Z",
     "shell.execute_reply": "2023-03-28T13:32:02.132350Z",
     "shell.execute_reply.started": "2023-03-28T13:32:02.128517Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with open(f'{DATA_PATH}/data.txt', \"w\") as fout:\n",
    "#     for i, row in train_data.iterrows():\n",
    "#         print(row['abstract'] + '\\n' + row['title'], file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:16.299620Z",
     "iopub.status.busy": "2023-03-28T13:32:16.299034Z",
     "iopub.status.idle": "2023-03-28T13:32:16.306341Z",
     "shell.execute_reply": "2023-03-28T13:32:16.304730Z",
     "shell.execute_reply.started": "2023-03-28T13:32:16.299571Z"
    }
   },
   "outputs": [],
   "source": [
    "MODELS_PATH = './models'\n",
    "\n",
    "BPE_MODEL_FILENAME = f'{MODELS_PATH}/bpe.yttm'\n",
    "TRAIN_TEXTS_FILENAME = f'{DATA_PATH}/data.txt'\n",
    "\n",
    "yttm.BPE.train(data=TRAIN_TEXTS_FILENAME, vocab_size=2000, model=BPE_MODEL_FILENAME);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:17.288348Z",
     "iopub.status.busy": "2023-03-28T13:32:17.287447Z",
     "iopub.status.idle": "2023-03-28T13:32:17.295595Z",
     "shell.execute_reply": "2023-03-28T13:32:17.294228Z",
     "shell.execute_reply.started": "2023-03-28T13:32:17.288279Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = yttm.BPE(BPE_MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:20.084283Z",
     "iopub.status.busy": "2023-03-28T13:32:20.083567Z",
     "iopub.status.idle": "2023-03-28T13:32:20.092021Z",
     "shell.execute_reply": "2023-03-28T13:32:20.090774Z",
     "shell.execute_reply.started": "2023-03-28T13:32:20.084243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <UNK> <BOS> <EOS> ▁ e t i a o n s r l c h d m p u f g y b w v . , - k x $ q ) ( z \\ 0 1 2 j } { _ ' 3 : ^ 5 / 4 \" 9 6 = 8 7 + ; % [ ] ` > < | ~ * ? & ! # @  ▁t ▁a in on ▁th ti er ▁the ▁s re ▁o en ▁c al ▁p or es tion ▁of at is ▁f ▁m ▁in ▁w ▁d ed it ar an ro ▁an ing ▁b ic le ation ▁e ▁and et el ▁re as ▁to ▁n ent im om ul ct us ▁h od ▁l ▁pro ▁g ▁for ▁we un ▁is ▁st ▁con ra ce ly ch ve st si ur ol tic ith ▁on ow qu am ri ▁ex ▁that il ▁with ity ▁v res ut em s. ▁as ▁mod ction ▁com ▁al per ate um ▁wh ter ig os ab id ver ot pl ▁( if ▁be ▁model ▁are ▁sp ▁this ▁de ge ▁su ▁comp ▁r ▁by iz ect ▁dis ir ▁us ure ▁$ ical s, se ▁ap und tim ati ces orm ▁sh th ▁res di ▁ma ations ▁ne og ▁se ence ari ▁ch ution ts sion oc etw rom pro ff ▁par ▁co ated ork ment ain ▁met ich ▁it ▁im ble ant ener op ore form ▁from ▁cl fer ▁sy and ine du ▁dat ▁or ▁which ▁can ▁le ru ere igh ▁at ▁es ec rib ud act vel tical ran ▁meth ▁ob ▁me ▁method es. end ▁k te ple ell ric ▁inter ▁qu ▁data ance der ous ▁show ▁un ▁per ▁ac ay ach ▁resul ph enti able ac ad ▁appro pos ▁dist est ▁sim eter ap tive ▁anal iv ▁pre ion ▁gener ▁po ▁ad ign ▁estim ▁dif ▁cont ased unction stem ular ▁fin ies ary ▁analy ▁eff ally ▁system etwork ▁our ag sis ▁non resent ▁network ▁function ▁ev ass ▁vari ase ▁op ruct ▁int ▁pa ort ave all ▁tim up ▁tran ▁tw ▁ph ▁rec ms cess ▁reg ▁propos ility ▁using olution ▁sc ▁two ▁mo ator ting vi ▁these ens ▁num gor ribution de ▁inc olog oth ▁differ ▁rel ties ▁mul tain ber plic ates yn so ial ▁proble ound ▁und dition ess ong ▁cor ▁high ▁time ative ization ▁all ▁ass ▁ar vid ▁des ▁multi ▁under ▁results ension ▁mat ▁equ ome ace ▁no ▁distribution een ding ▁paper ▁approach ynam etween ulation ▁between ▁fi ▁also erv ▁tra alu ark ures yp gorith ▁algorith age ▁form ▁have enc ▁sam gh pend ew ▁trans ▁not -s ▁sign ▁ext ▁inv ▁em ▁$\\ ▁based ▁di xim ▁sub ▁exp ability ▁1 ▁such ▁struct ▁const ill con ther ite ory ree ▁param ▁gro dic ▁models ici ard ▁problem ak ▁disc are ▁acc ▁set ▁stud ▁process eld ▁ro ▁dynam ▁has imension ▁general ▁present ▁meas es, ced ▁study port ▁one ating serv ▁new ▁ra our inear ized ▁how ▁comple ▁lar ents ential -d pt ▁gra ust int ▁parameter ▁analysis ▁comput ▁ab ed. ▁optim rate ene ▁provid ning ▁number ▁over ▁perform ual -b ram ▁en ian atis ely ▁2 formation ▁more ▁observ ▁man ▁fl lect ▁\\ sider ▁its ▁algorithm ise ip ▁pl ▁consider ast ific ugh ack ik ib ▁exper ath ▁dec ▁out aus ist ▁partic ature ▁lear tiv ▁dynamic ▁when ▁different ▁det ▁their ▁proper ower ▁condition e. ▁where ▁spec ▁sm ▁char ▁loc ne ▁id ied ▁class ech etric ▁j gy ▁predic ep ▁proposed ▁field ▁both ▁experim ▁non- ural rel ▁ver ym ▁used rac ▁large ral fic ▁fe ▁mark ▁measure pon abl ▁bi fin ▁some ight ▁fir now ▁chan ▁use istic ▁bound ren andom ors par ail ). onst ▁well ▁obtain 's ▁rep ▁statis ▁effect iqu ▁order ron ational ▁structure ▁information ▁applic action velop icient ression ▁than ▁theory out ▁random ▁prob ize ers ive ros ency imensional ry ▁been old sition acter ject -m ▁der ▁am -c ▁develop ue ▁desc ▁comm ▁learning ▁complex lo ▁other ▁first -t tern chan ption ▁cur ie astic ose ▁ag ▁spect ▁scal ▁real ▁typ ▁space ▁valu ▁dem ▁sur over ▁methods ▁col och ological ish ▁y ▁giv ▁depend imit ▁group ▁ener ▁state ▁min ▁solution anti ▁cell ), ood av ov ▁case ▁ter rain ▁there nel ▁but ▁sing udi 00 ▁expl ▁limit assi -f ▁character ▁pop lud ia echn ▁theore ▁represent arch ile xt ation. ▁techn ▁signal ty ▁linear ▁work ▁approxim ology ▁fram ▁into ▁exam -l ▁i ▁networks ys ▁result ▁only ▁er ax ▁performance nown ▁simul of ress ▁graph her ▁do ▁intro ▁propose ▁each ▁introdu }$ ▁test ▁up ▁fact tig eterm ▁mean ▁rate ▁super ▁sequ ▁experiment ▁energy ▁beh ub uster ments ically ▁pos ▁power ▁recent _{ olv ective rough rol ▁properties avi rin ▁produ ▁determ ensity ▁estimation ▁local ▁inde ▁demonst ▁particular ▁identi ire ▁cal ▁str ▁allow ection ▁asym ▁ran ▁studi vari ference ▁cluster oci ▁then ▁optimal teg ▁correl ▁stoch ensi ock ▁low vely ▁quanti sist ▁given ma ▁stochastic lec ework ▁small ▁framework ges ▁mon ▁3 ▁incre ▁through ▁if estig ▁elect ▁find ▁may ▁behavi ▁investig ▁includ ▁he ▁sch ▁dynamics ▁systems ▁minim rect ▁app ▁assum ▁interaction oun ▁sampl tivity ▁describ tically ism ▁control por ten put ide ▁integ ▁discus ▁z ▁mag ality 0. ▁lat antum ever ▁provide ▁redu ▁import ected ▁many lection ▁however rix )$ -based sible ▁mechan ▁estimator geb ▁quantum ▁ge ▁conc rop ▁maxim ▁oper ences -dimensional ▁evolution ▁single ▁numer bin ▁compare ▁impro ▁cap otic ▁here ▁market ▁most ▁car ▁aut ier fy fication ▁lik low ▁err vers ▁techniqu ertain ▁finite ▁fre ▁inf ▁matrix ^{ ▁sever ▁hy ness ▁design ▁pot ▁tem gin ▁classi isk ▁point ven ▁u ▁pric ▁discuss ted ▁flu ▁requ ▁associ atures ▁however, ▁while til atic ision uc uld ▁prote ▁x ▁star ▁density ▁bl sp ▁statistical inu ▁level ations. ▁signific ayes ▁simple ▁fur ▁was usion ds ▁three ful ▁asympt ▁deriv cal ci ▁multiple ▁- pendent ▁any ▁sym ▁further ▁conver ▁\" ation, ▁probability -p ▁long ▁phase ross ▁risk ▁paper, ▁bayes ing. ▁lead ▁population eng ases ▁several ▁simulation etry ities ear bit ▁imag ▁mi ▁ser iti ▁syn ▁spati ang ▁mic ▁gene ▁strong respon ▁protein ▁dom the ▁combin ▁they na ▁algeb e, ▁parameters ▁calc ▁conf ▁obtained les ▁poly ▁vol ctor ▁gen ▁observed ▁determin ▁pat sian ▁shown ▁neural rent ▁ve ▁significant ▁efficient cond ▁noise ▁continu ▁terms ▁radi ▁sup ▁potential ▁indi ▁mass tions ▁correspon erm ▁compar anc get ▁error ▁norm ▁spe ▁stand linear ▁av ward ▁sour ▁frequ ▁region ▁functions tur aces ▁regression -w ▁second ing, ▁important ▁ent ▁compon ▁found aw ▁so ▁map ▁addition ▁due ilar eli ▁demonstrate ▁numerical -in ves sc vious ▁defin ▁within ost gence fficient ▁bayesian ogene -st ▁ach ▁bas ▁rob ord aussian its ▁behavior $. iter ▁very ▁bec ▁rem ▁adap ▁prove ▁main ▁spar upl ics ▁tre ▁strate ▁achie ▁known netic ▁extend ▁selection ▁sample ▁inst ▁top ▁gal ▁analyz ▁consist als ▁sug ▁grow ▁ori ▁standard ▁previous ▁appl ▁pri ▁features ▁evalu ▁cent ▁transition abil ▁bin ▁respon ission $, ▁interest ▁dimension ▁possible ▁mak ▁fol ▁train ons {\\ ▁phys ▁cod ▁deg ▁individ ▁pattern ask ▁geom ▁asymptotic ▁resp au ved ables ration ▁same ▁pres ▁effects ult ▁imp ract ▁sem rim ▁commun iss ▁novel ▁ill ane ull lying elf ▁similar ▁construct xed ▁size hood ▁via ▁inference ▁individual ▁schem ▁channel ruction ▁data. raction ▁robust verse ▁pol ▁about ▁factor ▁fil ly, ▁att ▁formul ▁algorithms iod oint ▁conditions ▁symm cc ▁associated ▁deep uring ▁direct ▁experimental ▁tak ▁will ▁were ▁coupl ▁equation ▁molec ays ▁detection ed, ▁gaussian ains ▁exis ▁path ▁lin ole math ▁states ▁el ▁calcul ▁proced ally, rated ▁coe led ▁processes omic ances ▁diff cop gest ▁compared o- ray ▁bet ▁surf ▁parti ▁spatial ▁applied verage plement ▁application ▁spin pir ▁type aset -1 rum ▁current cept ▁sol ▁discre ▁dataset iron ribut vant ▁require ▁underst round idence ▁theoretical ▁distributions ▁regular ▁nat ▁mem ▁cr lu ▁give rection ▁(m lob ▁range uman ▁operator ▁allows ▁statistic ▁exist ▁functional ount ▁expon orph ▁even elihood ▁vi ▁value ▁empir ▁log ▁lo ▁image ough ▁gam plicit ▁coun ily ▁indic ns onal ▁various ton ition ▁computational ablish row viron ▁including ▁est ▁temper izing ▁period ▁estimate ▁ri ▁continuous ▁implement ▁derive ▁avail ▁glob pre ▁ke ▁optimization ival ▁illust ike omial ▁algebra ▁task ▁prin ength one -g ▁investigate ▁pair ▁common ▁cy ▁series urac ▁(s ice ▁equations ▁covari ▁problems ▁follow ▁unc ▁environ ▁establish ▁nonlinear ified itud equ art ritical ▁conn ity. ▁galax ▁assumption ▁fam man ▁certain ▁introduce ▁applications -v 01 ▁caus ▁without ▁dri ▁accurac ▁model. ior ▁independent ▁provides hib ucle ▁classical ▁detect ▁human ▁cost ▁origin ▁corresponding ger ▁wave ▁classification ▁4 ▁related ▁sequence ▁relations ▁prediction ▁(2 text ▁initi ping ▁thus ▁clos ield ▁flow ▁improve ▁phen s) ▁occ gan ▁prog -h ▁solutions ▁aff ctu ▁maximum ▁vector ▁def ▁accuracy ▁ele ▁call ould ▁sens ▁generalized ▁four ifold ement ▁likelihood ▁higher ▁0. ▁tri ▁end raph tice ooth -de ▁simulations ▁[ ▁correlation ▁suggest tively red cl ▁sparse ▁magnetic ▁post ▁chall reg esis ▁frequency ▁mom ▁brain ▁those ▁fit param ples time -n ▁q to ▁explicit ▁spectral ▁tool ero ▁back ▁empirical ▁available ▁understand ▁constrain ▁convergence ▁specific ▁separ ▁transm ▁expression ▁studies ies. ocus ▁rati ising ▁among ▁(i vex ▁prec ▁self omp arget osition ▁growth ▁exact ▁ep ▁structures ▁existing ▁los ▁experiments king ▁prac eta search ogn ▁short irc fore ▁hom ▁sum ▁5 ▁med ▁research ▁way ▁vis pha ▁particular, ging ▁prior ▁markov ▁constant ▁critical ▁weak ▁environment alid ised ▁values ▁lower known ule ind ▁modeling ▁rates ▁consistent ▁neur ▁posi ▁setting ▁near ▁effective ▁ker ▁biological sequ gment ▁add ▁math rid ▁model, ately ▁mut ilib ras ▁need ▁focus not ▁approximation ▁altern ld ▁characteristic ▁normal order ▁target ▁coll uch ▁hyper ▁$n ▁during ▁input ▁nucle plo ▁measures ilibri ▁cross ancial ules ▁mach ▁(c ▁smooth ▁often ▁component ▁financial asing ▁global ▁reconst ling aneous ▁metric ▁variable ▁bo ▁discrete ▁electron ▁sampling ▁context hip ▁af -sp ▁example ▁= ▁mechanism ▁infin ▁uni ▁describe ription ▁probabil ▁identify ▁procedure ▁phot ▁econ ▁theorem ▁kernel ^2 ▁bu ks ▁cons ▁hyp ▁law ▁differential ▁them ▁natural ▁ide ropy ▁invari ▁developed -of ▁source ▁term ▁util ▁fluctu ental tal ▁gre .e. ▁models. ▁dimensional ▁temperature ▁better ta ▁response ▁domain ▁mathem ▁rest ▁variables ▁interpre -e roscop nomial ▁filter ible ▁role ▁average ▁accur ▁computation ▁nod ▁autom ▁plan ▁neut ▁step ▁cho ▁does ▁arbit ▁approaches ▁micro ▁rele ▁part ity, olving ▁price ▁underlying ving ▁interactions ▁observations ▁abs ▁good ▁surface ▁ear ▁hypoth val ght ▁exc ner ▁scale -the ▁presence ▁polynomial ▁dependence set ense ▁mar atory ▁squ ▁length ▁object ▁positive ▁distance ▁bel ▁fund ▁finally, resh ▁support ▁representation ▁spectrum ▁sit ▁transform ▁osc onic ▁valid bed ▁light ▁loss ▁sin ▁dynamical ▁free jective ▁estimates ft ▁oscill sive cale ▁circ ▁derived ▁change ead ▁stock ▁diag ▁diffusion ayer ▁occur ▁comparis ern duct ▁communic ▁predict ▁sl ▁fixed ▁measurement ching iciency ▁ed ▁monte ▁fore atively ▁detail ▁feature ilibrium ▁weight da ▁ratio ▁quas ogeneous ▁techniques gies oid atil ▁sw ▁key tional view ▁et ticle ants ▁uncertain yl ▁finding ▁initial tation omen ▁existence ▁dise taneous -con ▁band ond ▁influ ▁impact ▁enc bility ▁poin ither ▁defined alpha ings ok ▁recover ▁equival ▁indu ▁apply ▁fraction atter ▁central ▁prim ▁motion ▁therm ▁after ▁address su ▁bounds ▁spaces poral rem ploy ▁molecular ype cing ▁introduced volution fied ▁matric ▁gu sig rary ▁sets _1 ▁product izes ▁strategy ▁fast ▁could ▁training ▁wid ▁mathema tit ▁moreover -ray ▁reve ▁moment ▁proces ▁volatil ▁scen ▁stability ▁prof ▁carlo ▁200 ▁respect ▁recently ▁manifold ▁adaptive -time ▁sufficient ▁suc ▁exhib ▁search ▁special ps ape ▁convex ▁eig ▁te ▁phenomen ▁heter isms ▁chain ▁groups ob ▁changes ▁regim ▁much ▁examples ▁princi ▁sensi ▁tur ensive ▁species com ributed ▁analyze (\\ ▁know ▁report ▁treat ▁lab ▁activity ▁least ▁thresh ▁cas ▁relationship ater ectively read ▁zero ▁go ▁cos ▁ques ▁complexity ▁expected ▁data, ▁resulting ▁efficiency ▁emer ▁fundam ▁across nection ▁ens ▁pertur ▁studied ▁joint ▁dna ▁boundary parametric ▁physical ▁account orld ▁cells ▁scenari ▁buil ▁extension ▁relative ▁view ▁neg -le ▁magn ▁shows ▁machine ▁eigen y. ▁fields ▁action ▁hand ▁del ▁since ▁liter ▁(1 ▁10 ▁direction ▁times ates. ▁enh ▁entropy ▁scheme emical ▁explo iform ▁measurements ▁prop ▁moreover, ▁leads ▁clustering ▁estimators ▁arch ▁line ▁patterns ▁whose ▁organ ▁significantly ▁index ▁unit amb ▁version ▁explain ▁literature ▁mixt more ▁statistics ograph ▁satis ▁optical ▁extrem ▁reaction ▁along ▁considered ▁variance line ▁total ▁called ▁degree variate ▁criter \\' ▁mathematical g. ▁genetic ▁generated ▁black entially ▁comparison ▁necess ▁emission ▁assess i) alth ▁furthermore ▁technique ▁pe oper ▁aim ▁grav ually ▁speech ativ ably ▁evidence ▁increasing ▁open ▁(p ▁few ▁points _n ▁decision ▁family ages ture ▁binary ▁best ▁formation ▁fundamental ▁` ause ▁determine olved ▁ir _2 ▁being ▁sources ▁let ▁recogn ▁particle ▁ref ationary\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(tokenizer.vocab()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:23.449168Z",
     "iopub.status.busy": "2023-03-28T13:32:23.448238Z",
     "iopub.status.idle": "2023-03-28T13:32:23.457411Z",
     "shell.execute_reply": "2023-03-28T13:32:23.455977Z",
     "shell.execute_reply.started": "2023-03-28T13:32:23.449129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1108, 100, 88, 537, 114, 249, 130, 315, 119, 873, 1725, 521, 21, 249, 80, 106, 97, 96, 124, 108, 1017, 83, 1996, 1301]\n"
     ]
    }
   ],
   "source": [
    "encoded_sample = tokenizer.encode(test_data['title'].values[0])\n",
    "print(encoded_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:24.168741Z",
     "iopub.status.busy": "2023-03-28T13:32:24.168396Z",
     "iopub.status.idle": "2023-03-28T13:32:24.413786Z",
     "shell.execute_reply": "2023-03-28T13:32:24.412466Z",
     "shell.execute_reply.started": "2023-03-28T13:32:24.168709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extended pipeline for content-based feature engineering in music genre recognition']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.decode(encoded_sample))\n",
    "del encoded_sample\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.subword_to_id('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:27.185480Z",
     "iopub.status.busy": "2023-03-28T13:32:27.184987Z",
     "iopub.status.idle": "2023-03-28T13:32:27.356631Z",
     "shell.execute_reply": "2023-03-28T13:32:27.355680Z",
     "shell.execute_reply.started": "2023-03-28T13:32:27.185429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество случаев с неизвестными n-граммами символов в валидационной выборке 0\n"
     ]
    }
   ],
   "source": [
    "val_token_abstract = tokenizer.encode(val_data['abstract'].values.tolist(), bos=True, eos=True)\n",
    "\n",
    "unknown_subwords_in_test = sum(1 for text in val_token_abstract for token_id in text if token_id == 1)\n",
    "print('Количество случаев с неизвестными n-граммами символов в валидационной выборке',\n",
    "      unknown_subwords_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:28.746841Z",
     "iopub.status.busy": "2023-03-28T13:32:28.746419Z",
     "iopub.status.idle": "2023-03-28T13:32:28.856246Z",
     "shell.execute_reply": "2023-03-28T13:32:28.854790Z",
     "shell.execute_reply.started": "2023-03-28T13:32:28.746804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество случаев с неизвестными n-граммами символов в тестовой выборке 0\n"
     ]
    }
   ],
   "source": [
    "test_token_abstract = tokenizer.encode(test_data['abstract'].values.tolist(), bos=True, eos=True)\n",
    "\n",
    "unknown_subwords_in_test = sum(1 for text in test_token_abstract for token_id in text if token_id == 1)\n",
    "print('Количество случаев с неизвестными n-граммами символов в тестовой выборке',\n",
    "      unknown_subwords_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:29.933663Z",
     "iopub.status.busy": "2023-03-28T13:32:29.932910Z",
     "iopub.status.idle": "2023-03-28T13:32:29.939647Z",
     "shell.execute_reply": "2023-03-28T13:32:29.937370Z",
     "shell.execute_reply.started": "2023-03-28T13:32:29.933623Z"
    }
   },
   "outputs": [],
   "source": [
    "# spacy_en = spacy.load('en_core_web_sm')\n",
    "# def tokenize_spacy(text):\n",
    "#     \"\"\"\n",
    "#     Tokenizes English text from a string into a list of strings (tokens)\n",
    "#     \"\"\"\n",
    "#     return [tok.text for tok in spacy_en.tokenizer(text) if not tok.text.isspace()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:31.369612Z",
     "iopub.status.busy": "2023-03-28T13:32:31.368925Z",
     "iopub.status.idle": "2023-03-28T13:32:31.376129Z",
     "shell.execute_reply": "2023-03-28T13:32:31.374928Z",
     "shell.execute_reply.started": "2023-03-28T13:32:31.369572Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_vocabulary(\n",
    "#     tokenized_texts,\n",
    "#     max_size=1000000,\n",
    "#     max_doc_freq=0.8,\n",
    "#     min_count=5,\n",
    "#     pad_word=None,\n",
    "#     unk_word=None,\n",
    "#     sos_word=None,\n",
    "#     eos_word=None\n",
    "# ):\n",
    "#     word_counts = collections.defaultdict(int)\n",
    "#     doc_n = 0\n",
    "\n",
    "#     # посчитать количество документов, в которых употребляется каждое слово\n",
    "#     # а также общее количество документов\n",
    "#     for txt in tokenized_texts:\n",
    "#         doc_n += 1\n",
    "#         unique_text_tokens = set(txt)\n",
    "#         for token in unique_text_tokens:\n",
    "#             word_counts[token] += 1\n",
    "\n",
    "#     # убрать слишком редкие и слишком частые слова\n",
    "#     word_counts = {word: cnt for word, cnt in word_counts.items()\n",
    "#                    if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n",
    "\n",
    "#     # отсортировать слова по убыванию частоты\n",
    "#     sorted_word_counts = sorted(word_counts.items(),\n",
    "#                                 reverse=True,\n",
    "#                                 key=lambda pair: pair[1])\n",
    "#     if unk_word is not None:\n",
    "#         sorted_word_counts = [(unk_word, 0)] + sorted_word_counts\n",
    "    \n",
    "#     # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n",
    "#     if pad_word is not None:\n",
    "#         sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n",
    "        \n",
    "#     if sos_word is not None:\n",
    "#         sorted_word_counts = [(sos_word, 0)] + sorted_word_counts\n",
    "        \n",
    "#     if eos_word is not None:\n",
    "#         sorted_word_counts = [(eos_word, 0)] + sorted_word_counts\n",
    "\n",
    "#     # если у нас по прежнему слишком много слов, оставить только max_size самых частотных\n",
    "#     if len(word_counts) > max_size:\n",
    "#         sorted_word_counts = sorted_word_counts[:max_size]\n",
    "\n",
    "#     # нумеруем слова\n",
    "#     word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
    "\n",
    "#     # нормируем частоты слов\n",
    "#     word2freq = np.array([cnt / doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
    "\n",
    "#     return word2id, word2freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:31.957026Z",
     "iopub.status.busy": "2023-03-28T13:32:31.956445Z",
     "iopub.status.idle": "2023-03-28T13:32:31.961488Z",
     "shell.execute_reply": "2023-03-28T13:32:31.960383Z",
     "shell.execute_reply.started": "2023-03-28T13:32:31.956993Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# train_tokenized = [\n",
    "#     tokenize(sentence) for sentence in (train_data['abstract'] + ' ' + train_data['title'])\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:32.141935Z",
     "iopub.status.busy": "2023-03-28T13:32:32.141163Z",
     "iopub.status.idle": "2023-03-28T13:32:32.147199Z",
     "shell.execute_reply": "2023-03-28T13:32:32.145692Z",
     "shell.execute_reply.started": "2023-03-28T13:32:32.141888Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# vocabulary, _ = build_vocabulary(\n",
    "#     train_tokenized,\n",
    "#     max_doc_freq=1,\n",
    "#     min_count=3,\n",
    "#     pad_word='<PAD>',\n",
    "#     unk_word='<UNK>',\n",
    "#     sos_word='<SOS>',\n",
    "#     eos_word='<EOS>'\n",
    "# )\n",
    "\n",
    "# print(len(vocabulary))\n",
    "# del train_tokenized, data\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting texts by their length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:32.503268Z",
     "iopub.status.busy": "2023-03-28T13:32:32.502982Z",
     "iopub.status.idle": "2023-03-28T13:32:32.508675Z",
     "shell.execute_reply": "2023-03-28T13:32:32.507461Z",
     "shell.execute_reply.started": "2023-03-28T13:32:32.503240Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data['len_abstract'] = train_data['abstract'].apply(len)\n",
    "# train_data['len_title'] = train_data['title'].apply(len)\n",
    "# train_data = train_data.sort_values(['len_abstract', 'len_title'], ascending=False)\n",
    "\n",
    "# val_data['len_abstract'] = val_data['abstract'].apply(len)\n",
    "# val_data['len_title'] = val_data['title'].apply(len)\n",
    "# val_data = val_data.sort_values(['len_abstract', 'len_title'], ascending=False)\n",
    "\n",
    "# test_data['len_abstract'] = test_data['abstract'].apply(len)\n",
    "# test_data['len_title'] = test_data['title'].apply(len)\n",
    "# test_data = test_data.sort_values(['len_abstract', 'len_title'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:32.668345Z",
     "iopub.status.busy": "2023-03-28T13:32:32.668051Z",
     "iopub.status.idle": "2023-03-28T13:32:44.162392Z",
     "shell.execute_reply": "2023-03-28T13:32:44.161263Z",
     "shell.execute_reply.started": "2023-03-28T13:32:32.668313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 29.6 s\n",
      "Wall time: 4.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data['len_abstract'] = list(map(len, tokenizer.encode(train_data['abstract'].values.tolist())))\n",
    "train_data['len_title'] = list(map(len, tokenizer.encode(train_data['title'].values.tolist())))\n",
    "train_data = train_data.sort_values(['len_abstract', 'len_title'], ascending=False)\n",
    "\n",
    "val_data['len_abstract'] = list(map(len, tokenizer.encode(val_data['abstract'].values.tolist())))\n",
    "val_data['len_title'] = list(map(len, tokenizer.encode(val_data['title'].values.tolist())))\n",
    "val_data = val_data.sort_values(['len_abstract', 'len_title'], ascending=False)\n",
    "\n",
    "test_data['len_abstract'] = list(map(len, tokenizer.encode(test_data['abstract'].values.tolist())))\n",
    "test_data['len_title'] = list(map(len, tokenizer.encode(test_data['title'].values.tolist())))\n",
    "test_data = test_data.sort_values(['len_abstract', 'len_title'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:44.165183Z",
     "iopub.status.busy": "2023-03-28T13:32:44.164531Z",
     "iopub.status.idle": "2023-03-28T13:32:44.173930Z",
     "shell.execute_reply": "2023-03-28T13:32:44.172718Z",
     "shell.execute_reply.started": "2023-03-28T13:32:44.165140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1380, 124)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['len_abstract'].max(), train_data['len_title'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['len_abstract'].min(), train_data['len_title'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:44.176238Z",
     "iopub.status.busy": "2023-03-28T13:32:44.175565Z",
     "iopub.status.idle": "2023-03-28T13:32:44.182452Z",
     "shell.execute_reply": "2023-03-28T13:32:44.181078Z",
     "shell.execute_reply.started": "2023-03-28T13:32:44.176191Z"
    }
   },
   "outputs": [],
   "source": [
    "# class ArxivDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self,\n",
    "#                  src,\n",
    "#                  trg,\n",
    "#                  tokenizer,\n",
    "#                  vocabulary,\n",
    "#                  unk_word='<UNK>',\n",
    "#                  pad_word='<PAD>',\n",
    "#                  sos_word='<SOS>',\n",
    "#                  eos_word='<EOS>'\n",
    "#                 ):\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.word2id = vocabulary\n",
    "#         self.unk_word = unk_word\n",
    "#         self.pad_word = pad_word\n",
    "#         self.sos_word = sos_word\n",
    "#         self.eos_word = eos_word\n",
    "        \n",
    "#         # сразу токенизируем слова\n",
    "#         self.src = [self.tokenizer(sentence) for sentence in src]\n",
    "#         self.trg = [self.tokenizer(sentence) for sentence in trg]\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.src)\n",
    "    \n",
    "#     def __getitem__(self, i):\n",
    "#         # добавляем токены начала и конца предложения\n",
    "#         src_i = [self.sos_word] + self.src[i] + [self.eos_word]\n",
    "#         trg_i = [self.sos_word] + self.trg[i] + [self.eos_word]\n",
    "        \n",
    "#         # переводим токены в их номера из словаря, при этом незнакомые токены переводим в неизвестный токен\n",
    "#         src_num = [self.word2id.get(word, self.word2id[self.unk_word]) for word in src_i]\n",
    "#         trg_num = [self.word2id.get(word, self.word2id[self.unk_word]) for word in trg_i]\n",
    "        \n",
    "#         return src_num, trg_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:44.186819Z",
     "iopub.status.busy": "2023-03-28T13:32:44.185739Z",
     "iopub.status.idle": "2023-03-28T13:32:44.197597Z",
     "shell.execute_reply": "2023-03-28T13:32:44.196449Z",
     "shell.execute_reply.started": "2023-03-28T13:32:44.186779Z"
    }
   },
   "outputs": [],
   "source": [
    "class ArxivDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 src,\n",
    "                 trg,\n",
    "                 tokenizer,\n",
    "                 unk_word='<UNK>',\n",
    "                 pad_word='<PAD>',\n",
    "                 sos_word='<BOS>',\n",
    "                 eos_word='<EOS>'\n",
    "                ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.unk_word = unk_word\n",
    "        self.pad_word = pad_word\n",
    "        self.sos_word = sos_word\n",
    "        self.eos_word = eos_word\n",
    "        \n",
    "        # сразу кодируем слова\n",
    "        self.src = self.tokenizer.encode(src)\n",
    "        self.trg = self.tokenizer.encode(trg)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # добавляем токены начала и конца предложения\n",
    "        src_i = [self.tokenizer.subword_to_id(self.sos_word)] + self.src[i]\\\n",
    "        + [self.tokenizer.subword_to_id(self.eos_word)]\n",
    "        trg_i = [self.tokenizer.subword_to_id(self.sos_word)] + self.trg[i]\\\n",
    "        + [self.tokenizer.subword_to_id(self.eos_word)]\n",
    "        \n",
    "        return src_i, trg_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:44.200088Z",
     "iopub.status.busy": "2023-03-28T13:32:44.199233Z",
     "iopub.status.idle": "2023-03-28T13:32:55.601125Z",
     "shell.execute_reply": "2023-03-28T13:32:55.600002Z",
     "shell.execute_reply.started": "2023-03-28T13:32:44.200049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25.8 s\n",
      "Wall time: 4.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "arx_dataset_train = ArxivDataset(\n",
    "    train_data['abstract'].values.tolist(),\n",
    "    train_data['title'].values.tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "arx_dataset_val = ArxivDataset(\n",
    "    val_data['abstract'].values.tolist(),\n",
    "    val_data['title'].values.tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "arx_dataset_test = ArxivDataset(\n",
    "    test_data['abstract'].values.tolist(),\n",
    "    test_data['title'].values.tolist(),\n",
    "    tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:55.603709Z",
     "iopub.status.busy": "2023-03-28T13:32:55.602885Z",
     "iopub.status.idle": "2023-03-28T13:32:55.609962Z",
     "shell.execute_reply": "2023-03-28T13:32:55.608855Z",
     "shell.execute_reply.started": "2023-03-28T13:32:55.603662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([2, 763, 9, 30, 854, 865, 123, 338, 1337, 89, 33, 133, 105, 594, 1001, 153, 86, 93, 87, 22, 35, 90, 81, 865, 164, 92, 763, 9, 30, 854, 117, 1269, 125, 34, 39, 33, 9, 34, 39, 614, 774, 1189, 81, 1532, 110, 92, 81, 129, 1268, 50, 56, 115, 142, 250, 5, 733, 166, 103, 249, 179, 5, 50, 56, 8, 33, 97, 81, 288, 304, 82, 458, 92, 82, 89, 244, 400, 122, 20, 9, 102, 14, 122, 124, 107, 8, 102, 142, 7, 478, 795, 100, 81, 134, 1128, 395, 92, 105, 4, 1255, 28, 167, 9, 30, 9, 1844, 557, 280, 108, 29, 138, 115, 264, 100, 155, 125, 34, 39, 33, 9, 34, 39, 33, 1427, 1218, 1140, 44, 5, 41, 1740, 166, 26, 1387, 709, 39, 33, 576, 26, 652, 26, 219, 160, 26, 82, 223, 26, 451, 39, 50, 27, 1382, 52, 53, 53, 28, 50, 52, 53, 56, 61, 26, 117, 967, 1331, 185, 584, 15, 160, 5, 287, 9, 30, 1234, 1255, 1844, 27, 131, 431, 897, 151, 100, 549, 75, 96, 1140, 51, 9, 41, 11, 11, 23, 1150, 80, 485, 92, 81, 179, 48, 56, 33, 20, 5, 28, 85, 12, 235, 100, 111, 50, 56, 8, 82, 89, 244, 99, 26, 107, 8, 102, 142, 7, 115, 264, 100, 280, 108, 29, 138, 155, 125, 34, 39, 33, 9, 34, 39, 614, 539, 106, 81, 96, 1140, 51, 9, 41, 11, 11, 23, 1150, 80, 1867, 131, 880, 716, 1008, 97, 135, 40, 317, 155, 81, 661, 672, 1627, 108, 281, 1456, 112, 155, 81, 403, 92, 942, 1279, 1221, 213, 147, 1383, 182, 200, 153, 185, 1844, 1038, 955, 117, 75, 392, 1578, 76, 82, 854, 28, 77, 287, 9, 30, 9, 713, 5, 34, 45, 57, 33, 659, 26, 185, 133, 487, 92, 81, 662, 1839, 92, 452, 75, 1844, 97, 75, 1524, 326, 130, 253, 96, 1140, 51, 9, 41, 11, 11, 23, 1150, 80, 1009, 183, 118, 148, 1456, 46, 1900, 1619, 34, 49, 20, 5, 33, 1580, 1419, 48, 50, 1903, 33, 96, 17, 49, 200, 1900, 1619, 5, 34, 32, 33, 1580, 963, 860, 55, 37, 179, 48, 33, 96, 17, 49, 200, 112, 81, 797, 17, 986, 505, 111, 1619, 1580, 1419, 53, 37, 179, 48, 33, 96, 17, 49, 161, 81, 96, 1140, 51, 9, 41, 11, 11, 23, 1150, 80, 112, 1244, 125, 150, 154, 1300, 522, 1009, 431, 645, 1125, 230, 147, 75, 182, 244, 81, 82, 854, 28, 77, 287, 9, 30, 9, 659, 1271, 126, 114, 525, 33, 133, 1777, 100, 244, 81, 84, 30, 175, 494, 4, 1255, 1126, 80, 97, 82, 89, 244, 88, 22, 104, 14, 223, 14, 124, 952, 7, 173, 124, 27, 130, 253, 453, 585, 281, 183, 1456, 97, 81, 1931, 1427, 22, 5, 15, 1740, 166, 26, 1387, 709, 37, 33, 599, 683, 160, 551, 644, 824, 52, 27, 525, 50, 52, 52, 28, 39, 48, 37, 55, 61, 26, 130, 1956, 27, 1170, 1221, 213, 431, 645, 897, 151, 100, 549, 147, 75, 182, 1702, 244, 525, 1271, 126, 114, 824, 697, 565, 81, 1427, 139, 34, 45, 33, 439, 61, 34, 38, 33, 34, 28, 33, 690, 478, 645, 115, 178, 295, 100, 191, 81, 1638, 592, 1427, 10, 15, 34, 45, 33, 61, 34, 37, 33, 690, 1427, 570, 90, 5, 112, 1252, 121, 77, 1903, 52, 52, 55, 33, 576, 26, 652, 26, 219, 160, 26, 82, 223, 26, 451, 39, 37, 27, 451, 39, 55, 39, 52, 1248, 39, 55, 50, 55, 61, 26, 582, 464, 525, 112, 824, 315, 233, 75, 430, 325, 392, 1578, 76, 594, 34, 45, 57, 33, 4, 308, 1470, 1614, 27, 155, 443, 501, 22, 693, 89, 156, 1244, 252, 989, 1116, 614, 131, 1063, 27, 932, 75, 1026, 1769, 179, 303, 226, 447, 1531, 1419, 53, 130, 525, 27, 730, 1531, 1419, 55, 130, 824, 33, 92, 1244, 179, 1349, 1321, 119, 138, 568, 187, 33, 184, 1860, 516, 360, 1398, 347, 572, 1271, 76, 89, 156, 1244, 33, 252, 989, 87, 161, 81, 280, 296, 256, 18, 1217, 82, 178, 101, 363, 1286, 130, 525, 133, 1063, 117, 181, 1890, 394, 112, 405, 139, 90, 280, 458, 616, 81, 1202, 677, 564, 81, 507, 100, 280, 296, 256, 18, 1217, 74, 366, 611, 183, 190, 15, 121, 23, 108, 97, 81, 701, 92, 525, 112, 75, 30, 384, 97, 81, 701, 92, 824, 26, 185, 374, 217, 1377, 381, 1201, 138, 244, 81, 1665, 92, 81, 78, 7, 144, 168, 127, 172, 248, 97, 525, 26, 75, 1428, 418, 1202, 133, 121, 80, 208, 180, 221, 130, 594, 34, 45, 57, 33, 823, 77, 1372, 102, 659, 90, 155, 507, 100, 1573, 99, 809, 376, 259, 81, 4, 1255, 1551, 124, 478, 645, 1886, 6, 112, 589, 117, 1125, 168, 81, 133, 121, 80, 208, 180, 6, 1510, 130, 525, 112, 824, 179, 860, 48, 53, 112, 1419, 53, 45, 96, 17, 49, 200, 1149, 1859, 614, 75, 1026, 825, 338, 92, 133, 121, 80, 208, 180, 6, 1286, 133, 1063, 757, 77, 1862, 106, 244, 75, 268, 1744, 209, 7, 144, 168, 117, 75, 118, 101, 104, 21, 85, 127, 172, 248, 130, 81, 594, 34, 45, 57, 33, 4, 308, 27, 1517, 155, 229, 1659, 642, 1156, 1068, 117, 81, 1665, 92, 81, 75, 30, 384, 78, 7, 144, 168, 127, 172, 248, 26, 539, 106, 153, 81, 133, 121, 80, 208, 180, 6, 1286, 130, 824, 133, 902, 524, 117, 181, 97, 81, 1419, 53, 38, 28, 860, 53, 48, 96, 17, 49, 11, 1273, 1427, 15, 89, 1662, 1740, 166, 26, 1387, 709, 39, 33, 111, 143, 26, 576, 26, 97, 89, 1951, 219, 160, 26, 27, 824, 39, 56, 55, 28, 45, 39, 55, 45, 61, 27, 81, 133, 121, 80, 208, 180, 6, 1286, 130, 75, 392, 1578, 76, 111, 1619, 34, 39, 33, 28, 9, 34, 39, 33, 594, 34, 45, 57, 33, 659, 155, 105, 75, 30, 384, 78, 7, 144, 168, 690, 254, 181, 313, 230, 117, 181, 97, 81, 1419, 48, 50, 28, 860, 48, 55, 96, 17, 49, 11, 1273, 26, 81, 1709, 609, 137, 92, 75, 82, 854, 28, 77, 287, 9, 30, 9, 279, 17, 100, 7, 168, 97, 82, 89, 133, 926, 100, 97, 375, 110, 117, 81, 774, 281, 88, 768, 13, 685, 100, 130, 75, 82, 854, 28, 77, 287, 9, 30, 9, 713, 5, 34, 45, 57, 33, 1844, 97, 105, 373, 80, 1524, 326, 1427, 29, 102, 13, 11, 11, 77, 1740, 166, 26, 1387, 709, 45, 33, 359, 7, 217, 525, 52, 52, 27, 1904, 45, 52, 1248, 37, 50, 39, 61, 26, 3], [2, 96, 1140, 51, 9, 41, 11, 11, 23, 1150, 80, 714, 395, 92, 105, 286, 124, 518, 392, 1578, 76, 82, 854, 28, 77, 287, 9, 30, 9, 713, 5, 45, 57, 1844, 97, 81, 288, 304, 82, 458, 92, 763, 9, 30, 854, 865, 123, 338, 244, 400, 122, 20, 9, 102, 14, 122, 124, 107, 8, 102, 142, 7, 26, 942, 1279, 1221, 213, 147, 1383, 464, 3])\n"
     ]
    }
   ],
   "source": [
    "print(arx_dataset_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:55.612358Z",
     "iopub.status.busy": "2023-03-28T13:32:55.611681Z",
     "iopub.status.idle": "2023-03-28T13:32:55.631050Z",
     "shell.execute_reply": "2023-03-28T13:32:55.630017Z",
     "shell.execute_reply.started": "2023-03-28T13:32:55.612318Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchSizeDataloader:\n",
    "    def __init__(self, dataset, batch_size, pad_value, device, batch_first=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_len = len(dataset)\n",
    "        self.pad_value = pad_value\n",
    "        self.batch_first = batch_first\n",
    "        self.device = device\n",
    "        \n",
    "        # для создания итератора\n",
    "        self.num = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataset) / self.batch_size))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    @staticmethod\n",
    "    def ensure_length(txt: list, out_len: int, pad_value: int):\n",
    "        \"\"\"\n",
    "        Функция для добавления фиктивных токенов в преложение вида [23, 43, 121]\n",
    "        \"\"\"\n",
    "        if len(txt) < out_len:\n",
    "            txt = list(txt) + [pad_value] * (out_len - len(txt))\n",
    "        else:\n",
    "            txt = txt[:out_len]\n",
    "        return txt\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.num >= self.__len__():\n",
    "            # если итерирование закончено, то выставить счетчик снова в 0\n",
    "            self.num = 0\n",
    "            raise StopIteration\n",
    "            \n",
    "        src = []\n",
    "        src_len = []\n",
    "        trg = []\n",
    "        trg_len = []\n",
    "        for i in range(self.num*self.batch_size, (self.num+1)*self.batch_size):\n",
    "            if i >= self.dataset_len:\n",
    "                break\n",
    "                \n",
    "            src_i, trg_i = self.dataset[i]\n",
    "            src.append(src_i)\n",
    "            src_len.append(len(src_i))\n",
    "            \n",
    "            trg.append(trg_i)\n",
    "            trg_len.append(len(trg_i))\n",
    "            \n",
    "        max_len_src = np.max(src_len)\n",
    "        max_len_trg = np.max(trg_len)\n",
    "        \n",
    "        ensured_src = []\n",
    "        ensured_trg = []\n",
    "        for i in range(len(src)):\n",
    "            src_i = src[i]\n",
    "            trg_i = trg[i]\n",
    "            \n",
    "            ensured_src.append(self.ensure_length(src_i, max_len_src, self.pad_value))\n",
    "            ensured_trg.append(self.ensure_length(trg_i, max_len_trg, self.pad_value))\n",
    "\n",
    "        self.num += 1\n",
    "        \n",
    "        ensured_src = torch.LongTensor(ensured_src)\n",
    "        src_len = torch.LongTensor(src_len)\n",
    "        ensured_trg = torch.LongTensor(ensured_trg)\n",
    "        trg_len = torch.LongTensor(trg_len)\n",
    "        \n",
    "        if not self.batch_first:\n",
    "            ensured_src = ensured_src.permute(1, 0)\n",
    "            ensured_trg = ensured_trg.permute(1, 0)\n",
    "        \n",
    "        return ensured_src.to(self.device), src_len.to(self.device),\\\n",
    "                ensured_trg.to(self.device), trg_len.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:55.633226Z",
     "iopub.status.busy": "2023-03-28T13:32:55.632563Z",
     "iopub.status.idle": "2023-03-28T13:32:55.643709Z",
     "shell.execute_reply": "2023-03-28T13:32:55.642539Z",
     "shell.execute_reply.started": "2023-03-28T13:32:55.633183Z"
    }
   },
   "outputs": [],
   "source": [
    "# PAD_IDX = vocabulary['<PAD>']\n",
    "PAD_IDX = tokenizer.subword_to_id('<PAD>')\n",
    "\n",
    "train_data_loader = BatchSizeDataloader(arx_dataset_train, batch_size=32, device=device, pad_value=PAD_IDX)\n",
    "# val_data_loader = BatchSizeDataloader(arx_dataset_val, batch_size=32, device=device, pad_value=PAD_IDX)\n",
    "# test_data_loader = BatchSizeDataloader(arx_dataset_test, batch_size=32, device=device, pad_value=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:55.646268Z",
     "iopub.status.busy": "2023-03-28T13:32:55.645537Z",
     "iopub.status.idle": "2023-03-28T13:32:56.205752Z",
     "shell.execute_reply": "2023-03-28T13:32:56.204376Z",
     "shell.execute_reply.started": "2023-03-28T13:32:55.646230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [ 127,  763,  350,  ..., 1995,  185,  748],\n",
      "        [  44,    9, 1744,  ...,  444,  413,   11],\n",
      "        ...,\n",
      "        [1004,    0,    0,  ...,    0,    0,    0],\n",
      "        [ 509,    0,    0,  ...,    0,    0,    0],\n",
      "        [   3,    0,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "tensor([1382, 1129, 1110, 1109,  939,  908,  864,  839,  837,  802,  797,  788,\n",
      "         787,  784,  778,  769,  769,  767,  766,  760,  757,  745,  739,  739,\n",
      "         734,  732,  730,  730,  728,  727,  725,  723], device='cuda:0')\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [  81,   81,   97,  ...,    4,  130,   75],\n",
      "        [ 930,  115,  107,  ..., 1157,  868,  326],\n",
      "        ...,\n",
      "        [  16,   26,    0,  ...,    0,    0,    0],\n",
      "        [  26,    3,    0,  ...,    0,    0,    0],\n",
      "        [   3,    0,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "tensor([720, 719, 715, 715, 712, 711, 709, 707, 707, 706, 702, 701, 701, 701,\n",
      "        701, 700, 699, 699, 699, 696, 696, 696, 695, 691, 689, 688, 686, 686,\n",
      "        685, 684, 684, 683], device='cuda:0')\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [ 131, 1657, 1995,  ...,   88,  446,  131],\n",
      "        [ 485,  138,  198,  ...,  143,  174, 1850],\n",
      "        ...,\n",
      "        [  48,  161,    3,  ...,    0,    0,    0],\n",
      "        [1092,    3,    0,  ...,    0,    0,    0],\n",
      "        [   3,    0,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "tensor([681, 680, 679, 678, 678, 676, 676, 675, 675, 674, 673, 673, 672, 672,\n",
      "        671, 671, 671, 670, 670, 669, 669, 667, 667, 665, 665, 664, 664, 662,\n",
      "        662, 661, 661, 661], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for src, src_len, trg, trg_len in train_data_loader:\n",
    "    print(src)\n",
    "    print(src_len)\n",
    "    j += 1\n",
    "    if j == 3:\n",
    "        break\n",
    "        \n",
    "del train_data_loader#, val_data_loader, test_data_loader\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.212499Z",
     "iopub.status.busy": "2023-03-28T13:32:56.211998Z",
     "iopub.status.idle": "2023-03-28T13:32:56.221512Z",
     "shell.execute_reply": "2023-03-28T13:32:56.220221Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.212447Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_positional_encoding(max_length, embedding_size):\n",
    "    time = np.pi * torch.arange(0, max_length).float()\n",
    "    freq_dividers = torch.arange(1, embedding_size // 2 + 1).float()\n",
    "    inputs = time[:, None] / freq_dividers[None, :]\n",
    "    \n",
    "    result = torch.zeros(max_length, embedding_size)\n",
    "    result[:, 0::2] = torch.sin(inputs)\n",
    "    result[:, 1::2] = torch.cos(inputs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.224055Z",
     "iopub.status.busy": "2023-03-28T13:32:56.223498Z",
     "iopub.status.idle": "2023-03-28T13:32:56.237404Z",
     "shell.execute_reply": "2023-03-28T13:32:56.235900Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.224010Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 n_heads, \n",
    "                 pf_dim,\n",
    "                 dropout, \n",
    "                 device,\n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.hid_dim = hid_dim\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "#         self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
    "                                                  n_heads, \n",
    "                                                  pf_dim,\n",
    "                                                  dropout, \n",
    "                                                  device) \n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "        \n",
    "#         pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        \n",
    "        #pos = [batch size, src len]\n",
    "        \n",
    "#         src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "    \n",
    "        pos_codes = make_positional_encoding(src_len,\n",
    "                                             self.hid_dim).unsqueeze(0).to(self.device)\n",
    "\n",
    "        src = self.dropout((self.tok_embedding(src) * self.scale) + pos_codes.repeat(batch_size, 1, 1))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "            \n",
    "        #src = [batch size, src len, hid dim]\n",
    "            \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.240500Z",
     "iopub.status.busy": "2023-03-28T13:32:56.239130Z",
     "iopub.status.idle": "2023-03-28T13:32:56.251400Z",
     "shell.execute_reply": "2023-03-28T13:32:56.250136Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.240462Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim,  \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
    "                                                                     pf_dim, \n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        #src_mask = [batch size, 1, 1, src len] \n",
    "                \n",
    "        #self attention\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        #positionwise feedforward\n",
    "        _src = self.positionwise_feedforward(src)\n",
    "        \n",
    "        #dropout, residual and layer norm\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.254534Z",
     "iopub.status.busy": "2023-03-28T13:32:56.253465Z",
     "iopub.status.idle": "2023-03-28T13:32:56.271811Z",
     "shell.execute_reply": "2023-03-28T13:32:56.270586Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.254497Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "        \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        \n",
    "        #Q = [batch size, query len, hid dim]\n",
    "        #K = [batch size, key len, hid dim]\n",
    "        #V = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        #Q = [batch size, n heads, query len, head dim]\n",
    "        #K = [batch size, n heads, key len, head dim]\n",
    "        #V = [batch size, n heads, value len, head dim]\n",
    "                \n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        #energy = [batch size, n heads, query len, key len]\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "                \n",
    "        #attention = [batch size, n heads, query len, key len]\n",
    "                \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        \n",
    "        #x = [batch size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        #x = [batch size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.274564Z",
     "iopub.status.busy": "2023-03-28T13:32:56.273612Z",
     "iopub.status.idle": "2023-03-28T13:32:56.284540Z",
     "shell.execute_reply": "2023-03-28T13:32:56.283428Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.274526Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        \n",
    "        #x = [batch size, seq len, pf dim]\n",
    "        \n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.288086Z",
     "iopub.status.busy": "2023-03-28T13:32:56.286755Z",
     "iopub.status.idle": "2023-03-28T13:32:56.301758Z",
     "shell.execute_reply": "2023-03-28T13:32:56.300362Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.287876Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 output_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 n_heads, \n",
    "                 pf_dim, \n",
    "                 dropout, \n",
    "                 device,\n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "#         self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
    "                                                  n_heads, \n",
    "                                                  pf_dim, \n",
    "                                                  dropout, \n",
    "                                                  device)\n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "                \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "#         pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "                            \n",
    "        #pos = [batch size, trg len]\n",
    "            \n",
    "#         trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        \n",
    "        pos_codes = make_positional_encoding(trg_len,\n",
    "                                             self.hid_dim).unsqueeze(0).to(self.device)\n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + pos_codes)\n",
    "        \n",
    "                \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "            \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.304848Z",
     "iopub.status.busy": "2023-03-28T13:32:56.303870Z",
     "iopub.status.idle": "2023-03-28T13:32:56.317586Z",
     "shell.execute_reply": "2023-03-28T13:32:56.316111Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.304810Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim, \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
    "                                                                     pf_dim, \n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        #self attention\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "            \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "            \n",
    "        #encoder attention\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "                    \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        #positionwise feedforward\n",
    "        _trg = self.positionwise_feedforward(trg)\n",
    "        \n",
    "        #dropout, residual and layer norm\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.320596Z",
     "iopub.status.busy": "2023-03-28T13:32:56.319570Z",
     "iopub.status.idle": "2023-03-28T13:32:56.333801Z",
     "shell.execute_reply": "2023-03-28T13:32:56.332624Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.320559Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder, \n",
    "                 decoder, \n",
    "                 src_pad_idx, \n",
    "                 trg_pad_idx, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        \n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        return src_mask\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        \n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        \n",
    "        #trg_sub_mask = [trg len, trg len]\n",
    "            \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        \n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len]\n",
    "                \n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        \n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "                \n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.336747Z",
     "iopub.status.busy": "2023-03-28T13:32:56.335453Z",
     "iopub.status.idle": "2023-03-28T13:32:56.358637Z",
     "shell.execute_reply": "2023-03-28T13:32:56.357661Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.336708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "      <th>len_abstract</th>\n",
       "      <th>len_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39856</th>\n",
       "      <td>l'analyse du lien entre l'environnement et la ...</td>\n",
       "      <td>construction d'une plate-forme int\\'egr\\'ee po...</td>\n",
       "      <td>1380</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73288</th>\n",
       "      <td>superoxide reductase (sor) is an fe protein th...</td>\n",
       "      <td>m{\\\"o}ssbauer characterization of an unusual h...</td>\n",
       "      <td>1127</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>phylogenetic approaches are finding more and m...</td>\n",
       "      <td>clustering with phylogenetic tools in astrophy...</td>\n",
       "      <td>1108</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70669</th>\n",
       "      <td>this article, in english, represents part of t...</td>\n",
       "      <td>ettore majorana's scientific (and human) perso...</td>\n",
       "      <td>1107</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81882</th>\n",
       "      <td>background: there is uncertainty about the bur...</td>\n",
       "      <td>pediatric hospitalizations associated with res...</td>\n",
       "      <td>937</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45245</th>\n",
       "      <td>we determine the fundamental group of period d...</td>\n",
       "      <td>the fundamental group of period domains over f...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80674</th>\n",
       "      <td>methods of particle beam cooling are reviewed.</td>\n",
       "      <td>cooling of particle beams in storage rings</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82834</th>\n",
       "      <td>computations in the cohomology of finite groups.</td>\n",
       "      <td>the cohomology of certain groups</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35605</th>\n",
       "      <td>a simple application of the semipositivity.</td>\n",
       "      <td>a product formula for volumes of varieties</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70592</th>\n",
       "      <td>some problems of testology are discussed.</td>\n",
       "      <td>problems of testology</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102557 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "39856  l'analyse du lien entre l'environnement et la ...   \n",
       "73288  superoxide reductase (sor) is an fe protein th...   \n",
       "1340   phylogenetic approaches are finding more and m...   \n",
       "70669  this article, in english, represents part of t...   \n",
       "81882  background: there is uncertainty about the bur...   \n",
       "...                                                  ...   \n",
       "45245  we determine the fundamental group of period d...   \n",
       "80674     methods of particle beam cooling are reviewed.   \n",
       "82834   computations in the cohomology of finite groups.   \n",
       "35605        a simple application of the semipositivity.   \n",
       "70592          some problems of testology are discussed.   \n",
       "\n",
       "                                                   title  len_abstract  \\\n",
       "39856  construction d'une plate-forme int\\'egr\\'ee po...          1380   \n",
       "73288  m{\\\"o}ssbauer characterization of an unusual h...          1127   \n",
       "1340   clustering with phylogenetic tools in astrophy...          1108   \n",
       "70669  ettore majorana's scientific (and human) perso...          1107   \n",
       "81882  pediatric hospitalizations associated with res...           937   \n",
       "...                                                  ...           ...   \n",
       "45245  the fundamental group of period domains over f...            13   \n",
       "80674         cooling of particle beams in storage rings            12   \n",
       "82834                   the cohomology of certain groups            12   \n",
       "35605         a product formula for volumes of varieties            11   \n",
       "70592                              problems of testology             8   \n",
       "\n",
       "       len_title  \n",
       "39856         55  \n",
       "73288         69  \n",
       "1340          15  \n",
       "70669         21  \n",
       "81882         52  \n",
       "...          ...  \n",
       "45245         10  \n",
       "80674         14  \n",
       "82834          8  \n",
       "35605         12  \n",
       "70592          4  \n",
       "\n",
       "[102557 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.361024Z",
     "iopub.status.busy": "2023-03-28T13:32:56.360002Z",
     "iopub.status.idle": "2023-03-28T13:32:56.430527Z",
     "shell.execute_reply": "2023-03-28T13:32:56.429447Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.360987Z"
    }
   },
   "outputs": [],
   "source": [
    "# INPUT_DIM = len(vocabulary)\n",
    "# OUTPUT_DIM = len(vocabulary)\n",
    "INPUT_DIM = tokenizer.vocab_size()\n",
    "OUTPUT_DIM = tokenizer.vocab_size()\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 64\n",
    "DEC_PF_DIM = 64\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "# SOS_IDX = vocabulary['<SOS>']\n",
    "# EOS_IDX = vocabulary['<EOS>']\n",
    "SOS_IDX = tokenizer.subword_to_id('<BOS>')\n",
    "EOS_IDX = tokenizer.subword_to_id('<EOS>')\n",
    "\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device\n",
    "             )\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device\n",
    "             )\n",
    "\n",
    "model = Seq2Seq(enc, dec, PAD_IDX, PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.432756Z",
     "iopub.status.busy": "2023-03-28T13:32:56.431979Z",
     "iopub.status.idle": "2023-03-28T13:32:56.459504Z",
     "shell.execute_reply": "2023-03-28T13:32:56.458515Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.432718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(2000, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (fc_2): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (fc_2): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (fc_2): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(2000, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (fc_2): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (fc_2): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (fc_2): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=2000, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "            \n",
    "model.apply(initialize_weights)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' not in name:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.461997Z",
     "iopub.status.busy": "2023-03-28T13:32:56.460878Z",
     "iopub.status.idle": "2023-03-28T13:32:56.469543Z",
     "shell.execute_reply": "2023-03-28T13:32:56.468274Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.461959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,112,720 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.472163Z",
     "iopub.status.busy": "2023-03-28T13:32:56.471177Z",
     "iopub.status.idle": "2023-03-28T13:32:56.479203Z",
     "shell.execute_reply": "2023-03-28T13:32:56.478059Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.472125Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.000125)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "lr_sched = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.481891Z",
     "iopub.status.busy": "2023-03-28T13:32:56.480905Z",
     "iopub.status.idle": "2023-03-28T13:32:56.488692Z",
     "shell.execute_reply": "2023-03-28T13:32:56.487547Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.481855Z"
    }
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(optimizer):\n",
    "    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                      patience=3,\n",
    "                                                      factor=0.5,\n",
    "                                                      verbose=True)\n",
    "\n",
    "lr_sched = lr_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.491863Z",
     "iopub.status.busy": "2023-03-28T13:32:56.490799Z",
     "iopub.status.idle": "2023-03-28T13:32:56.517713Z",
     "shell.execute_reply": "2023-03-28T13:32:56.516485Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.491708Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src, src_len, trg, trg_len = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg = [batch size, trg len]\n",
    "            \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.520930Z",
     "iopub.status.busy": "2023-03-28T13:32:56.519886Z",
     "iopub.status.idle": "2023-03-28T13:32:56.531589Z",
     "shell.execute_reply": "2023-03-28T13:32:56.530361Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.520884Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src, src_len, trg, trg_len = batch\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.535134Z",
     "iopub.status.busy": "2023-03-28T13:32:56.533973Z",
     "iopub.status.idle": "2023-03-28T13:32:56.543248Z",
     "shell.execute_reply": "2023-03-28T13:32:56.542130Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.535096Z"
    }
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:32:56.546659Z",
     "iopub.status.busy": "2023-03-28T13:32:56.545472Z",
     "iopub.status.idle": "2023-03-28T13:32:56.552277Z",
     "shell.execute_reply": "2023-03-28T13:32:56.551116Z",
     "shell.execute_reply.started": "2023-03-28T13:32:56.546621Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = f'{MODELS_PATH}/transformer_yttm.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[-0.0385,  0.0327,  0.0045,  ..., -0.0504,  0.0197, -0.0298],\n",
       "           [-0.0212,  0.0395, -0.0206,  ..., -0.0253,  0.0327, -0.0048],\n",
       "           [ 0.0546, -0.0462,  0.2006,  ..., -0.0297, -0.2753, -0.0328],\n",
       "           ...,\n",
       "           [ 0.8339,  0.3079,  0.2088,  ..., -0.8094, -0.5149,  0.0926],\n",
       "           [ 0.0436,  0.1904,  0.2077,  ..., -0.0054, -0.1352,  0.1382],\n",
       "           [ 0.0058,  0.0880, -0.2132,  ...,  0.0171, -0.2079,  0.0700]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0.8924, 0.3829, 1.0946, 0.9791, 1.3326, 1.2822, 0.9896, 0.7459, 0.9788,\n",
       "           1.3791, 1.3874, 0.9081, 1.4637, 1.1194, 0.8420, 1.1368, 1.0967, 1.0298,\n",
       "           0.9009, 1.1566, 0.6937, 0.9528, 1.2975, 1.3079, 0.8076, 1.4147, 1.3848,\n",
       "           1.1110, 1.4756, 0.9886, 0.9951, 1.1572, 1.2136, 0.8950, 0.7774, 1.9902,\n",
       "           1.1649, 0.6979, 1.0144, 0.6275, 1.6930, 1.2363, 1.0165, 0.5246, 0.7331,\n",
       "           1.4817, 0.8226, 1.4484, 1.1868, 1.1038, 1.0390, 1.3234, 1.2647, 1.3371,\n",
       "           0.7733, 1.1454, 1.5824, 0.8714, 1.1627, 0.9707, 1.1512, 0.7437, 0.8398,\n",
       "           0.9950, 1.2979, 1.3931, 0.8622, 1.0443, 1.1829, 1.1391, 0.6553, 0.5012,\n",
       "           1.1191, 0.8799, 1.5278, 1.3432, 0.6562, 0.9080, 0.2973, 1.1521, 1.3584,\n",
       "           1.0892, 1.0620, 1.2369, 1.1216, 1.3351, 0.9426, 1.2681, 1.2141, 1.1430,\n",
       "           1.1774, 1.2235, 1.3874, 0.7355, 1.7425, 1.2907, 1.2188, 1.2279, 0.9670,\n",
       "           0.6711, 1.2544, 1.1656, 1.2273, 1.2189, 1.2488, 1.2652, 1.4214, 0.6231,\n",
       "           0.9158, 0.4441, 0.9777, 0.9029, 1.0738, 0.9617, 0.9961, 0.8582, 0.4801,\n",
       "           0.4969, 1.3325, 1.6469, 0.9845, 0.6737, 1.3014, 0.9210, 1.2277, 0.8723,\n",
       "           1.1757, 0.9644, 1.0419, 0.8374, 1.3102, 1.1702, 0.9576, 0.9644, 1.2910,\n",
       "           1.1938, 1.2781, 1.2469, 1.0932, 0.7525, 1.0391, 1.2404, 0.8884, 0.7012,\n",
       "           0.6615, 1.2247, 1.2901, 0.6966, 0.8257, 1.5557, 1.2422, 0.8269, 0.9097,\n",
       "           1.0469, 1.5011, 0.7308, 1.1323, 0.8848, 0.9196, 1.0256, 0.7177, 1.6640,\n",
       "           1.2329, 0.6079, 1.0939, 1.1912, 1.1867, 0.9723, 1.1304, 1.4147, 1.2623,\n",
       "           0.7956, 0.7971, 1.4294, 0.5035, 1.2803, 1.0548, 1.1531, 1.5481, 1.1072,\n",
       "           1.4228, 0.7013, 0.9069, 1.0113, 1.0397, 1.3569, 0.9819, 1.4151, 1.1843,\n",
       "           1.3931, 0.9638, 0.9404, 0.9385, 1.1945, 0.7083, 0.8107, 0.9078, 1.0774,\n",
       "           0.9246, 1.2913, 0.6004, 1.1939, 0.6363, 0.3565, 1.0379, 0.9210, 0.4907,\n",
       "           0.6282, 1.0262, 1.6640, 0.7967, 0.7359, 1.0199, 1.2150, 1.2037, 0.9769,\n",
       "           1.4768, 1.4634, 0.5186, 1.0331, 1.0186, 1.0689, 1.2538, 1.0907, 0.9544,\n",
       "           0.9869, 1.2544, 0.9202, 1.0588, 0.7029, 1.4992, 0.7111, 1.3813, 1.2267,\n",
       "           1.3182, 0.7917, 0.7596, 1.2373, 1.4167, 0.6882, 0.6246, 1.0515, 0.7988,\n",
       "           0.7761, 0.6034, 1.5144, 1.1177, 0.8517, 1.1409, 0.7988, 0.7727, 1.1202,\n",
       "           0.8243, 0.8334, 1.1948, 1.0777], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 3.0589e-01,  3.1913e-01,  2.6235e-01, -5.8505e-02, -4.7152e-02,\n",
       "            8.0777e-02, -3.5298e-01,  4.8747e-01,  4.1281e-04,  3.3803e-02,\n",
       "            6.1635e-02, -3.1687e-01, -1.9461e-01,  8.0227e-02,  4.5297e-01,\n",
       "            3.2556e-01, -2.6201e-01,  3.0983e-01, -3.9467e-01, -2.7952e-01,\n",
       "            3.7001e-01,  1.4175e-02, -3.1076e-01,  1.5004e-01,  6.0307e-01,\n",
       "           -3.2227e-01, -4.1600e-01, -3.5910e-01, -3.8330e-01,  2.2775e-01,\n",
       "           -2.6546e-01, -3.6253e-02, -3.5846e-01, -4.0568e-01,  2.2044e-01,\n",
       "            1.2968e-01,  3.2703e-02,  2.7656e-01, -3.1954e-01,  4.7477e-01,\n",
       "           -1.9810e-01,  2.2142e-01,  2.3467e-01,  1.4376e-01, -1.6817e-01,\n",
       "           -5.3576e-01,  3.6694e-01,  2.2289e-01, -1.6363e-01, -4.8300e-01,\n",
       "           -3.2128e-01,  2.5230e-01,  3.9995e-01, -1.5235e-01, -1.7470e-01,\n",
       "           -2.4700e-01, -3.2873e-01, -2.0638e-01,  2.9714e-01,  5.0344e-01,\n",
       "           -3.3002e-02, -1.8117e-01, -2.8489e-01, -2.0715e-01, -2.2627e-01,\n",
       "            1.2845e-01,  2.4869e-01, -4.7816e-02,  2.0558e-01,  1.8285e-01,\n",
       "           -2.8892e-01,  1.6520e-01, -4.7610e-01, -2.1766e-01, -5.9432e-01,\n",
       "           -5.5330e-02, -2.7769e-01, -3.3894e-01, -4.9274e-01, -1.7206e-01,\n",
       "            2.8746e-01, -2.1042e-01, -4.9083e-01, -8.0263e-02,  3.5634e-02,\n",
       "           -1.2015e-01, -1.0343e-01, -8.7051e-02,  6.7631e-01,  4.5619e-03,\n",
       "            2.6792e-01, -1.7240e-01, -4.0302e-01, -1.2162e-01, -1.7002e-01,\n",
       "           -2.6064e-01,  5.7058e-01, -5.1895e-01,  1.9522e-01, -5.5079e-02,\n",
       "           -4.3180e-01, -8.8397e-02, -2.4257e-01,  3.7604e-01,  2.1580e-01,\n",
       "           -4.9015e-02, -3.5911e-01, -1.1802e-01,  2.2705e-01,  2.7882e-01,\n",
       "           -5.1962e-02, -1.9406e-01,  2.1565e-01,  8.7518e-03, -2.0083e-01,\n",
       "           -9.0583e-02,  6.9513e-02,  3.6296e-01,  6.9506e-02, -3.9601e-02,\n",
       "            2.3313e-01, -3.0533e-02,  1.6522e-03, -2.9176e-01,  3.0015e-01,\n",
       "            7.8391e-02, -2.7071e-03,  3.8385e-01, -1.8252e-01, -1.1723e-01,\n",
       "           -3.4415e-01,  5.2843e-01, -4.7872e-02,  4.9021e-02, -1.8624e-01,\n",
       "            2.9152e-02, -1.5608e-01, -1.1461e-01,  1.7041e-01, -1.6243e-01,\n",
       "            1.4282e-01, -4.8724e-01,  3.5703e-01,  1.0987e-02, -3.5680e-02,\n",
       "           -2.9029e-01,  5.6475e-01, -4.1450e-01,  4.1449e-01,  3.8507e-01,\n",
       "            3.3467e-01, -1.8243e-01, -3.4683e-01,  3.1816e-01,  4.7056e-01,\n",
       "           -2.5861e-01,  2.6325e-01,  1.2111e-01, -2.0410e-01,  4.9670e-01,\n",
       "            5.6807e-02, -9.2651e-02, -3.7053e-01,  5.4817e-02, -4.1922e-01,\n",
       "            1.8324e-01,  4.4714e-01,  3.3728e-01,  1.0686e-01,  1.1019e-01,\n",
       "            4.7263e-01, -4.5208e-03, -3.2250e-02,  5.5759e-01, -2.6983e-01,\n",
       "            2.1199e-01,  5.6488e-02,  7.5964e-02, -2.4498e-01,  6.4901e-01,\n",
       "           -4.3062e-01, -2.5624e-01, -1.1523e-01, -3.3557e-01, -1.2210e-01,\n",
       "            3.0837e-01,  1.5309e-01,  5.1761e-01, -2.3316e-01, -5.4031e-01,\n",
       "            5.0636e-01,  2.7274e-01,  4.6446e-01,  3.1223e-01, -1.7791e-01,\n",
       "            2.9719e-02,  2.1492e-01,  3.4096e-01, -6.1807e-02,  1.9149e-01,\n",
       "           -1.8844e-01, -2.6188e-02, -6.1079e-01, -8.2988e-02,  3.9681e-01,\n",
       "            2.8487e-01,  4.0073e-01, -2.2127e-01, -8.2484e-02, -1.9360e-01,\n",
       "           -8.8601e-02, -3.6559e-01, -1.8743e-01, -4.3369e-01, -1.6398e-01,\n",
       "            2.8080e-01, -1.1848e-02,  1.8328e-01, -2.4252e-01,  4.4911e-02,\n",
       "            2.2916e-01,  2.0518e-01,  2.4464e-01,  2.3395e-02,  2.6129e-01,\n",
       "           -7.6396e-02,  4.9401e-01, -3.1373e-01,  2.0662e-01, -3.8487e-01,\n",
       "           -3.0889e-01, -1.4288e-02,  1.0669e-01, -8.9798e-02, -2.7619e-01,\n",
       "            1.0545e-02,  4.7858e-01,  7.1109e-02,  1.5465e-01, -3.3494e-01,\n",
       "           -1.7541e-01,  4.4142e-01,  1.6726e-01, -3.5713e-01, -1.8787e-01,\n",
       "            6.4961e-02,  2.7923e-01, -3.8052e-01,  1.2582e-01,  6.0780e-02,\n",
       "            5.6286e-01,  1.7529e-01,  3.5225e-01, -1.7516e-01, -1.0996e-01,\n",
       "           -4.2087e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0.3731, 1.3834, 0.8061, 0.7585, 1.6703, 1.3765, 1.0974, 0.7899, 0.9649,\n",
       "           1.0668, 0.2866, 0.6992, 0.8454, 0.4256, 1.2771, 0.8240, 0.7210, 1.1471,\n",
       "           1.1143, 0.8191, 1.5850, 1.1348, 0.7124, 1.2407, 1.1935, 1.0552, 1.0627,\n",
       "           1.0115, 0.9848, 1.0731, 1.1303, 1.3842, 1.5305, 0.5850, 0.6379, 1.7470,\n",
       "           1.4086, 1.0611, 1.4131, 1.1582, 1.0501, 0.7827, 1.0444, 1.1167, 1.0333,\n",
       "           1.1062, 0.8455, 1.1427, 1.1814, 1.0254, 1.0966, 1.2282, 0.8317, 1.0752,\n",
       "           1.4883, 1.0027, 0.9850, 0.8945, 1.0131, 0.6899, 1.2423, 1.5519, 0.9510,\n",
       "           1.2102, 0.7679, 1.3412, 1.2523, 0.4779, 0.8378, 0.7966, 0.9144, 0.9511,\n",
       "           0.6967, 0.8564, 0.5681, 0.8391, 0.7923, 1.0254, 1.0721, 0.5761, 1.1082,\n",
       "           1.4205, 1.0895, 0.9830, 0.8521, 1.0814, 0.8321, 1.1112, 1.2746, 1.0102,\n",
       "           0.6272, 1.1676, 1.6124, 0.8741, 1.3865, 1.9845, 1.2840, 1.0201, 0.5121,\n",
       "           1.6200, 0.9912, 0.3028, 1.1178, 1.0187, 1.0198, 1.1451, 0.9140, 1.0824,\n",
       "           0.9396, 1.0581, 1.0202, 0.6071, 1.4667, 1.1049, 0.7216, 1.3932, 1.1241,\n",
       "           0.8192, 0.8209, 1.8466, 0.6959, 1.0103, 0.9402, 0.4906, 1.1357, 1.1919,\n",
       "           1.1183, 1.7514, 0.5492, 0.8398, 0.7207, 1.1576, 0.5097, 0.5464, 1.2562,\n",
       "           0.5271, 0.6774, 0.8034, 0.9364, 0.2720, 0.8216, 0.7134, 1.0619, 0.6097,\n",
       "           1.4376, 1.2533, 0.9592, 0.8850, 1.3663, 1.3984, 0.9136, 0.7473, 1.0465,\n",
       "           0.9547, 0.6731, 0.0191, 1.1429, 0.4520, 0.9809, 1.5163, 0.7502, 1.2100,\n",
       "           1.1267, 0.7135, 0.8405, 0.8676, 1.2061, 0.9530, 1.3931, 1.1124, 1.1515,\n",
       "           0.9464, 1.1528, 0.9308, 1.0832, 1.6865, 1.1689, 1.3738, 1.1454, 1.1274,\n",
       "           1.2182, 1.2171, 0.9578, 1.2229, 1.1151, 1.0979, 1.3059, 0.9370, 1.0316,\n",
       "           1.2483, 1.1285, 0.7831, 0.8270, 0.8842, 1.5330, 0.5327, 0.7696, 0.7527,\n",
       "           1.1001, 0.4780, 1.2688, 1.1658, 1.0551, 0.7512, 0.6776, 1.3521, 0.9819,\n",
       "           1.5112, 0.5536, 1.0990, 1.0939, 1.6836, 0.7203, 1.3381, 1.2409, 1.1407,\n",
       "           1.4452, 1.1159, 0.6503, 1.1428, 1.4854, 1.0895, 0.8932, 1.4776, 1.1952,\n",
       "           1.0600, 0.5184, 0.8104, 0.2676, 0.5806, 0.8399, 0.5898, 1.0018, 0.8557,\n",
       "           0.7195, 1.3179, 0.6821, 0.6198, 1.0325, 1.2163, 0.7693, 1.2274, 0.4650,\n",
       "           1.0527, 1.0016, 1.5018, 0.3385, 0.4298, 0.8303, 1.5397, 1.3146, 0.5698,\n",
       "           1.1629, 0.6204, 1.1210, 1.0740], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0217,  0.3959, -0.2354, -0.0537, -0.5080, -0.0575,  0.0871,  0.0396,\n",
       "           -0.4756,  0.0520,  0.1516, -0.4190, -0.0560,  0.3413, -0.4577,  0.0626,\n",
       "           -0.0135,  0.0871, -0.3986, -0.5184, -0.0354, -0.1847,  0.2756,  0.3242,\n",
       "           -0.1451, -0.2005, -0.0691,  0.0833,  0.0363, -0.3678, -0.1542, -0.4966,\n",
       "            0.1495, -0.3703,  0.2218, -0.2460, -0.4736, -0.1515, -0.2037, -0.0605,\n",
       "            0.1353,  0.1703, -0.2248,  0.3654,  0.0279,  0.0346, -0.2735,  0.3290,\n",
       "            0.2951, -0.1013,  0.1410, -0.0886, -0.1621,  0.5959,  0.0727,  0.3856,\n",
       "            0.1208,  0.1439,  0.4707,  0.6962, -0.0390,  0.3882, -0.1101,  0.0802,\n",
       "           -0.6236,  0.3572,  0.2709,  0.0476, -0.3537, -0.1624,  0.4736,  0.4367,\n",
       "           -0.0710,  0.4563, -0.6023, -0.4400, -0.1725, -0.1166,  0.4149, -0.0199,\n",
       "            0.3616,  0.2008,  0.3041, -0.1299, -0.1111,  0.1293,  0.2936,  0.4844,\n",
       "           -0.0898,  0.4769, -0.4316, -0.1173, -0.1855, -0.1948,  0.0932, -0.1359,\n",
       "            0.4469, -0.1423, -0.1287,  0.0175,  0.2147,  0.4419, -0.2836, -0.2691,\n",
       "            0.2020,  0.1321,  0.1964, -0.0560, -0.1738, -0.0637, -0.0397, -0.0072,\n",
       "           -0.2775,  0.1301,  0.2223, -0.1762, -0.0839,  0.4888,  0.4502,  0.1001,\n",
       "           -0.4572, -0.1546, -0.0595,  0.0324,  0.1826,  0.0765,  0.4243,  0.0400,\n",
       "            0.0376,  0.0963,  0.2169, -0.0394,  0.3706,  0.0882,  0.5509, -0.2615,\n",
       "            0.0397,  0.0350, -0.2925,  0.0948,  0.0179, -0.3826, -0.4203,  0.1712,\n",
       "           -0.2473,  0.1330,  0.3314,  0.2545,  0.2217, -0.0924,  0.3703,  0.0316,\n",
       "           -0.0768, -0.0844, -0.0659, -0.1296, -0.6500, -0.1283, -0.1162,  0.0707,\n",
       "            0.0554, -0.0597,  0.3517, -0.4736, -0.3360, -0.0307, -0.4163,  0.2833,\n",
       "            0.0719, -0.0509, -0.5400,  0.3740,  0.2142, -0.2997, -0.4012, -0.0876,\n",
       "            0.0795,  0.1768, -0.3104, -0.1051,  0.0755, -0.4938, -0.1590,  0.2433,\n",
       "            0.1704, -0.0496,  0.1624, -0.0771, -0.0776,  0.3375,  0.0331, -0.0884,\n",
       "            0.3405,  0.0476, -0.0620,  0.3846,  0.2935, -0.2341,  0.3690, -0.2195,\n",
       "            0.0326, -0.1966,  0.2351,  0.4247,  0.0390, -0.0549,  0.2093, -0.2419,\n",
       "           -0.5454,  0.0366, -0.0277, -0.2826,  0.5126,  0.0409, -0.0244,  0.1759,\n",
       "           -0.2347, -0.0885,  0.1591, -0.2300, -0.0807, -0.4105, -0.1717, -0.0010,\n",
       "           -0.4756,  0.0564, -0.1440, -0.2004, -0.0096, -0.0653, -0.1178, -0.2017,\n",
       "           -0.0938,  0.0635, -0.3172,  0.1814,  0.4123,  0.2666, -0.0722,  0.2312,\n",
       "            0.0277, -0.3043, -0.3654, -0.0658, -0.3940, -0.1060,  0.2705,  0.0182,\n",
       "           -0.2233,  0.0105, -0.0249,  0.4687, -0.5542,  0.0341, -0.2548,  0.1161],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.4567,  0.0323,  0.0921,  ...,  0.2599, -0.0399,  0.2560],\n",
       "           [ 0.0482,  0.0354,  0.1400,  ...,  0.2150,  0.0270,  0.1245],\n",
       "           [-0.1089, -0.0665, -0.1883,  ...,  0.3347,  0.0572,  0.2404],\n",
       "           ...,\n",
       "           [-0.5278, -0.1766, -0.3227,  ...,  0.2548,  0.3318, -0.2003],\n",
       "           [ 0.2904, -0.0912,  0.5348,  ..., -0.0557,  0.1270,  0.2909],\n",
       "           [-0.1426, -0.2879,  0.0136,  ..., -0.2113,  0.5252, -0.3165]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.1884, -0.0837,  0.0669,  0.1577, -0.1296, -0.2568, -0.0096, -0.0711,\n",
       "           -0.2390, -0.0456, -0.2725,  0.1465,  0.0674,  0.0366,  0.4594, -0.0414,\n",
       "            0.2466, -0.1232, -0.3350, -0.0093, -0.3817, -0.0244,  0.0562, -0.2370,\n",
       "            0.0344,  0.0491,  0.0596,  0.0417,  0.2054, -0.1478,  0.0266,  0.0513,\n",
       "           -0.6014, -0.3424, -0.4328, -0.4129,  0.3671,  0.2601,  0.2546, -0.1926,\n",
       "           -0.0861,  0.6095,  0.1225, -0.1075,  0.4186,  0.2826,  0.0670,  0.1160,\n",
       "           -0.0701,  0.1285,  0.3429, -0.3203, -0.2772, -0.5517,  0.1091, -0.1100,\n",
       "           -0.5281,  0.0895, -0.2518, -0.5435, -0.6019, -0.0393, -0.2264, -0.2734,\n",
       "            0.2191, -0.1094,  0.0838, -0.0741,  0.1645, -0.0535, -0.4205,  0.1788,\n",
       "            0.0399,  0.2187, -0.1031, -0.1508, -0.0374,  0.0483, -0.0425, -0.3479,\n",
       "            0.0117,  0.2895, -0.0551,  0.1111, -0.2313,  0.1653, -0.3244,  0.1957,\n",
       "           -0.0844, -0.4563,  0.0396, -0.0517, -0.0280, -0.1917, -0.0039, -0.0176,\n",
       "           -0.6216, -0.2431, -0.2403,  0.4873,  0.0710,  0.4139,  0.0109,  0.4494,\n",
       "            0.2565,  0.3347,  0.3406,  0.5895, -0.3805,  0.3211,  0.2346,  0.0121,\n",
       "           -0.4501,  0.9505, -0.3306,  0.2050,  0.5750, -0.6896, -0.5246,  0.2280,\n",
       "            0.2081,  0.4859,  0.5221,  0.1789, -0.6119,  0.1351,  0.2819,  0.3523,\n",
       "           -0.2917,  0.0224, -0.0080, -0.4773,  0.2038,  0.4745,  0.1744, -0.0409,\n",
       "            0.0859, -0.2602, -0.0576,  0.2210, -0.1191, -0.5400, -0.3800, -0.3808,\n",
       "            0.2717, -0.2570, -0.4126, -0.1643, -0.2798, -0.3234,  0.3574, -0.5157,\n",
       "           -0.3202,  0.3167, -0.2356, -0.0828,  0.3886,  0.1455,  0.2682, -0.0743,\n",
       "           -0.1721,  0.1806, -0.0956,  0.1865, -0.1619, -0.1508, -0.3092, -0.2512,\n",
       "            0.1831,  0.1372, -0.0351, -0.0036,  0.1042,  0.1139, -0.1278, -0.4940,\n",
       "           -0.3725,  0.3755, -0.0096, -0.0118, -0.1086,  0.2510,  0.1485, -0.0038,\n",
       "           -0.0172, -0.1072,  0.1086, -0.3410, -0.1494,  0.0128, -0.1838,  0.2726,\n",
       "           -0.0835, -0.0737, -0.1455, -0.2739,  0.1424, -0.3244,  0.1234,  0.0276,\n",
       "            0.1769, -0.0813, -0.2273,  0.0472, -0.2062, -0.2216, -0.1981,  0.2261,\n",
       "           -0.1268,  0.2756,  0.1051, -0.1215, -0.4363, -0.3398,  0.3855,  0.2380,\n",
       "            0.0237,  0.1718,  0.3039, -0.0720, -0.0263, -0.4339,  0.3510,  0.1153,\n",
       "           -0.0037, -0.0790, -0.1433,  0.1731, -0.0349,  0.0101, -0.0896,  0.0401,\n",
       "            0.0198,  0.2468, -0.4006, -0.0129, -0.2446, -0.1467, -0.1653,  0.0010,\n",
       "           -0.2030, -0.0056, -0.0132,  0.0778, -0.0955, -0.1505,  0.0314, -0.0223,\n",
       "           -0.0319, -0.1709, -0.3134, -0.1321,  0.3074, -0.0013, -0.2441, -0.2145],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 6.6941e-02,  3.5602e-01,  1.8748e-04,  ..., -4.9213e-03,\n",
       "            -6.4630e-01,  4.9340e-01],\n",
       "           [-4.5506e-01, -4.2722e-01, -2.2465e-01,  ..., -2.3901e-01,\n",
       "            -5.5551e-01, -1.0841e-01],\n",
       "           [ 5.7153e-02,  5.7793e-01, -1.2577e-01,  ..., -4.5215e-01,\n",
       "            -1.5568e-01,  3.0142e-01],\n",
       "           ...,\n",
       "           [-1.3041e-01,  7.1002e-03,  3.4027e-01,  ..., -3.3619e-02,\n",
       "            -1.2165e-02,  3.7219e-02],\n",
       "           [-1.8722e-01, -2.0725e-01, -6.0368e-02,  ...,  1.8689e-01,\n",
       "             1.7238e-02,  2.6471e-01],\n",
       "           [ 6.4169e-01, -1.3456e-01, -7.3861e-02,  ...,  2.6224e-01,\n",
       "             5.1510e-01, -3.8031e-01]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0290, -0.0381,  0.0157,  0.0395,  0.0392, -0.0093, -0.0323, -0.0226,\n",
       "           -0.0908,  0.0364, -0.0759,  0.0647, -0.0559, -0.0540, -0.0747, -0.0409,\n",
       "            0.0372, -0.0697, -0.0610, -0.0693,  0.0299,  0.0526,  0.0287, -0.0283,\n",
       "           -0.0278,  0.0879, -0.0321,  0.0017,  0.0009, -0.0148,  0.0077,  0.0019,\n",
       "           -0.0800,  0.0256,  0.0050,  0.0373,  0.0335,  0.0896,  0.0425,  0.0278,\n",
       "           -0.0561, -0.0149,  0.0806, -0.0273, -0.0048,  0.0606,  0.1028,  0.0654,\n",
       "            0.0160,  0.0023,  0.0429, -0.0469,  0.0152, -0.0254, -0.0579, -0.0874,\n",
       "           -0.0581, -0.0943,  0.0754, -0.0509,  0.0445,  0.0582, -0.0823,  0.0541,\n",
       "            0.0387,  0.0308, -0.0898,  0.0237,  0.0123, -0.0209, -0.0494,  0.0620,\n",
       "           -0.0351, -0.0280, -0.0560, -0.0316, -0.0361, -0.0098,  0.0554,  0.0521,\n",
       "           -0.0600,  0.0294, -0.0026,  0.0600,  0.0166, -0.0155, -0.0409,  0.0010,\n",
       "           -0.0161, -0.0430,  0.0313,  0.0115,  0.0168, -0.0267, -0.0606,  0.0793,\n",
       "           -0.1707, -0.1209, -0.1257, -0.0717, -0.0703,  0.1166,  0.0732, -0.0312,\n",
       "           -0.0458,  0.0928,  0.1302,  0.1135, -0.0258,  0.1130,  0.0507,  0.0686,\n",
       "           -0.1222,  0.1421,  0.0707,  0.0358,  0.1174, -0.1797, -0.0182,  0.0024,\n",
       "            0.1169,  0.1474,  0.0273,  0.0316, -0.0999,  0.0973,  0.0172,  0.0882,\n",
       "           -0.0084,  0.0505, -0.0555,  0.0418, -0.0521, -0.0069,  0.0607, -0.0607,\n",
       "            0.0615,  0.0181, -0.0595, -0.0569, -0.0045, -0.0162, -0.0724, -0.0496,\n",
       "            0.0546, -0.0292, -0.0075,  0.0272,  0.0182, -0.0064, -0.0176,  0.0054,\n",
       "           -0.0026,  0.0264, -0.0086,  0.0024, -0.0074, -0.0486, -0.0114,  0.0095,\n",
       "            0.0292, -0.0501,  0.0396, -0.0577,  0.0137,  0.0156, -0.0063,  0.0851,\n",
       "           -0.0466, -0.0610,  0.0554,  0.0026,  0.0115, -0.0658, -0.1058,  0.0212,\n",
       "            0.0173, -0.0470,  0.0357,  0.0417,  0.0483,  0.0857,  0.1023,  0.0681,\n",
       "            0.0349, -0.0780,  0.0720, -0.0235,  0.0789,  0.0128,  0.0824, -0.0008,\n",
       "           -0.0649, -0.0213, -0.0575, -0.0412,  0.0479,  0.0530,  0.0459,  0.0247,\n",
       "            0.0281, -0.0592,  0.0195,  0.0189, -0.0289, -0.0132, -0.0165,  0.0576,\n",
       "            0.0654,  0.0546,  0.0049, -0.0240, -0.0494, -0.0674,  0.0059,  0.0218,\n",
       "           -0.0475,  0.0506, -0.0132, -0.0554, -0.0172, -0.0012, -0.0172,  0.0234,\n",
       "           -0.0705, -0.1262,  0.1047, -0.0211, -0.1156,  0.0980, -0.1219,  0.0381,\n",
       "           -0.0952,  0.0482,  0.0175,  0.0284,  0.0110,  0.0352, -0.1167,  0.0489,\n",
       "           -0.0827, -0.0281, -0.0713, -0.0842, -0.0455, -0.0777, -0.0088, -0.0789,\n",
       "           -0.0888, -0.0370,  0.0117, -0.0818, -0.0190,  0.1179, -0.0601,  0.0112],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.3373,  0.4672, -0.0212,  ..., -0.3255,  0.0880, -0.2678],\n",
       "           [-0.2271,  0.1723, -0.3829,  ...,  0.2902, -0.2543,  0.4083],\n",
       "           [ 0.0393,  0.2584,  0.1212,  ..., -0.2919,  0.0909, -0.0466],\n",
       "           ...,\n",
       "           [-0.0410, -0.3073, -0.0208,  ..., -0.1584,  0.6672,  0.1133],\n",
       "           [-0.1499, -0.6218, -0.0579,  ..., -0.1063,  0.5652,  0.2846],\n",
       "           [-0.2681, -0.6420,  0.1164,  ...,  0.0302,  0.7055,  0.2303]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 1.4280e-02, -4.6968e-01, -2.0378e-01, -5.4612e-01,  5.9949e-01,\n",
       "            1.6079e-01,  1.6555e-01, -4.9300e-01, -5.1901e-01, -4.9927e-01,\n",
       "            1.8906e-01,  8.2034e-02, -2.0464e-01, -3.9514e-02, -3.8742e-01,\n",
       "           -1.1916e-01,  2.5876e-01, -5.4569e-02, -4.0589e-04, -3.1771e-01,\n",
       "           -4.9653e-01,  2.0636e-01,  3.3308e-01,  2.4120e-01,  1.1990e-01,\n",
       "            9.3523e-02,  4.6557e-01,  5.0496e-01, -4.2399e-01, -2.7738e-01,\n",
       "           -1.2522e-01, -6.5276e-01,  3.5276e-01,  6.6549e-01,  6.7798e-01,\n",
       "           -3.2517e-01,  1.6241e-01,  5.1104e-01,  7.2826e-01, -4.3600e-01,\n",
       "           -5.4454e-01, -4.3193e-01, -4.5731e-01,  4.1922e-01,  3.2104e-01,\n",
       "           -4.0466e-01,  5.8799e-01,  7.7200e-01,  6.1326e-02,  3.1315e-01,\n",
       "           -6.2623e-01,  7.9247e-01,  6.1617e-01, -6.0276e-01, -4.2528e-02,\n",
       "           -5.4781e-02, -4.7209e-01, -6.9479e-01,  4.5447e-01, -6.4885e-01,\n",
       "           -5.0077e-01, -2.6224e-01, -5.0885e-01, -7.4984e-01, -5.8756e-02,\n",
       "            1.4535e-01,  1.6892e-01, -2.4546e-01,  2.6406e-01, -1.5913e-01,\n",
       "           -4.8300e-01, -8.9536e-02,  1.8050e-01,  1.3426e-01, -1.0631e-02,\n",
       "           -2.1685e-01,  3.1832e-01,  5.8613e-01, -6.1785e-01,  3.7123e-01,\n",
       "            4.9713e-01,  3.6720e-01, -1.7188e-01, -8.6418e-02, -6.0663e-01,\n",
       "           -1.3043e-02, -3.3521e-01,  1.8220e-01,  5.3381e-01,  2.6628e-01,\n",
       "           -2.3051e-01, -5.8426e-01, -1.0811e-01,  3.0603e-01,  5.0697e-02,\n",
       "           -1.3302e-01, -2.4911e-01, -3.8206e-01,  5.0125e-01, -1.2717e-01,\n",
       "            2.8573e-01,  1.9320e-02,  1.1543e-02,  4.6583e-01,  9.1734e-02,\n",
       "            8.7468e-02, -1.8107e-01,  1.4191e-01,  2.1141e-01, -4.6618e-01,\n",
       "            1.2020e-01,  4.1732e-01, -1.7263e-01,  2.2478e-01, -2.4134e-01,\n",
       "           -6.8813e-02, -1.3740e-01,  2.1940e-01,  2.2810e-01,  7.6783e-02,\n",
       "            3.4556e-01,  1.6983e-01,  2.4112e-01, -2.3705e-01, -2.3971e-01,\n",
       "           -1.1903e-01, -4.5970e-01, -7.3259e-02,  1.2367e-01, -6.7164e-01,\n",
       "           -5.7003e-01,  6.6236e-01, -7.9303e-01, -5.5955e-01, -5.1674e-01,\n",
       "           -3.2438e-01,  7.5615e-01, -7.0671e-01,  5.0103e-01,  5.3224e-01,\n",
       "            6.6858e-01,  6.8258e-01, -5.6005e-01,  6.8937e-01, -6.7318e-01,\n",
       "           -5.0755e-01, -5.6178e-01,  6.6648e-01, -4.6866e-01, -6.5370e-01,\n",
       "            4.4811e-01, -6.7939e-01,  4.6321e-01, -6.4875e-01,  5.0318e-01,\n",
       "            5.2614e-01, -4.9028e-01,  7.2905e-01, -7.0832e-01,  5.6514e-01,\n",
       "            3.2552e-01,  1.2117e-01, -5.8022e-01, -7.4350e-03,  4.1467e-01,\n",
       "           -6.0750e-01,  5.1694e-01, -2.3524e-01,  8.3654e-02,  5.7624e-01,\n",
       "           -1.7623e-01,  9.2595e-02,  8.5618e-02, -3.8165e-01, -3.3946e-02,\n",
       "            8.0919e-01, -1.6484e-02, -1.7445e-01,  6.4873e-02, -6.8653e-01,\n",
       "           -3.3349e-01, -2.0448e-01, -3.9155e-02,  2.1079e-01, -3.7242e-01,\n",
       "           -2.9603e-02,  1.9895e-01,  2.7940e-01, -3.1673e-01,  3.9152e-01,\n",
       "           -3.2251e-01, -4.6454e-02, -2.5183e-01,  4.6409e-01,  1.7313e-01,\n",
       "            1.3636e-01, -7.0939e-02,  1.5759e-01,  3.7996e-01,  1.7081e-01,\n",
       "           -5.5211e-01, -2.8383e-01,  1.1262e-01,  2.1231e-01,  2.8100e-01,\n",
       "            2.0693e-01, -2.3997e-01, -1.1879e-01,  2.6940e-01,  5.3299e-01,\n",
       "           -9.5975e-02,  1.5725e-03, -3.1205e-02, -2.4622e-01,  4.3097e-01,\n",
       "            3.6415e-02, -2.6345e-01, -1.4979e-01,  1.7811e-01, -6.2759e-02,\n",
       "            2.7852e-02,  4.5654e-01, -1.4333e-01,  3.6558e-01, -4.0833e-01,\n",
       "           -4.6740e-02, -1.7623e-01, -6.1172e-01,  1.9822e-01, -8.4168e-01,\n",
       "            3.3618e-01,  3.9295e-01,  1.0730e-01,  5.3467e-01, -4.7808e-01,\n",
       "            3.4344e-01, -7.5643e-02, -6.9657e-01, -5.9554e-01, -1.1965e-01,\n",
       "            5.0203e-01,  2.4478e-01,  1.8273e-01,  7.4096e-01,  3.3281e-01,\n",
       "            2.5594e-01,  5.1043e-01,  2.1292e-01,  2.8988e-02, -2.7542e-01,\n",
       "            3.7050e-02, -3.1533e-01,  8.1649e-01, -1.2358e-01, -5.7647e-01,\n",
       "           -2.8880e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.1640,  0.3005,  0.1841,  ..., -0.3676, -0.2590, -0.1950],\n",
       "           [-0.1203, -0.0312, -0.2389,  ..., -0.1325, -0.5568, -0.4691],\n",
       "           [ 0.0819,  0.0258, -0.2205,  ..., -0.2894, -0.4146, -0.4327],\n",
       "           ...,\n",
       "           [ 0.2451, -0.1178,  0.6649,  ..., -0.0162,  0.3785,  0.3721],\n",
       "           [-0.0839,  0.2164, -0.0095,  ...,  0.5636,  0.1002,  0.5944],\n",
       "           [ 0.2082,  0.1744,  0.3257,  ...,  0.2616,  0.5578,  0.3169]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.6307,  0.3076,  0.1800, -0.0723,  0.1663,  0.2705, -0.2975,  0.1748,\n",
       "           -0.2203, -0.0923,  0.5655, -0.0970,  0.2197,  0.0174,  0.2450,  0.2520,\n",
       "           -0.1116,  0.0231, -0.4391, -0.6465,  0.4020,  0.0869, -0.0613,  0.6195,\n",
       "            0.4140, -0.5672, -0.2813, -0.3844, -0.2364, -0.0818, -0.3617,  0.0999,\n",
       "            0.0943, -0.2668,  0.0724,  0.5696,  0.3012,  0.5853, -0.0960, -0.2394,\n",
       "           -0.4281,  0.1855,  0.0373, -0.0955,  0.2520, -0.3274,  0.4454, -0.1446,\n",
       "            0.2787, -0.6511,  0.1797,  0.5384, -0.0712, -0.4325,  0.1657,  0.0359,\n",
       "           -0.7922, -0.3494,  0.8012,  0.3404,  0.3741, -0.7018, -0.4154, -0.1308,\n",
       "           -0.3260,  0.4980, -0.0227,  0.1605, -0.1148, -0.3127, -0.0818, -0.0405,\n",
       "           -0.0586,  0.5957,  0.0775,  0.1719, -0.3296, -0.8431, -0.2022,  0.0045,\n",
       "            0.3313, -0.3628, -0.2188, -0.5177, -0.1739,  0.0973, -0.2740,  0.3655,\n",
       "            0.7951,  0.0846, -0.3579, -0.1722, -0.3190, -0.0293, -0.7272, -0.4267,\n",
       "            0.5544, -0.5289,  0.2175,  0.6622, -0.3129,  0.0419, -0.3291, -0.0601,\n",
       "           -0.3232,  0.2124, -0.2618, -0.2290, -0.0306, -0.2790,  0.2342, -0.5140,\n",
       "            0.5219, -0.6816,  0.0864,  0.1220, -0.1704,  0.4991,  0.1892, -0.4589,\n",
       "           -0.0591, -0.1495, -0.5329, -0.2709, -0.1206, -0.0554,  0.1183,  0.3133,\n",
       "           -0.2305, -0.3029, -0.5303, -0.0418, -0.2649, -0.3804, -0.0683,  0.5423,\n",
       "            0.0248, -0.5185, -0.4020,  0.1077,  0.4220, -0.6439,  0.0504, -0.2504,\n",
       "           -0.4467, -0.3112,  0.5166, -0.5863,  0.1696,  0.4234,  0.8613, -0.5434,\n",
       "           -0.5358,  0.2005,  0.2304, -0.2076,  0.0658, -0.4246,  0.4427,  0.1748,\n",
       "            0.4165,  0.2620, -0.3434,  0.0931, -0.0244,  0.3127,  0.3353,  0.3974,\n",
       "            0.6148,  0.4300,  0.6096, -0.0656, -0.0290, -0.1454, -0.5516,  0.6831,\n",
       "            0.2438,  0.2705, -0.6296,  0.7039, -0.3043, -0.4556, -0.2868, -0.1429,\n",
       "            0.1147,  0.0179, -0.2567,  0.1516, -0.6576, -0.0855,  0.1837,  0.1619,\n",
       "            0.6070,  0.2742, -0.1935, -0.2364,  0.5909,  0.5178, -0.2191, -0.2417,\n",
       "           -0.4303, -0.2417, -0.3503, -0.1452,  0.3307,  0.0633,  0.7243,  0.1642,\n",
       "           -0.3606,  0.5188,  0.0818, -0.3112,  0.2097, -0.5441, -0.0146, -0.0927,\n",
       "            0.3678,  0.0056, -0.0525,  0.1208,  0.6323,  0.0932,  0.2158,  0.3118,\n",
       "           -0.1075,  0.4589,  0.0418, -0.3373,  0.0721, -0.0041, -0.1940, -0.6527,\n",
       "           -0.5191, -0.0927,  0.3241,  0.0788,  0.3171, -0.1010,  0.4685,  0.1702,\n",
       "            0.1422,  0.2065,  0.3281, -0.0837, -0.1609, -0.1297, -0.3033,  0.0035,\n",
       "           -0.1566, -0.2573,  0.4027,  0.3219,  0.0959, -0.3169, -0.1746, -0.6874],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.3381, -0.4076, -1.0713,  ..., -0.0249,  0.1187,  1.0053],\n",
       "           [-0.2120,  0.2131, -0.0158,  ...,  0.1685, -0.0082, -0.2770],\n",
       "           [ 0.2249,  0.0720,  0.2311,  ..., -0.0485, -0.4690, -0.6426],\n",
       "           ...,\n",
       "           [-0.4372, -0.0919, -0.0895,  ...,  0.3661,  0.0215,  0.3361],\n",
       "           [ 0.0159,  0.0213,  0.3462,  ..., -0.0266,  0.3391, -0.3854],\n",
       "           [-0.0110,  0.1745,  0.6903,  ..., -0.2361, -0.2887, -0.5113]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.4901, -0.4735,  0.0706, -0.9434, -0.1125,  0.2108,  0.2616, -0.5901,\n",
       "           -0.1988,  0.0266, -0.1229, -0.4254,  0.5566,  0.1572, -0.6008,  0.0615,\n",
       "            0.2256,  0.1085,  0.1220, -0.5784, -0.2888, -0.5305,  0.0986, -0.0927,\n",
       "           -0.0784,  0.0863,  0.0345, -0.2740,  0.1058,  0.3774, -0.6444, -0.2225,\n",
       "            0.0687,  0.2959, -0.4835, -0.3301, -0.2375, -0.5248,  0.0698, -0.5005,\n",
       "            0.4274,  0.3686, -0.5343, -0.4277, -0.2880, -0.3002, -0.2136, -0.3773,\n",
       "           -0.0050, -0.1004, -0.2529, -0.2420, -0.0650, -0.0698, -0.1131, -0.3265,\n",
       "            0.1183, -0.1127,  0.0110, -0.4699, -0.1376, -0.1940, -0.4452, -0.1884],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.4326,  0.0241, -0.3166,  ...,  0.1973,  0.1358,  0.2055],\n",
       "           [ 0.3093, -0.0420,  0.1156,  ...,  0.4902,  0.4158,  0.9038],\n",
       "           [ 0.6987,  0.1198,  0.4516,  ...,  0.1070,  0.2802,  0.0422],\n",
       "           ...,\n",
       "           [-0.6573, -0.4592, -0.0017,  ..., -0.0203,  0.1030, -0.0876],\n",
       "           [ 0.0072, -0.3358,  0.3443,  ..., -0.2165, -0.3801, -0.3367],\n",
       "           [-0.0186,  0.0068, -0.2715,  ...,  0.1267, -0.2100, -0.4132]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0800,  0.6859,  0.4438, -0.0717, -0.4903,  0.3041,  0.0475, -0.0165,\n",
       "           -0.3419,  0.2147,  0.1440,  0.2934, -0.1772,  0.4635, -0.8015,  0.3147,\n",
       "           -0.0357, -0.3792, -0.0286, -0.1216,  0.1454,  0.5927, -0.4415,  0.1789,\n",
       "           -0.0723, -0.1983, -0.2267, -0.1745, -0.0995, -0.8047, -0.5285, -0.6889,\n",
       "           -0.0432, -0.3696,  0.3406, -0.1112, -0.6025,  0.3804, -0.2649,  0.0403,\n",
       "            0.4952,  0.1650, -0.7747,  0.1194, -0.0105,  0.3292, -0.3621,  0.3785,\n",
       "            0.2030, -0.1881,  0.1764, -0.0444,  0.0944,  0.4775,  0.1425,  0.6493,\n",
       "            0.0536,  0.4826,  0.5830,  0.1939, -0.0807,  0.3097,  0.4295,  0.3377,\n",
       "           -0.1853, -0.2897,  0.5477,  0.3287, -0.1398, -0.1393,  0.5694,  0.2198,\n",
       "           -0.3344,  0.2967, -0.2339, -0.2656, -0.7939, -0.2166, -0.0959,  0.1832,\n",
       "            0.3464,  0.5075,  0.2083,  0.0422, -0.0263,  0.4838,  0.3225,  0.6948,\n",
       "            0.3139,  0.4271, -0.1142,  0.3031, -0.4730, -0.5755, -0.0987, -0.2537,\n",
       "            0.2727, -0.3487, -0.2838,  0.2094,  0.0448,  0.1819, -0.3326, -0.0509,\n",
       "           -0.5100,  0.2883, -0.3489,  0.1722,  0.5512, -0.3653,  0.3634, -0.0335,\n",
       "            0.2645,  0.1170,  0.1561, -0.5283, -0.5023,  0.0539,  0.3910, -0.0667,\n",
       "           -0.1784, -0.1115,  0.3860,  0.2297,  0.2077, -0.0968,  0.6464,  0.2516,\n",
       "           -0.3643,  0.5735, -0.2777, -0.2733,  0.1463, -0.4112,  0.5216, -0.3918,\n",
       "           -0.3758, -0.3360, -0.4315,  0.1677, -0.1058, -0.3530, -0.0336,  0.1895,\n",
       "           -0.4473,  0.2805,  0.2482,  0.5315,  0.5866, -0.0036,  0.0556,  0.4373,\n",
       "           -0.1490, -0.0794, -0.1291, -0.0798, -0.1131, -0.1276,  0.1168,  0.1152,\n",
       "            0.1774,  0.1653,  0.1109, -0.5402, -0.1605,  0.1475, -0.5689,  0.5387,\n",
       "            0.2257, -0.4194, -0.2847,  0.6392, -0.4284,  0.3795, -0.2827, -0.1121,\n",
       "           -0.0811, -0.0918, -0.3572,  0.0375, -0.0420, -0.2321, -0.4956,  0.8482,\n",
       "           -0.0090, -0.2643, -0.0193,  0.1584,  0.4747,  0.2642,  0.1454,  0.0411,\n",
       "            0.0759, -0.0733,  0.3552,  0.0642,  0.6957, -0.0481,  0.6782, -0.1728,\n",
       "            0.1783, -0.2144,  0.4300, -0.0712, -0.2135,  0.3054,  0.3143,  0.3970,\n",
       "           -0.0300,  0.2568,  0.4498, -0.2999,  0.2021, -0.0113, -0.1465,  0.4015,\n",
       "            0.3677, -0.3725, -0.0950, -0.3800, -0.0117, -0.6041,  0.3532,  0.0574,\n",
       "           -0.2939, -0.0904, -0.5416, -0.6007,  0.2439, -0.0758,  0.1099, -0.4216,\n",
       "            0.0666,  0.0896, -0.3411,  0.3571,  0.0648,  0.0759,  0.0201,  0.1011,\n",
       "           -0.2539, -0.4739, -0.1510, -0.7167, -0.6430,  0.1678,  0.1721, -0.0016,\n",
       "            0.1140,  0.0410,  0.9000, -0.3071, -0.0625, -0.1626, -0.1940,  0.1531],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 1.0427,  0.8546,  1.0952,  0.9206,  0.6364,  1.0207,  1.3225,  0.8498,\n",
       "            0.9860,  0.6959,  0.8434,  1.6106,  1.2485,  1.4147,  1.0814,  1.6972,\n",
       "            0.8631,  0.7687,  0.9143,  0.8210,  1.2804,  0.7602,  0.6457,  1.1728,\n",
       "            1.1295,  1.0787,  0.6072,  0.5198,  1.2639,  1.5215,  0.7678, -0.0169,\n",
       "            0.7199,  1.2767,  1.1101,  2.1868,  1.0883,  1.4006,  0.3334,  0.7230,\n",
       "            1.4035,  0.9226,  0.7228,  1.0180,  1.4123,  0.7227,  0.9370,  0.8196,\n",
       "            0.2430,  0.9591,  1.2112,  1.5335,  1.0987,  1.1758,  1.0955,  1.0779,\n",
       "            0.7572,  1.0661,  1.4902,  0.9986,  0.9879,  0.9133,  0.8186,  1.0027,\n",
       "            0.9340,  0.9831,  0.8855,  0.9768,  0.8763,  0.3143,  1.2251,  1.0905,\n",
       "            0.5486,  1.1386,  0.5360,  1.1557,  0.6417,  1.2599,  1.0150,  1.3232,\n",
       "            1.2707,  1.3140,  1.2591,  1.9643,  1.1428,  1.1195,  0.8050,  0.4796,\n",
       "            0.9132,  1.0314,  0.6065,  1.4737,  1.5177,  1.1334,  1.3981,  0.8451,\n",
       "            1.2801,  1.6359,  0.9973,  1.1519,  0.7528,  0.7565,  0.4658,  1.0159,\n",
       "            0.6639,  1.2534,  0.9186,  0.2843,  0.2867,  1.0330,  0.4880,  0.7792,\n",
       "            1.3115,  1.3522,  0.2638,  1.1964,  1.0117,  1.5674,  1.1837,  1.3602,\n",
       "            0.4717,  0.8235,  0.5341,  1.7747,  0.8974,  1.1152,  0.5984,  0.8320,\n",
       "            1.2753,  1.4685,  0.6967,  0.4680,  0.5644,  0.3686,  0.8443,  0.7746,\n",
       "            1.2359,  1.3693,  0.5143,  1.8663,  1.1673,  0.7199,  0.9264,  1.1388,\n",
       "            1.4458,  0.5743,  1.0715,  1.0425,  1.3406,  0.6650,  0.9194,  1.0938,\n",
       "            0.9298,  0.7989,  0.8006,  0.9320,  0.4484,  0.9694,  0.3647,  0.7099,\n",
       "            0.6718,  0.9900,  0.5314,  1.1714,  1.0888,  1.1052,  1.7936,  1.0903,\n",
       "            1.4942,  1.6314,  1.0265,  0.4862,  0.7297,  0.6218,  1.5846,  0.9859,\n",
       "            1.5476,  1.1888,  1.2248,  0.9134,  1.3600,  0.8972,  0.8129,  1.6497,\n",
       "            1.0533, -0.0564,  0.7617,  0.5383,  1.0788,  0.8887,  1.2982,  1.1616,\n",
       "            0.5777,  0.4031,  0.8348,  0.8021,  0.4091,  1.2627,  1.5836,  0.9018,\n",
       "            1.4154,  1.2055,  1.1177,  0.2548,  0.7416,  0.8714,  1.0901,  0.5578,\n",
       "            1.2533,  0.4284,  0.9845,  0.7204,  0.7482,  0.9428,  1.0924,  0.6993,\n",
       "            0.7070,  1.3758,  1.3138,  0.9222,  1.1047,  1.2169,  1.2638,  1.5889,\n",
       "            1.2276,  0.8330,  1.3651,  0.5623,  0.7780,  0.9452,  1.2954,  0.9834,\n",
       "            1.2416,  1.2002,  1.5452,  0.9537,  1.2111,  1.4291,  1.1884,  1.4824,\n",
       "            0.3478,  0.5793,  0.0619,  1.2725,  1.1237,  1.1515,  1.4286,  1.4259,\n",
       "            0.9996,  1.5177,  0.3326,  1.3513,  0.7972,  0.5844,  1.4521,  1.1060],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 6.7322e-01,  1.8184e-02,  5.8130e-01, -9.0326e-02, -1.8015e-02,\n",
       "           -2.9980e-01, -3.3570e-01,  1.0754e-01, -2.4069e-03, -9.2986e-02,\n",
       "           -4.6255e-01, -4.5614e-01, -1.1243e-01, -4.2055e-01,  5.4431e-01,\n",
       "           -4.5076e-01, -2.6014e-01, -3.1323e-01,  5.7251e-01,  4.8925e-01,\n",
       "            2.7384e-01,  1.8906e-01,  2.8721e-01, -7.6116e-01,  7.1244e-02,\n",
       "            4.5079e-01, -5.1042e-01,  1.1606e-01, -2.0372e-01,  8.7902e-02,\n",
       "           -5.6520e-01, -2.6648e-01,  1.2587e-02, -2.8602e-01, -3.1222e-01,\n",
       "           -2.9661e-01,  4.3292e-01, -1.3181e-01, -1.7900e-01,  9.5579e-02,\n",
       "            2.7652e-01,  1.7687e-01,  8.7673e-02, -8.7859e-02, -4.6018e-01,\n",
       "            1.8977e-01, -1.9897e-01, -3.9776e-01, -2.6515e-01,  3.4051e-02,\n",
       "           -9.1046e-02,  5.3174e-01,  3.5095e-01,  2.2043e-01,  4.4632e-01,\n",
       "           -3.9731e-01,  1.9136e-01,  5.1438e-01, -4.1069e-02, -6.0201e-02,\n",
       "           -1.8952e-01,  4.1190e-01,  2.6572e-01, -4.8122e-01, -8.2711e-02,\n",
       "           -3.1523e-01, -1.2117e-01,  3.8946e-01,  2.7030e-02,  3.0737e-02,\n",
       "           -4.4835e-01,  3.7749e-01, -3.4775e-01, -1.0072e-02,  3.1783e-01,\n",
       "           -1.4081e-01, -1.2954e-01, -6.1458e-02, -3.2965e-01,  3.1336e-01,\n",
       "            2.5056e-01, -4.1638e-01,  5.0583e-02, -3.5417e-01,  2.9436e-02,\n",
       "            8.2905e-02, -1.4790e-01,  8.5306e-02,  2.6709e-02, -1.3709e-01,\n",
       "            1.8681e-02, -5.9540e-01, -8.8150e-02,  6.9330e-02,  2.1762e-01,\n",
       "           -3.6233e-01,  2.3829e-01, -9.3725e-02,  4.1163e-01,  1.4923e-01,\n",
       "           -3.0388e-01, -5.6038e-01,  1.6534e-01,  5.8751e-01, -6.5739e-01,\n",
       "           -3.6116e-01,  1.3616e-01, -4.4354e-01,  2.4714e-01,  7.1655e-01,\n",
       "            9.2703e-02,  6.1054e-01, -1.0915e-01, -2.7149e-03,  4.6636e-02,\n",
       "           -4.7701e-01,  1.8801e-01, -2.4490e-01,  1.6129e-01,  2.8222e-01,\n",
       "            2.8480e-01, -4.9916e-01,  3.7608e-01,  6.3828e-01, -2.6715e-01,\n",
       "           -1.7087e-02,  2.0754e-01,  1.9753e-01,  5.4929e-01, -1.6274e-02,\n",
       "           -1.1041e-01,  1.6871e-01, -3.9081e-01,  2.0593e-01, -1.6345e-01,\n",
       "           -4.5187e-01, -1.2168e-01,  3.7650e-01,  1.7080e-01, -1.3207e-01,\n",
       "           -3.9845e-01, -6.1092e-02, -3.6126e-02, -1.0489e-01,  4.6439e-01,\n",
       "           -1.0781e-01, -8.3549e-02, -1.8546e-02,  6.7863e-01,  9.1917e-02,\n",
       "            5.8231e-04, -3.3387e-01,  1.2748e-03, -2.0335e-01,  3.9203e-01,\n",
       "           -8.3466e-02,  3.1133e-01, -2.2298e-01, -1.9341e-01, -2.9516e-01,\n",
       "            3.3429e-01, -1.0687e-01,  1.7124e-01, -8.2014e-02,  4.5256e-01,\n",
       "            1.4285e-01,  3.1189e-02, -2.2446e-01, -7.0334e-02, -4.9453e-01,\n",
       "            4.5733e-01, -5.7551e-02, -2.9331e-01,  5.7661e-01,  6.5683e-02,\n",
       "            6.3872e-02,  4.7109e-01, -5.1342e-01,  4.6338e-01,  4.0012e-01,\n",
       "            4.9356e-01, -4.1754e-02,  3.5653e-01,  3.7910e-01, -2.3630e-01,\n",
       "           -9.4461e-02,  5.5501e-01, -3.2651e-01,  4.6269e-02, -3.8076e-01,\n",
       "           -3.3682e-02,  3.6209e-01, -1.5984e-02,  3.9413e-01, -1.5672e-01,\n",
       "           -2.7199e-01, -2.1766e-01,  7.8908e-02, -4.0006e-01,  4.6838e-01,\n",
       "            3.0505e-01,  9.3571e-02,  1.9977e-01,  8.4086e-02, -3.5851e-02,\n",
       "            1.0390e-01, -2.5117e-01,  1.5474e-01, -2.8576e-01, -3.1337e-01,\n",
       "           -2.9683e-01,  2.9947e-02,  2.1998e-01,  5.1481e-01,  4.3111e-01,\n",
       "            1.5863e-01, -1.1382e-01, -6.7694e-01,  1.8315e-01,  1.0445e-01,\n",
       "           -6.8322e-02,  3.7255e-01, -3.7175e-01, -1.8710e-01, -5.3598e-01,\n",
       "           -2.0272e-01,  2.4607e-01, -1.5503e-01,  1.3541e-01, -3.4625e-01,\n",
       "           -1.9518e-01, -3.9670e-01,  4.8583e-02,  2.1061e-01, -5.4868e-01,\n",
       "            1.2276e-01,  5.4266e-01, -4.5988e-01,  4.1332e-01,  4.5852e-01,\n",
       "            1.7212e-01, -2.1057e-01,  1.7711e-01,  1.0411e-01,  1.2343e-01,\n",
       "            3.7511e-01, -4.2229e-01, -3.5116e-01,  3.5492e-02,  7.0659e-02,\n",
       "           -1.4681e-01,  9.2743e-02, -4.7369e-01,  1.7268e-01,  1.0078e-01,\n",
       "           -3.9546e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.9721,  0.7973,  0.8334,  0.8243,  0.0349,  1.0690,  0.8422,  0.6465,\n",
       "            0.5982,  0.2674,  0.9501,  1.0528,  0.4512,  1.3715,  0.8718,  0.3517,\n",
       "            0.9876,  0.9863,  0.3408,  1.3284,  0.6764,  0.5758,  1.1576,  0.7238,\n",
       "            0.5708,  1.4517,  0.7632,  0.5959,  1.7620,  1.5859,  1.4411,  0.4875,\n",
       "            0.9447,  0.8252,  0.5677,  2.0652,  0.6073,  1.3975,  1.0485,  0.4962,\n",
       "            0.6914,  1.0858,  1.1038,  1.3399,  0.9979,  0.5546,  0.6761,  1.0594,\n",
       "            1.1294,  0.8317,  1.0116,  1.1552,  0.7875,  0.2171,  0.4754,  1.0171,\n",
       "            1.1852,  1.6552,  1.0682, -0.0059,  1.2065,  0.9497,  0.7062,  1.1793,\n",
       "            0.6062,  0.6588,  0.9984,  0.7008,  0.6003,  1.2154,  1.0997,  1.4874,\n",
       "            1.0342,  1.0660,  0.6128,  1.2640,  0.8424,  0.9050,  0.7171,  0.5071,\n",
       "            1.2753,  0.6533,  1.1095,  1.2175,  1.1319,  1.2297,  0.6463,  0.1997,\n",
       "            0.6773,  1.1133,  0.7651,  0.4248,  1.2760,  0.9302,  1.4323,  0.2512,\n",
       "            1.0945,  0.5404,  1.1278,  1.1880,  1.0866,  0.0453,  1.2263,  0.7562,\n",
       "            1.4770,  1.1195,  0.5316,  1.1140,  0.3862,  1.2199,  0.8791,  1.0178,\n",
       "            1.3433,  0.4928,  0.9043,  0.5435,  0.9358,  0.5666,  1.0384,  1.3619,\n",
       "            0.9123,  0.5711,  1.1443,  1.0579,  0.7634,  1.0360,  0.5706,  0.2034,\n",
       "            0.9320,  1.0287,  0.6962,  1.1631,  1.2163,  0.6296,  0.7587,  0.7358,\n",
       "            1.1510,  1.2960,  0.5293,  1.3488,  1.0160,  1.3439,  0.9678,  1.1683,\n",
       "            1.0924,  0.8653,  1.5909,  0.9711,  0.6865,  1.3264,  1.4749,  0.2888,\n",
       "            1.3025,  0.8653,  0.3032,  0.8528,  0.8834,  1.6351,  0.9168,  0.9496,\n",
       "            0.7325,  0.7400,  0.7308,  1.0465,  0.6039,  1.4264,  1.6580,  1.2480,\n",
       "            1.4029,  2.2426,  0.8620, -0.0054,  0.9939,  0.8156,  1.7334,  1.0838,\n",
       "            0.5879,  0.4979,  1.1199,  1.1505,  0.9300,  0.6811,  0.6114,  1.0547,\n",
       "            0.3399,  0.9557,  0.8165,  0.8365,  1.1448,  1.2067,  1.1498,  1.2944,\n",
       "            1.0503,  1.5101,  1.4081,  0.2339,  1.5334,  1.3665,  1.2825,  1.3058,\n",
       "            0.1728,  1.4883,  0.4846,  0.1674,  0.6690,  0.6615,  1.0282,  0.6325,\n",
       "            1.3116,  0.6947,  0.9518,  0.6310,  1.0555,  0.6009,  0.7116,  0.7697,\n",
       "            0.3911,  1.0457,  1.4511,  1.0268,  1.7533,  1.2484,  0.8742,  2.0268,\n",
       "            0.9329,  0.4134,  0.7877,  0.9934,  0.6046,  0.9486,  1.1227,  0.7902,\n",
       "            1.4537,  0.8313,  0.9977,  0.9839,  0.6245,  0.5476,  1.6434,  1.0006,\n",
       "            1.3620,  1.0524,  0.2181,  1.3078,  0.4159,  0.7870,  1.3068,  1.6231,\n",
       "            1.1655,  1.3189,  0.3719,  1.3953,  0.4410,  0.4187,  1.3363,  0.7538],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 3.6238e-01,  1.3797e-01,  3.8694e-02,  2.1764e-01, -3.5009e-02,\n",
       "           -5.4902e-01,  4.3327e-01, -3.2118e-01,  3.1643e-01,  1.4856e-02,\n",
       "           -6.2549e-03, -1.6129e-02,  9.4486e-02, -4.4404e-01, -1.8684e-01,\n",
       "           -5.2148e-02,  3.5659e-01,  5.9490e-02, -4.0570e-02,  2.4410e-01,\n",
       "           -2.6664e-02,  1.4773e-01, -4.3057e-01,  3.2351e-01,  9.3189e-02,\n",
       "            9.7714e-03,  1.2658e-01,  2.9321e-01,  1.4483e-02, -4.1808e-02,\n",
       "           -1.5505e-02, -1.1886e-02,  6.8186e-02, -4.1574e-02,  1.1987e-01,\n",
       "            3.9629e-02,  2.5769e-01, -3.9253e-01,  1.6781e-04,  1.8247e-01,\n",
       "            4.9223e-02, -3.0045e-01,  5.6192e-02, -9.5774e-02,  2.2874e-01,\n",
       "            2.0696e-01,  5.8452e-02,  4.2899e-04, -1.6841e-01,  2.5230e-01,\n",
       "           -1.0999e-01,  8.7989e-02, -9.7591e-02, -2.9708e-02,  1.0417e-01,\n",
       "            2.8916e-01,  4.4466e-02,  4.0725e-01, -6.7337e-02, -1.3543e-01,\n",
       "           -1.8303e-01, -2.1290e-01, -9.4738e-02, -7.8919e-02, -1.4717e-01,\n",
       "           -3.4435e-01, -1.6946e-01,  1.4367e-01,  2.4512e-01, -1.8619e-01,\n",
       "            4.7408e-02, -2.8435e-02,  1.1870e-01,  6.5577e-02, -2.3236e-03,\n",
       "            1.2189e-01,  1.2302e-01, -2.4986e-01,  1.4266e-01, -1.4666e-01,\n",
       "            5.7714e-01,  1.9361e-01, -2.1337e-01, -2.1015e-02,  4.7423e-01,\n",
       "           -4.0112e-01,  1.0902e-01,  1.9368e-01,  6.7718e-02,  1.0594e-02,\n",
       "            5.8609e-01,  2.9141e-01,  2.2676e-01,  3.8123e-02,  3.1532e-01,\n",
       "            1.6922e-01, -1.7222e-01, -8.0697e-02, -1.0773e-01,  9.6823e-02,\n",
       "           -8.4106e-03,  3.0344e-01,  2.4495e-01,  4.1845e-02,  2.9865e-01,\n",
       "            9.2914e-02,  4.2028e-01,  2.5624e-01,  2.9060e-01, -2.2102e-02,\n",
       "            3.6403e-01,  2.4016e-01,  2.1086e-01,  6.1426e-02, -1.0285e-01,\n",
       "            9.5253e-02,  2.1909e-01, -9.4296e-02,  2.1975e-01, -1.6412e-01,\n",
       "            5.6801e-02,  2.5646e-01, -8.5975e-02, -1.4159e-01,  2.7686e-01,\n",
       "           -3.5984e-02,  2.0323e-01, -1.1572e-01,  1.2947e-01,  2.7423e-01,\n",
       "           -1.4162e-01, -2.2935e-01, -3.1102e-01, -1.2332e-01, -7.4736e-02,\n",
       "           -1.2756e-02,  2.2839e-01,  2.0443e-01,  1.9989e-01, -5.4012e-02,\n",
       "            1.3531e-01, -2.3737e-01, -2.0038e-01, -2.2672e-01,  1.3711e-02,\n",
       "            1.2043e-01, -8.1332e-02, -3.0550e-01, -4.8765e-02,  6.8687e-06,\n",
       "           -5.4592e-02, -3.3629e-01,  4.1662e-02, -4.6018e-01, -1.4198e-01,\n",
       "           -2.3997e-01,  3.2123e-01,  2.7404e-02, -4.6152e-01,  2.9728e-02,\n",
       "            2.6010e-01, -9.8484e-02, -4.4700e-01, -1.2968e-02, -1.4232e-01,\n",
       "           -4.3421e-02,  4.2064e-03, -2.6948e-01, -1.1682e-01, -2.6437e-01,\n",
       "           -2.7542e-01, -4.5993e-01, -1.2181e-01,  4.4184e-01,  1.1889e-01,\n",
       "            2.7830e-02,  1.9095e-01,  7.1335e-02, -5.6399e-01,  8.9260e-02,\n",
       "            5.3903e-02,  1.2203e-01, -6.4885e-02,  1.3206e-01, -1.5542e-01,\n",
       "           -1.4725e-02, -3.6365e-01,  3.7225e-01, -1.5586e-01,  2.1106e-01,\n",
       "           -1.5086e-01,  1.3854e-01,  1.0742e-01, -3.3412e-01, -1.8415e-02,\n",
       "           -4.4059e-01, -8.6649e-02,  3.8132e-02, -1.9062e-01,  2.3810e-01,\n",
       "            4.2099e-01,  8.0775e-02,  2.0824e-01,  1.9128e-01, -1.5912e-01,\n",
       "            1.4585e-02, -9.8378e-02, -2.0096e-01, -1.6588e-01,  1.3116e-01,\n",
       "           -1.8043e-01,  1.7357e-02, -8.5097e-02,  4.8945e-02, -2.4292e-01,\n",
       "            2.2697e-02,  1.4322e-01,  1.7610e-01,  4.6851e-01, -1.5086e-01,\n",
       "            1.1815e-01,  1.4857e-01,  3.0570e-01, -1.8190e-02, -2.4268e-01,\n",
       "            1.1809e-01, -5.3294e-01, -8.2049e-02, -3.6825e-02, -5.0922e-01,\n",
       "           -1.7449e-01,  2.0111e-01,  2.2485e-01,  1.3701e-01, -9.1853e-02,\n",
       "            8.4224e-02,  1.6650e-01, -2.6166e-01,  1.0733e-02, -4.1141e-02,\n",
       "            1.2890e-01,  1.6970e-03, -8.0788e-02, -4.3401e-01,  1.4594e-01,\n",
       "           -3.4878e-01,  9.2837e-03, -7.9444e-02, -8.6021e-02,  1.7298e-01,\n",
       "           -1.9765e-01, -1.4599e-01,  1.1372e-01,  2.0103e-01,  1.1773e-01,\n",
       "           -1.5309e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.4857, -0.0360,  0.0300,  ..., -0.4856, -0.4151, -0.3132],\n",
       "           [ 0.2392, -0.4008,  0.4527,  ..., -0.2092,  0.1698,  0.1001],\n",
       "           [-0.3730,  0.1673, -0.2352,  ...,  0.2148, -0.2592, -0.1544],\n",
       "           ...,\n",
       "           [ 0.2434,  1.0094,  0.1202,  ..., -0.2891, -0.5757,  0.0529],\n",
       "           [ 0.2318, -0.2375,  0.0151,  ...,  0.1202,  0.0576, -0.0177],\n",
       "           [-0.3145,  0.4439,  0.1027,  ...,  0.0171, -0.0329, -0.0191]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0424, -0.0979,  0.1686, -0.0977,  0.2458, -0.2667, -0.2495,  0.3315,\n",
       "           -0.2935,  0.0721,  0.1464, -0.1162, -0.1007,  0.2420,  0.0253,  0.0593,\n",
       "            0.1506,  0.0229, -0.2717, -0.0095,  0.0436,  0.3760,  0.2642,  0.2641,\n",
       "            0.0167,  0.1639,  0.1957,  0.2620,  0.1265, -0.3275, -0.2129,  0.1024,\n",
       "            0.3581, -0.0536,  0.2476, -0.3607,  0.2038,  0.5661, -0.4760,  0.6152,\n",
       "           -0.1526, -0.4056,  0.0781, -0.6687,  0.1388,  0.0950, -0.0915, -0.3512,\n",
       "            0.1096, -0.3492, -0.2339,  0.3844,  0.2333, -0.3416, -0.2804, -0.1676,\n",
       "           -0.2889,  0.0080,  0.3123, -0.2779,  0.1049,  0.4393,  0.2208,  0.2358,\n",
       "           -0.1155, -0.1829, -0.2547, -0.4844, -0.1575, -0.1676, -0.3429, -0.3039,\n",
       "           -0.2748, -0.2586,  0.4667,  0.3555, -0.5749, -0.1589,  0.0751,  0.2317,\n",
       "           -0.0640,  0.0475,  0.1828, -0.3671,  0.2553,  0.2347,  0.1173,  0.2036,\n",
       "            0.1214,  0.1360, -0.1071,  0.0066,  0.1019, -0.2216,  0.4526,  0.3297,\n",
       "            0.5869,  0.3850,  0.2713,  0.1840, -0.4640,  0.3845, -0.3689,  0.4426,\n",
       "           -0.7883, -0.4017, -0.2085, -0.2189, -0.6338, -0.8276, -0.6325, -0.2569,\n",
       "           -0.0824, -0.4590,  0.1911,  0.4361, -0.1508, -0.1543, -0.1321, -0.3469,\n",
       "           -0.2581, -0.5830,  0.2420,  0.4595,  0.0017,  0.4382, -0.6140, -0.5846,\n",
       "            0.2057, -0.0742,  0.1211, -0.0437, -0.2310, -0.3816, -0.1172, -0.0450,\n",
       "           -0.0153, -0.0845, -0.0349, -0.0980, -0.0618, -0.0857, -0.1216,  0.0051,\n",
       "           -0.0664,  0.1337,  0.0465,  0.2582, -0.0699,  0.2037,  0.2044, -0.4560,\n",
       "           -0.0784,  0.0714, -0.0441, -0.0355,  0.2024, -0.3964,  0.0443,  0.1876,\n",
       "            0.0128, -0.1205,  0.0607, -0.0133, -0.0144, -0.2547, -0.0760, -0.0682,\n",
       "           -0.2099,  0.1149,  0.0221, -0.3282,  0.0258,  0.0010, -0.0897,  0.0721,\n",
       "           -0.1935,  0.0114,  0.0304,  0.1909, -0.1680, -0.3816,  0.1145, -0.0962,\n",
       "           -0.2378, -0.1605, -0.0988, -0.0789, -0.0834,  0.3023,  0.0896,  0.0757,\n",
       "           -0.3599,  0.1095, -0.3707, -0.2165, -0.1268, -0.2816, -0.3607, -0.3291,\n",
       "           -0.2405,  0.2830, -0.2733, -0.4732, -0.3650, -0.2324, -0.3616,  0.0073,\n",
       "            0.0213,  0.1624,  0.2498, -0.0346, -0.0462, -0.2102, -0.4386, -0.5126,\n",
       "            0.2089,  0.3010, -0.6163, -0.2971, -0.4292,  0.4570, -0.6055,  0.2757,\n",
       "            0.1091,  0.6811, -0.3363,  0.1925, -0.1393, -0.1372,  0.6701,  0.0241,\n",
       "            0.6205, -0.4874, -0.2247,  0.2388, -0.3321,  0.6035, -0.7942, -0.1696,\n",
       "            0.4692,  0.6332,  0.7547, -0.2776, -0.5447, -0.2560,  0.5987, -0.0306,\n",
       "            0.0964,  0.2422, -0.1354, -0.2948, -0.1742,  0.6650, -0.1334,  0.1521],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0900, -0.2248,  0.0359,  ..., -0.4786, -0.0322,  0.0935],\n",
       "           [-0.2759, -0.0742,  0.5425,  ...,  0.1232, -0.2950,  0.0884],\n",
       "           [ 0.0224,  0.3075, -0.3727,  ...,  0.1280, -0.1585, -0.3156],\n",
       "           ...,\n",
       "           [ 0.4331, -0.2028,  0.4799,  ..., -0.4604, -0.3762, -0.8584],\n",
       "           [-0.0428, -0.2932, -0.6169,  ..., -0.1733, -0.2093,  0.1203],\n",
       "           [ 0.1774,  0.3303,  0.1697,  ...,  0.5674,  0.1835, -0.1323]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0015,  0.0282, -0.0799,  0.0528, -0.0452,  0.0688,  0.0623, -0.0709,\n",
       "            0.0530, -0.0429, -0.0775,  0.0371,  0.0137, -0.0751, -0.0120, -0.0405,\n",
       "           -0.0770,  0.0330,  0.0443,  0.0017,  0.0129, -0.0636, -0.0583, -0.0268,\n",
       "           -0.0240, -0.0437, -0.0466, -0.0246, -0.0145,  0.0576,  0.0580, -0.0284,\n",
       "            0.0349, -0.0142,  0.0214, -0.0468,  0.0470,  0.0258, -0.0614,  0.0497,\n",
       "            0.0287, -0.0455, -0.0194, -0.0873, -0.0191,  0.0240,  0.0061, -0.0384,\n",
       "            0.0330, -0.0474, -0.0013,  0.0413,  0.0146, -0.0368, -0.0303,  0.0352,\n",
       "           -0.0320, -0.0439, -0.0074, -0.0334,  0.0096,  0.0265, -0.0015,  0.0290,\n",
       "            0.0310,  0.0267, -0.0214, -0.0185, -0.0184,  0.0644, -0.0520,  0.0206,\n",
       "           -0.0485,  0.0654, -0.0361,  0.0280,  0.0542, -0.0557, -0.0770,  0.0068,\n",
       "           -0.0639, -0.0666,  0.0654,  0.0357, -0.0816,  0.0258, -0.0466, -0.0657,\n",
       "            0.0600, -0.0532,  0.0295,  0.0112,  0.0869,  0.0444, -0.0103,  0.0243,\n",
       "           -0.0395, -0.0166, -0.0249, -0.0038,  0.0120, -0.0292,  0.0503, -0.0621,\n",
       "            0.0261,  0.0402,  0.0442,  0.0007,  0.0259,  0.0349,  0.0391,  0.0093,\n",
       "            0.0035,  0.0252, -0.0564, -0.0477,  0.0114,  0.0322,  0.0243,  0.0371,\n",
       "            0.0320,  0.0484, -0.0391, -0.0188,  0.0336, -0.0293,  0.0269,  0.0531,\n",
       "           -0.0066,  0.0311,  0.0151,  0.0125,  0.0250,  0.0201, -0.0084,  0.0200,\n",
       "           -0.0317, -0.0217, -0.0445, -0.0417, -0.0330,  0.0094,  0.0156,  0.0289,\n",
       "            0.0512,  0.0314, -0.0124,  0.0075, -0.0044, -0.0076, -0.0073, -0.0327,\n",
       "           -0.0033, -0.0143, -0.0233,  0.0208,  0.0423,  0.0135, -0.0153, -0.0104,\n",
       "            0.0062, -0.0212, -0.0063,  0.0010,  0.0225, -0.0098, -0.0092, -0.0306,\n",
       "           -0.0112,  0.0160,  0.0177,  0.0131, -0.0181,  0.0108,  0.0189,  0.0112,\n",
       "            0.0144, -0.0061, -0.0238,  0.0048,  0.0202, -0.0031,  0.0061, -0.0195,\n",
       "           -0.0028,  0.0112,  0.0334,  0.0038, -0.0040,  0.0055,  0.0188, -0.0337,\n",
       "           -0.0201,  0.0021, -0.0253, -0.0043, -0.0095, -0.0213, -0.0192, -0.0205,\n",
       "           -0.0198,  0.0247, -0.0234, -0.0214, -0.0219, -0.0140, -0.0236, -0.0047,\n",
       "            0.0053,  0.0128,  0.0236,  0.0005,  0.0039, -0.0156, -0.0265, -0.0292,\n",
       "            0.0139,  0.0237, -0.0322, -0.0148, -0.0208,  0.0193, -0.0331,  0.0130,\n",
       "           -0.0236,  0.0377,  0.0198, -0.0033, -0.0195,  0.0270,  0.0151,  0.0016,\n",
       "            0.0154, -0.0126, -0.0133, -0.0050, -0.0087,  0.0272, -0.0356,  0.0199,\n",
       "            0.0346,  0.0276,  0.0429,  0.0034, -0.0330,  0.0021,  0.0124,  0.0488,\n",
       "            0.0540, -0.0032, -0.0055,  0.0022,  0.0011,  0.0363,  0.0483, -0.0264],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.3880, -0.3709, -0.2321,  ...,  0.4349, -0.0363,  0.3811],\n",
       "           [-0.1370, -0.4741,  0.0573,  ..., -0.0629, -0.0754,  0.2713],\n",
       "           [ 0.2463,  0.0082,  0.1601,  ..., -0.1930, -0.1219, -0.1714],\n",
       "           ...,\n",
       "           [ 0.3403,  0.2091,  0.6323,  ..., -0.1741, -0.1172, -0.4075],\n",
       "           [-0.4304, -0.2812, -0.5731,  ...,  0.2967,  0.1022,  0.6599],\n",
       "           [ 0.1127,  0.0786,  0.4201,  ..., -0.0504, -0.0095, -0.0975]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-4.8091e-01, -2.0705e-01,  3.4923e-01, -5.1754e-01,  3.1214e-01,\n",
       "           -1.5908e-01, -1.1472e-02, -5.3583e-01, -1.5710e-01,  3.0478e-01,\n",
       "            4.2988e-01,  2.1087e-01, -2.3714e-01, -1.1703e-01, -4.0537e-01,\n",
       "           -1.0327e-01,  7.5812e-02, -5.4375e-01,  4.7997e-01,  2.4650e-01,\n",
       "           -2.4716e-01, -4.2236e-01, -8.6620e-02, -2.8794e-01, -1.2852e-01,\n",
       "           -1.6418e-01,  2.8651e-01,  1.3573e-01,  1.3172e-01,  4.1689e-01,\n",
       "           -2.1568e-01, -1.0520e-01, -1.7074e-01,  8.1827e-02,  1.5531e-01,\n",
       "            2.4740e-01,  5.6992e-03,  1.1578e-01,  1.9397e-01,  1.9859e-01,\n",
       "            2.3314e-01,  3.5126e-02,  2.8381e-01, -1.9108e-01,  1.1648e-01,\n",
       "           -1.8841e-01,  1.6473e-01, -1.7246e-01,  1.3655e-01, -8.7613e-02,\n",
       "           -1.7143e-01,  3.4987e-02, -4.2014e-03, -6.6914e-02, -2.8491e-02,\n",
       "            2.2242e-01,  8.7800e-02,  1.9164e-01,  6.4254e-02,  6.5498e-02,\n",
       "            1.4759e-01, -1.0767e-01, -1.0270e-01,  8.6379e-02,  2.7111e-03,\n",
       "            2.4614e-01, -1.0927e-01,  7.5765e-02,  1.1056e-01, -6.4950e-02,\n",
       "            4.9125e-02,  3.8449e-01, -5.6091e-01,  2.1458e-01, -2.9108e-01,\n",
       "           -1.8357e-01,  2.9746e-01,  3.9289e-01,  4.6130e-01,  2.5431e-01,\n",
       "            3.6352e-02,  2.1617e-01, -5.0582e-01, -2.3660e-01, -3.9683e-01,\n",
       "           -1.6080e-02,  5.0101e-02, -2.0879e-01,  2.4293e-01,  2.3451e-01,\n",
       "            1.1571e-01, -2.5859e-01,  5.3998e-01, -2.2441e-01, -3.1310e-01,\n",
       "           -2.8248e-01, -4.3393e-01, -2.5408e-01, -7.3954e-02, -2.6724e-01,\n",
       "           -3.8061e-01,  4.9171e-02, -1.9782e-01,  3.2815e-02,  1.0704e-01,\n",
       "            6.2751e-02,  3.1226e-01,  1.8283e-01, -7.7337e-02,  3.0984e-01,\n",
       "            3.9660e-02, -1.1300e-01,  1.1656e-01, -1.4092e-01, -9.7263e-02,\n",
       "           -1.6590e-01,  1.2495e-01,  3.4595e-01,  2.4085e-01, -2.3972e-01,\n",
       "            4.0734e-01, -1.4324e-01, -1.6647e-01,  2.9089e-01,  9.2507e-02,\n",
       "           -2.5512e-01,  1.5582e-01,  2.4920e-01,  2.4575e-02, -1.5146e-02,\n",
       "           -9.5494e-02,  3.9415e-01, -1.8254e-01, -2.5953e-01, -4.1221e-01,\n",
       "           -4.6422e-01, -4.4398e-01, -3.5504e-02,  3.4403e-01, -8.7835e-02,\n",
       "           -5.1011e-02, -2.7300e-01, -6.4403e-02, -8.8153e-02,  1.3031e-01,\n",
       "            1.0247e-01,  3.2449e-01,  1.4210e-01,  3.9049e-01, -1.9490e-01,\n",
       "            1.7386e-01, -3.8890e-01, -2.1781e-01,  3.1424e-01,  2.7260e-01,\n",
       "            4.6994e-01,  6.1524e-02,  2.7234e-01,  5.4807e-02,  2.7355e-01,\n",
       "            2.4975e-01, -1.3413e-02,  2.0911e-01, -4.2730e-01, -3.1316e-01,\n",
       "           -3.8202e-02,  2.8813e-01,  3.8790e-01,  1.6500e-02, -4.5970e-02,\n",
       "            3.4251e-01, -2.1407e-01,  1.3484e-01,  1.2545e-01,  5.0126e-01,\n",
       "            2.2858e-01, -2.5344e-01,  1.1791e-01, -2.1629e-01,  1.3026e-02,\n",
       "           -1.5806e-01,  5.9873e-02, -1.6805e-01, -2.0754e-01,  6.5458e-02,\n",
       "           -3.1231e-01, -9.6588e-02,  5.1179e-01,  2.9343e-02, -3.4174e-01,\n",
       "           -9.5914e-02, -1.2585e-01,  9.8477e-02, -1.6125e-01, -1.6463e-01,\n",
       "           -7.4475e-02,  5.2673e-02, -2.2367e-01, -1.0994e-01, -2.0938e-02,\n",
       "           -1.5834e-01, -1.5289e-01,  1.3743e-01, -1.7312e-01,  4.3632e-02,\n",
       "            2.5992e-01, -2.5782e-01,  2.3614e-01,  1.2579e-01, -1.6056e-01,\n",
       "            7.7768e-03, -3.4554e-02, -5.6747e-02,  1.8898e-01, -5.8172e-02,\n",
       "           -2.6212e-01,  2.4734e-01, -1.0571e-01, -1.0164e-01,  2.4681e-01,\n",
       "            3.2277e-02, -1.7140e-02, -1.1026e-01, -9.3387e-04, -4.8648e-01,\n",
       "           -3.5533e-01,  5.6188e-01, -1.5760e-01, -3.8065e-01,  7.0070e-01,\n",
       "            2.1601e-01, -6.6121e-01, -3.6756e-01,  6.9390e-01,  4.8574e-01,\n",
       "           -4.6660e-01,  5.6927e-01,  7.5270e-01, -1.0840e-01, -6.5341e-01,\n",
       "            6.7314e-01,  6.3159e-01,  4.9417e-01,  5.9017e-01, -7.6013e-01,\n",
       "            5.4227e-01,  7.9383e-01,  4.7023e-01,  2.7589e-01, -4.5579e-01,\n",
       "           -4.4279e-01, -5.7084e-04, -7.7438e-02,  2.4467e-01, -1.8948e-01,\n",
       "            1.1483e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.3581, -0.6498,  0.1591,  ...,  0.4528, -0.4070,  0.1624],\n",
       "           [ 0.0076,  0.4197,  0.1973,  ..., -0.4675,  0.0151, -0.3923],\n",
       "           [-0.7810, -0.3872,  0.4123,  ...,  0.0306, -0.0122,  0.0281],\n",
       "           ...,\n",
       "           [-0.4385,  0.0875,  0.2801,  ...,  0.2061, -0.5157, -0.1998],\n",
       "           [-0.6004, -0.6388,  0.2298,  ...,  0.3086, -0.3444,  0.1250],\n",
       "           [ 0.2059,  0.4735,  0.1802,  ...,  0.1867, -0.1097,  0.0102]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.2794, -0.2881,  0.8614, -0.1986,  0.1713,  0.0123, -0.8110,  0.2232,\n",
       "            0.3523, -0.1321, -0.2524, -0.4179, -0.3509, -0.2422,  0.6402, -0.5479,\n",
       "            0.3600, -0.2881,  0.5514,  0.7588,  0.2887,  0.4820,  0.1527, -0.7364,\n",
       "           -0.0292,  0.1651, -0.3910, -0.2871, -0.3414, -0.0698, -0.8176,  0.0720,\n",
       "           -0.0893, -0.2438, -0.4219, -0.0856,  0.2243, -0.1122,  0.1188, -0.0091,\n",
       "            0.4863,  0.0721,  0.3035, -0.2218, -0.7192,  0.0729, -0.3949, -0.1357,\n",
       "           -0.0917,  0.0302,  0.2732,  0.8279,  0.7291,  0.8280,  0.4821, -0.4612,\n",
       "            0.3555,  0.4322,  0.0736, -0.4158, -0.5052,  0.1898,  0.1335, -0.6165,\n",
       "            0.3544, -0.2585, -0.1486,  0.4021,  0.0086, -0.1990, -0.4526,  0.3352,\n",
       "           -0.2804, -0.3799,  0.4913, -0.0143, -0.1784, -0.2541, -0.2212,  0.5626,\n",
       "            0.1527, -0.8092, -0.1044, -0.3734, -0.1370, -0.0275, -0.1659,  0.0096,\n",
       "           -0.0923, -0.1054, -0.0600, -1.0172, -0.3480, -0.2012,  0.1933, -0.5799,\n",
       "            0.4214, -0.5329,  0.2450,  0.3528, -0.2751, -0.4694, -0.0533, -0.0821,\n",
       "           -0.8093, -0.5440,  0.3661, -0.3070,  0.2324,  0.8268,  0.4587,  0.4087,\n",
       "           -0.3576, -0.1777, -0.0882, -0.6515,  0.5315, -0.2748,  0.2822,  0.1736,\n",
       "            0.0201, -0.6077,  0.3486,  0.6635, -0.3507,  0.0611,  0.4363,  0.2404,\n",
       "            0.5338, -0.5224, -0.1508,  0.0744, -0.1271,  0.0590,  0.1440, -0.4613,\n",
       "           -0.0374,  0.6407, -0.1371, -0.7180, -0.1645, -0.3654, -0.0355, -0.3178,\n",
       "            0.5741, -0.6741,  0.1878, -0.2249,  0.9947,  0.0783,  0.0228,  0.0569,\n",
       "            0.2737, -0.1671,  0.6706, -0.4301,  0.0739, -0.1605, -0.0925, -0.3771,\n",
       "            0.1445, -0.6495, -0.0469, -0.5749,  0.7168,  0.0462, -0.2844, -0.3897,\n",
       "           -0.1485, -0.8203,  0.3758, -0.2050, -0.5637,  0.5690, -0.1541,  0.0588,\n",
       "            0.9743, -0.8299,  0.3732,  0.3077,  0.8011, -0.4308,  0.5259,  0.5583,\n",
       "           -0.4912, -0.1747,  0.6526, -0.4150,  0.2119, -0.6026,  0.1846,  0.1094,\n",
       "            0.1594,  0.3102, -0.1928, -0.4408, -0.0435,  0.1431, -0.5609,  0.5805,\n",
       "            0.8639,  0.0649,  0.4810,  0.2726,  0.1149,  0.1520, -0.1560,  0.0423,\n",
       "            0.0365, -0.1010, -0.2694,  0.3006, -0.0142,  0.7999,  0.3447,  0.1493,\n",
       "            0.0801, -0.7027,  0.2839,  0.2443,  0.3256,  0.6346, -0.4243, -0.0853,\n",
       "           -0.7691, -0.0374,  0.2140,  0.1354,  0.3664, -0.3863, -0.1857, -0.4042,\n",
       "            0.3138,  0.0527, -0.7435,  0.1248,  0.7871, -0.7894,  0.7006,  0.5279,\n",
       "            0.1507, -0.3132, -0.2112,  0.3200,  0.3994,  0.7660, -0.5830, -0.5712,\n",
       "            0.0513,  0.0129,  0.3442,  0.2826, -0.6170,  0.1183,  0.2524, -0.5611],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.1501, -0.1613,  0.3896,  ...,  0.1417,  0.0895,  0.1663],\n",
       "           [ 0.0013,  0.3818, -0.4812,  ...,  0.0240,  0.0467, -0.0788],\n",
       "           [-0.3380, -0.1030, -0.1721,  ..., -0.2615, -0.2464, -0.2142],\n",
       "           ...,\n",
       "           [-0.6931, -0.1515, -0.4199,  ..., -0.1399, -0.2438, -0.1769],\n",
       "           [-0.3679,  0.2215, -0.2343,  ..., -0.3733,  0.2769,  0.2155],\n",
       "           [-0.1119, -0.3655, -0.2276,  ..., -0.0416,  0.0363, -0.1419]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 1.9581e-01, -4.6906e-01, -4.3599e-01, -1.9615e-01,  5.1217e-02,\n",
       "           -2.9306e-01, -2.7281e-01, -1.4924e-01, -8.4120e-02, -1.4332e-01,\n",
       "           -3.9527e-01, -3.4011e-01, -1.0694e-01,  3.1976e-01, -7.2139e-03,\n",
       "           -3.2286e-01,  2.9669e-01,  1.8330e-01, -2.0911e-01, -1.1675e-01,\n",
       "           -7.5886e-02, -2.4440e-01, -4.9940e-01, -1.7787e-01, -1.5310e-01,\n",
       "           -2.7548e-01, -3.8656e-01, -7.7306e-01,  2.7602e-01, -5.7936e-01,\n",
       "            2.1724e-01, -2.8731e-01, -3.7389e-01, -3.7037e-01, -4.9386e-01,\n",
       "           -3.3269e-01,  4.2691e-01, -6.1001e-01, -7.8275e-02,  4.5685e-02,\n",
       "           -1.1923e-04, -2.6204e-01, -2.7084e-01, -7.4726e-02, -3.1810e-01,\n",
       "           -2.0353e-01,  1.7585e-01,  1.5537e-01, -2.5437e-01, -2.8034e-01,\n",
       "           -8.0555e-02, -7.8073e-04,  2.9705e-01, -3.1351e-01,  5.7780e-02,\n",
       "            4.3615e-03,  2.6420e-01, -4.8581e-02, -6.7619e-01,  2.4049e-01,\n",
       "           -4.2274e-01, -3.1729e-01, -4.9057e-01, -4.4095e-01], device='cuda:0',\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.6071, -0.0542,  0.1912,  ...,  0.1313,  0.2956,  0.1360],\n",
       "           [ 0.0552, -0.0632,  0.5110,  ...,  0.2593,  0.1086, -0.2302],\n",
       "           [ 0.1802, -0.0464, -0.2076,  ..., -0.1875, -0.6307, -0.1345],\n",
       "           ...,\n",
       "           [ 0.4066,  0.2115,  0.4176,  ..., -0.0625,  0.2127,  0.0716],\n",
       "           [-0.1398, -0.3403, -0.2603,  ...,  0.1155, -0.0933, -0.0527],\n",
       "           [-0.4706, -0.2698,  0.2080,  ..., -0.0248,  0.0106, -0.4056]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0467,  0.4531, -0.6321,  0.2159, -0.7470, -0.2562,  0.1786,  0.1140,\n",
       "           -0.2171, -0.4285, -0.0523, -0.2992, -0.4083, -0.2367,  0.1216,  0.3101,\n",
       "            0.3955, -0.2333, -0.0883, -0.3677,  0.0629,  0.3412,  0.1296, -0.4228,\n",
       "            0.1104,  0.5028, -0.4353, -0.1251, -0.1005, -0.0065, -0.1926,  0.1410,\n",
       "            0.2721,  0.0556, -0.2309, -0.0859, -0.0285, -0.5152, -0.0853, -0.2971,\n",
       "           -0.0704,  0.6656, -0.2987, -0.2680, -0.2782,  0.3949,  0.0478, -0.3847,\n",
       "           -0.0607,  0.1508, -0.3585, -0.0095, -0.0193,  0.1189, -0.5727, -0.1724,\n",
       "            0.2042, -0.8200,  0.0921, -0.1423, -0.1440,  0.5606,  0.2444, -0.4648,\n",
       "            0.3787,  0.2497, -0.0683, -0.0671, -0.1556,  0.1912,  0.0150,  0.8890,\n",
       "           -0.3547, -0.4748,  0.3470,  0.1447,  0.2419,  0.0914, -0.1407,  0.5027,\n",
       "           -0.7998, -0.4715, -0.1422, -0.0695, -0.1377,  0.5630, -0.0432, -0.0943,\n",
       "           -0.0776,  0.0728,  0.1315, -0.3917,  0.0851,  0.4058,  0.2017,  0.2366,\n",
       "            0.4519, -0.0518, -0.0956, -0.1141,  0.2378,  0.1841, -0.2775, -0.0759,\n",
       "           -0.7721,  0.0832, -0.2048,  0.2787, -0.4569,  0.3892, -0.3481,  0.6600,\n",
       "            0.0650, -0.0209, -0.4782, -0.2159, -0.0342, -0.6586, -0.5434,  0.2384,\n",
       "            0.3326, -0.1617, -0.3680, -0.0251, -0.1780,  0.0285,  0.2554,  0.2487,\n",
       "            0.1001, -0.4728,  0.1449, -0.4874, -0.5551,  0.1658, -0.4214, -0.4059,\n",
       "           -0.3892,  0.7964,  0.1324,  0.4203,  0.0803,  0.1905,  0.0418,  0.0392,\n",
       "           -0.6063,  0.4016, -0.2753,  0.2440,  0.2508, -0.1082,  0.3276,  0.3623,\n",
       "            0.4554, -0.1776, -0.0332,  0.0632, -0.1756,  0.1889,  0.5006, -0.0975,\n",
       "           -0.8977,  0.6387, -0.0914, -0.3398, -0.2335,  0.0172,  0.2256, -0.2504,\n",
       "           -0.4724, -0.7367, -0.2628, -0.0397,  0.1848, -0.1063,  0.0823, -0.0861,\n",
       "           -0.0390, -0.1137,  0.0020, -0.0629,  0.2397, -0.0100,  0.2981, -0.1014,\n",
       "            0.2092,  0.0681,  0.4981,  0.1629,  0.0422, -0.4820,  0.1736, -0.0071,\n",
       "           -0.4495,  0.3094,  0.0962, -0.1838, -0.3825, -0.2717, -0.3380,  0.3852,\n",
       "           -0.0532,  0.1398, -0.2900,  0.2567,  0.2539,  0.0373, -0.4623,  0.5176,\n",
       "           -0.0171, -0.5016, -0.3597, -0.2265, -0.0375,  0.0734, -0.1398,  0.0980,\n",
       "           -0.1132, -0.5802,  0.2655, -0.6000,  0.2133,  0.1389,  0.0027, -0.3741,\n",
       "           -0.0372, -0.0368, -0.1751,  0.6116,  0.1666,  0.2086, -0.0800, -0.0917,\n",
       "           -0.2087,  0.0603, -0.4104, -0.5067,  0.2651,  0.3225, -0.0037, -0.1555,\n",
       "            0.1642, -0.4308,  0.1972, -0.4602,  0.1444, -0.1191, -0.7299, -0.6860,\n",
       "           -0.1421,  0.0188,  0.5794,  0.6287,  0.1608,  0.0091,  0.0555, -0.0650],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 2.5226e-01, -1.1830e-01,  3.1617e-01, -3.7945e-02,  2.5840e-02,\n",
       "            3.4952e-01,  2.6197e-01,  5.2459e-02,  2.1434e-01,  1.9086e-01,\n",
       "            1.4481e-01,  6.7441e-01, -3.5051e-02,  1.5460e-01,  2.2212e-01,\n",
       "            1.4886e-02,  6.6736e-01,  2.2464e-01,  3.3521e-01,  3.3270e-01,\n",
       "            6.8199e-01,  4.5277e-01,  4.7311e-01,  5.5645e-01,  3.3202e-01,\n",
       "            6.1506e-01,  2.2259e-01,  3.3364e-01,  2.3801e-01,  1.8067e-01,\n",
       "            2.2561e-01,  1.5607e-01, -7.8851e-03,  8.2437e-01,  5.0140e-02,\n",
       "           -1.0978e-01, -1.9509e-02,  9.1363e-02,  2.5313e-01,  2.4066e-01,\n",
       "            3.2992e-01,  5.2361e-01,  4.9578e-01,  5.3078e-01,  2.9913e-01,\n",
       "            1.0840e-01,  4.9597e-01,  3.9183e-01, -2.0404e-04,  5.3850e-02,\n",
       "            5.9313e-01,  4.5633e-01,  3.2608e-01,  3.2752e-01,  3.1661e-01,\n",
       "            3.5636e-01,  2.1142e-01,  7.6426e-02,  3.2339e-01,  3.0442e-01,\n",
       "            5.6901e-01,  7.0274e-02,  2.7779e-01,  2.1743e-01,  3.4773e-01,\n",
       "            1.4134e-01,  6.2156e-01,  3.5652e-01, -3.3710e-02, -7.2691e-02,\n",
       "           -1.1055e-01, -1.2764e-02,  2.2313e-01,  1.1952e+00,  9.3887e-01,\n",
       "            1.8214e-02,  4.1040e-01, -3.0413e-02,  1.3942e-01, -3.0831e-02,\n",
       "           -1.7220e-01,  1.8757e-01, -7.9087e-02,  7.6496e-01,  1.8587e-02,\n",
       "            4.0306e-01,  6.2738e-03,  9.4117e-01,  5.6689e-01,  4.6843e-01,\n",
       "            7.8431e-01,  3.2716e-01,  1.4838e-01,  2.6812e-01,  4.8583e-01,\n",
       "            4.3640e-01,  4.3513e-01,  1.3077e+00,  5.2061e-01, -2.0129e-02,\n",
       "            2.5640e-01,  7.2337e-02,  4.8283e-01,  7.3389e-01,  3.1728e-01,\n",
       "            1.9857e-01,  2.1841e-01,  1.5454e-01,  7.3366e-01,  3.6539e-01,\n",
       "            2.2506e-01,  5.2263e-01,  3.6615e-01, -1.3840e-02,  3.1556e-01,\n",
       "            3.4238e-01,  4.3178e-01,  5.2916e-02,  1.8581e-01,  7.5455e-01,\n",
       "            1.9666e+00,  2.2714e-02,  1.1133e+00,  9.3773e-01,  1.3195e+00,\n",
       "            1.6709e-02,  2.1664e-01,  4.4415e-01,  2.0897e+00,  5.0968e-01,\n",
       "            3.0624e-01,  5.3079e-01,  6.2079e-01,  4.7150e-01,  1.1415e-02,\n",
       "            7.0922e-01,  7.0655e-02,  3.2722e-01,  4.6981e-01,  1.1439e-01,\n",
       "            6.6157e-01,  7.3609e-01,  2.1913e-01,  1.5505e-01,  4.0058e-01,\n",
       "            3.3972e-01,  7.0588e-01,  4.1294e-01,  4.8038e-01,  2.4257e-01,\n",
       "            1.8358e-01,  7.4474e-01,  9.1402e-01,  2.7084e-01,  3.0396e-01,\n",
       "            8.1993e-01,  2.6448e-01,  2.5826e-01,  4.4846e-01, -9.1551e-02,\n",
       "            3.3893e-01, -3.4206e-02,  1.5006e-02,  2.4554e-03,  3.9211e-01,\n",
       "           -7.0064e-02,  2.0139e-01,  3.3100e+00,  7.4539e-01,  5.0334e-02,\n",
       "            3.7060e-02,  7.8824e-01, -1.5639e-02,  2.8923e-01,  4.0237e-01,\n",
       "            2.3247e-01,  5.5119e-01,  1.7961e-01,  8.3426e-01,  3.5473e-01,\n",
       "           -6.0659e-02, -1.7189e-01,  1.0943e+00,  5.9327e-01,  1.5429e-01,\n",
       "            1.5750e-01, -3.2792e-02,  7.6552e-02, -2.4749e-02,  7.5752e-01,\n",
       "            9.3329e-01,  6.3939e-02,  4.1513e-01, -1.0061e-02,  4.4660e-01,\n",
       "            3.4912e-01,  4.4285e-02, -2.9513e-02,  4.9133e-01,  1.5102e-01,\n",
       "            1.6842e-01,  1.4420e+00,  7.9192e-01,  9.5942e-01,  2.4288e-02,\n",
       "            2.2204e-01,  8.8315e-01,  4.2148e-01,  5.7055e-01,  1.4341e-01,\n",
       "            1.3519e-01,  1.2847e-02,  4.0750e-01,  1.5997e-01,  2.8752e-01,\n",
       "            2.1108e-01,  5.1745e-01,  1.3686e+00,  8.8374e-01,  9.4462e-01,\n",
       "            5.4992e-01,  3.6883e-01,  8.5165e-01,  1.1467e-01,  1.0972e-02,\n",
       "            1.3736e-01,  1.0582e+00,  3.3647e-01,  3.9829e-02,  1.3134e-01,\n",
       "            2.2026e-01, -1.1950e-01,  4.8842e-01,  9.6874e-02,  9.1130e-02,\n",
       "            1.9523e-01,  3.0869e-02,  1.3621e-02,  3.7685e-01,  4.9386e-01,\n",
       "            6.1418e-02,  6.5517e-01,  3.6407e-02,  3.3430e-01,  1.5042e-01,\n",
       "            1.9907e-01,  3.7530e-01,  1.9432e-01,  3.5114e-02,  1.3103e-02,\n",
       "            1.6048e-02,  1.1536e-01,  5.7772e-01,  4.9772e-02,  1.8821e-01,\n",
       "           -5.5306e-02], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 1.2308e-01,  2.0680e-02,  1.0254e-01, -7.5032e-03, -1.8193e-02,\n",
       "            2.5733e-01,  1.3826e-01, -2.2417e-03,  5.5158e-02,  2.2624e-02,\n",
       "           -2.5223e-04, -3.3908e-01,  1.2770e-02,  1.5016e-02,  8.4624e-02,\n",
       "           -6.2165e-03, -3.7989e-01, -2.0021e-01,  1.6044e-01, -1.5223e-01,\n",
       "           -2.2981e-01,  2.1753e-01,  2.4277e-01, -3.9235e-01,  2.0657e-01,\n",
       "           -3.8839e-01, -1.2321e-01, -1.7121e-01,  8.9496e-02, -1.0428e-01,\n",
       "           -2.2012e-02, -7.0450e-03,  5.9852e-03,  3.3846e-01, -6.7074e-03,\n",
       "           -8.7638e-03, -3.6133e-03, -1.5702e-01, -1.0180e-02,  1.0238e-01,\n",
       "            1.8736e-01,  3.4215e-01,  6.8673e-02,  4.4440e-01, -1.5028e-01,\n",
       "            7.2113e-04, -1.9478e-01,  2.2072e-01, -3.4421e-03,  4.5608e-04,\n",
       "           -7.0326e-02,  2.6467e-01,  1.8600e-01, -1.8822e-01, -2.6828e-01,\n",
       "           -9.8813e-02, -7.9578e-02, -2.3280e-02, -2.4781e-01, -2.3776e-01,\n",
       "           -1.8457e-01,  3.8123e-03,  1.7574e-01,  6.6267e-02, -2.2678e-01,\n",
       "            8.5561e-02, -2.2417e-01, -2.7235e-01,  7.9107e-03,  3.9082e-03,\n",
       "           -4.0445e-03, -4.3601e-03,  1.2903e-01, -2.4093e-01, -2.1041e-01,\n",
       "            3.4654e-03, -6.2485e-02,  7.5220e-03, -4.7400e-02,  1.3034e-03,\n",
       "            6.2515e-03, -9.9650e-02,  2.0021e-02,  3.8398e-02, -1.1239e-02,\n",
       "            2.6407e-01,  3.2233e-06,  8.0067e-02, -3.0406e-01,  3.2434e-01,\n",
       "           -3.3288e-01,  1.6520e-01, -1.0179e-02, -1.5265e-01,  2.0832e-03,\n",
       "           -2.6405e-01, -1.0623e-02,  2.9074e-01, -3.0300e-01,  6.7309e-03,\n",
       "           -1.6977e-01, -3.2094e-02, -6.0866e-01, -1.9694e-01, -1.9749e-01,\n",
       "           -8.3704e-02,  8.3401e-02, -2.5002e-02,  3.4616e-01, -2.3434e-01,\n",
       "            1.4421e-01,  3.3578e-01, -2.1473e-01, -8.1084e-03, -3.5311e-01,\n",
       "            1.2327e-01, -2.7019e-01,  6.3093e-03, -8.4897e-02, -1.7379e-01,\n",
       "           -1.3041e+00, -3.6798e-03, -3.6151e-01, -5.5950e-01, -6.2475e-01,\n",
       "           -3.3678e-03, -1.4904e-01,  3.1606e-01,  3.4815e-01,  2.8576e-01,\n",
       "           -1.4400e-01, -2.7978e-01,  3.1551e-01, -1.5251e-01, -1.0974e-02,\n",
       "           -2.4542e-01,  1.6978e-02,  1.1527e-01, -4.3245e-01, -8.5835e-03,\n",
       "           -1.9796e-01, -5.0908e-01,  3.3378e-02,  4.1122e-02,  1.9795e-01,\n",
       "           -2.7093e-02, -2.8734e-01,  2.2759e-01,  4.2689e-02,  1.2289e-01,\n",
       "           -4.1953e-02, -5.2959e-01,  9.6996e-02,  1.0538e-01, -4.7415e-02,\n",
       "            1.7809e-01,  1.6355e-01,  1.0771e-01, -3.3884e-01,  7.9709e-03,\n",
       "            1.9023e-01,  1.5112e-02, -9.7039e-04,  8.0018e-04,  2.4012e-01,\n",
       "            1.6532e-02, -3.1248e-02, -6.0354e-02,  8.9832e-03, -9.1312e-03,\n",
       "           -8.1892e-03, -3.0625e-01,  1.6417e-03, -1.6978e-01,  2.5801e-01,\n",
       "           -1.5932e-01,  2.1184e-01, -4.6737e-02,  4.9610e-02, -3.3612e-01,\n",
       "            2.0142e-02, -1.2884e-02,  4.7431e-01, -4.9614e-02, -7.3141e-02,\n",
       "            5.1656e-02, -8.9058e-03,  4.6065e-03, -1.6365e-03, -2.4713e-01,\n",
       "            2.3601e-01, -2.0407e-02,  2.8094e-01, -7.3916e-03,  1.4479e-01,\n",
       "           -1.1990e-01, -2.0450e-02, -7.4921e-04,  1.5977e-01,  9.7854e-02,\n",
       "           -6.3075e-02,  6.7756e-02,  4.4387e-01, -4.6101e-01, -1.1495e-02,\n",
       "           -1.7162e-02,  3.6234e-01, -2.1923e-01,  2.5437e-01, -1.3658e-03,\n",
       "           -8.3373e-02,  9.0704e-03,  2.9284e-01, -1.8939e-02,  1.0370e-01,\n",
       "           -2.7993e-02,  1.4885e-01, -9.9884e-01, -3.4240e-02,  8.8338e-01,\n",
       "           -3.3378e-01,  2.3854e-01, -1.5049e-01,  2.0135e-03, -9.5128e-03,\n",
       "            5.6160e-02,  2.3166e-01, -1.2324e-01, -3.8690e-03,  5.0161e-02,\n",
       "           -1.9036e-02,  3.0099e-02,  2.6832e-01,  2.5612e-02, -3.6762e-02,\n",
       "            2.4520e-02, -3.3868e-03,  1.8165e-02,  1.0861e-01,  2.6517e-01,\n",
       "           -4.1995e-03,  3.3533e-01, -1.0710e-02,  9.0985e-02, -5.2748e-02,\n",
       "           -1.6339e-02,  2.9911e-01,  7.6322e-02,  1.0700e-03, -1.7819e-03,\n",
       "            3.1697e-04,  8.5329e-03,  2.1607e-01,  1.8297e-02,  5.5012e-03,\n",
       "           -9.6474e-04], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 2.0140e-02,  1.3174e-02, -2.9159e-03,  3.4228e-03,  1.9467e-02,\n",
       "           -1.1762e-02, -7.2786e-04, -1.2375e-02,  2.0027e-02,  8.4402e-05,\n",
       "           -4.4646e-03,  9.8790e-03,  7.6070e-03, -7.1785e-03,  9.6447e-03,\n",
       "           -1.1761e-02,  6.4472e-03,  3.0322e-02,  5.8742e-03, -2.7496e-03,\n",
       "            7.1234e-03, -3.8846e-04,  4.2486e-02,  1.3892e-03, -1.2100e-02,\n",
       "            5.3864e-03, -1.8024e-02,  1.3749e-02,  8.4146e-03,  2.9138e-03,\n",
       "           -1.6417e-02, -1.5702e-03, -1.3872e-02,  9.5751e-03,  4.6599e-03,\n",
       "            3.0739e-03,  1.6431e-02,  9.2517e-02, -3.8247e-03,  1.3294e-02,\n",
       "           -4.8462e-03, -2.5007e-02,  7.7839e-03, -8.2988e-03, -8.8261e-03,\n",
       "            7.2897e-03, -3.5978e-04, -8.5906e-03,  2.3919e-03,  8.5095e-03,\n",
       "            2.6509e-02,  5.8432e-03,  5.5283e-03,  8.1742e-03, -3.4180e-03,\n",
       "            1.0070e-01, -1.5398e-02,  3.9247e-03, -5.5410e-03,  1.4853e-02,\n",
       "           -2.1304e-02,  2.1956e-03,  5.4710e-03,  2.7458e-04,  1.1830e-02,\n",
       "           -3.8752e-02, -4.6924e-03,  1.1263e-02,  9.9789e-03, -4.0706e-03,\n",
       "            1.0241e-02,  2.5228e-03,  4.7807e-03,  2.0326e-02, -9.2287e-03,\n",
       "            6.4697e-04,  1.2299e-02,  1.3019e-02,  1.1507e-02,  8.8692e-03,\n",
       "           -1.9546e-02,  1.6349e-03, -1.7192e-02,  7.2772e-02, -1.4095e-02,\n",
       "           -9.4770e-03,  3.7879e-03,  8.2543e-02, -3.8309e-04,  2.4794e-02,\n",
       "            3.7064e-03, -5.7005e-03, -1.0190e-02, -1.5172e-02,  1.2161e-02,\n",
       "           -1.2137e-02,  1.7614e-02,  1.0813e-01,  4.2594e-04,  1.6659e-03,\n",
       "           -1.9426e-02,  3.0787e-02,  1.1785e-01, -3.9118e-03, -1.3892e-02,\n",
       "            4.4626e-03, -2.4148e-02, -1.5681e-02,  2.4874e-02,  3.9385e-03,\n",
       "           -1.6837e-02,  1.2262e-02,  3.5900e-02, -3.4663e-03, -4.8525e-03,\n",
       "            1.0408e-02,  2.8813e-03, -3.3506e-03,  8.3573e-03, -1.0643e-02,\n",
       "            3.2819e-02,  1.2448e-02, -5.7938e-03,  5.5817e-03,  7.4654e-02,\n",
       "           -2.1395e-02,  7.2910e-03,  9.2521e-03,  1.7549e-02,  3.6072e-03,\n",
       "            9.3442e-03, -9.4150e-03,  1.7673e-02,  6.0503e-03, -1.8233e-04,\n",
       "            1.6387e-03,  5.2272e-03,  2.2168e-02, -4.5003e-03,  9.5525e-03,\n",
       "            2.1307e-02, -1.1458e-02, -8.2075e-03,  1.2219e-02,  1.4557e-02,\n",
       "           -1.8312e-02,  7.2993e-03,  1.8250e-03,  1.3499e-02,  4.6460e-03,\n",
       "            1.1848e-03,  1.5522e-02,  7.0062e-02,  9.6437e-04,  1.6314e-02,\n",
       "            1.2922e-02, -3.8804e-02, -1.2735e-02,  5.9025e-03, -8.4895e-04,\n",
       "           -4.0443e-03, -1.3050e-02,  9.4292e-04, -1.1089e-02,  1.2515e-02,\n",
       "            1.4134e-02, -8.6619e-03,  3.0658e-02,  4.6900e-03,  1.3711e-02,\n",
       "            3.2579e-03,  1.0724e-01, -4.8932e-03,  1.5003e-02, -8.6695e-03,\n",
       "           -2.0572e-02, -1.9885e-02, -2.2841e-02,  1.0563e-02, -4.3301e-03,\n",
       "            2.2027e-02,  7.6187e-03,  5.5647e-03,  1.7599e-02,  1.0298e-02,\n",
       "           -6.3500e-03, -4.5351e-04,  1.1753e-02, -1.7108e-02, -2.6380e-02,\n",
       "            1.6533e-02, -2.3404e-03,  1.2803e-02, -2.6774e-03, -1.5864e-02,\n",
       "            5.0742e-03, -3.9500e-03,  1.7753e-03,  1.1859e-02,  1.4652e-02,\n",
       "            8.4554e-03,  1.7585e-01, -1.4772e-03, -9.6935e-03,  8.1728e-03,\n",
       "            8.9674e-04,  5.0426e-03, -1.5980e-02, -2.3214e-02,  1.3596e-02,\n",
       "            6.5579e-03,  6.3604e-04,  1.6130e-02,  9.8664e-03,  2.1319e-02,\n",
       "            2.5112e-03, -4.3896e-03,  6.0449e-02,  4.7192e-02,  1.3681e-01,\n",
       "           -1.3378e-02, -6.4836e-04, -1.5552e-03, -2.4508e-02, -1.7258e-02,\n",
       "            1.3926e-02,  1.9450e-02,  1.6853e-02,  1.6158e-02,  1.9301e-03,\n",
       "            2.5187e-03,  7.6238e-03, -3.8703e-02, -1.2313e-02,  7.9859e-05,\n",
       "           -1.2265e-02,  7.2289e-03,  5.1547e-03,  1.1985e-02,  7.0411e-02,\n",
       "           -2.2563e-02,  3.8079e-03, -4.2783e-03, -2.9274e-02,  9.9436e-03,\n",
       "            8.4620e-03,  1.8757e-02,  3.8134e-03,  4.9142e-03, -1.6265e-02,\n",
       "            4.1724e-02,  1.8480e-03, -5.4473e-03, -4.1972e-03,  7.7307e-03,\n",
       "           -2.6460e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 9.5514e-04,  4.5860e-03, -3.2876e-03, -4.7422e-03, -5.0939e-03,\n",
       "            1.6217e-03, -4.3561e-03,  7.3817e-04,  1.1792e-02,  1.0290e-03,\n",
       "           -7.9350e-05,  2.4200e-03,  3.5458e-03,  6.6455e-03,  1.2563e-03,\n",
       "            8.4050e-03, -5.2588e-03,  4.9371e-02,  7.4258e-03, -5.9904e-03,\n",
       "            2.3861e-04,  2.3827e-03, -5.6652e-03,  5.3204e-03,  3.6758e-03,\n",
       "           -5.0190e-03,  3.9915e-03, -2.7739e-03,  1.2038e-03,  4.2678e-03,\n",
       "            4.2576e-03, -1.7296e-04, -6.3937e-03,  4.4723e-03, -7.5654e-04,\n",
       "           -1.9558e-03,  1.2243e-03, -9.3956e-03, -1.2699e-03,  8.4272e-05,\n",
       "            5.5642e-03, -5.6698e-03, -2.7979e-03,  8.2172e-04,  5.5549e-03,\n",
       "            2.2218e-03, -4.9998e-03, -9.8716e-03,  3.9649e-03,  1.6884e-03,\n",
       "           -3.1342e-03,  7.8011e-04, -3.8732e-03, -1.5491e-03,  2.0518e-03,\n",
       "            2.0152e-02,  2.1371e-03,  3.1800e-03, -3.0974e-03, -2.3004e-03,\n",
       "           -6.7135e-04,  1.0176e-03,  1.6152e-03,  8.0285e-03,  2.6880e-03,\n",
       "            4.1054e-03,  1.1595e-03,  1.2635e-03, -7.2233e-04,  5.1785e-03,\n",
       "           -3.6538e-03,  8.4107e-03, -3.8632e-03, -5.6167e-03, -5.1787e-03,\n",
       "            1.0004e-03,  8.9073e-03, -5.1544e-04,  9.3289e-04, -2.2224e-04,\n",
       "           -5.6365e-03, -2.2959e-04, -1.3337e-03,  3.5913e-02, -2.2628e-03,\n",
       "            3.9254e-03, -2.9744e-03,  5.5024e-02,  2.6521e-03, -1.1648e-03,\n",
       "           -3.8025e-03,  8.7566e-04, -1.9855e-03,  2.0700e-03,  8.7689e-04,\n",
       "            1.3221e-03,  1.4186e-03, -6.8027e-03, -1.9852e-04, -8.8474e-03,\n",
       "            4.7661e-03,  5.2823e-03,  1.4362e-01, -3.7068e-03,  1.8111e-04,\n",
       "           -5.2105e-04, -3.8241e-05,  3.3831e-03, -3.4259e-03, -3.7820e-03,\n",
       "            6.9129e-03, -2.0955e-03,  9.0025e-03, -3.7499e-04,  9.0356e-04,\n",
       "           -4.0427e-04, -3.6472e-03,  8.0487e-03, -4.6232e-04, -5.2897e-03,\n",
       "            2.0851e-01,  9.0873e-04, -3.0109e-03, -3.6042e-03,  4.3563e-02,\n",
       "            4.6300e-03, -2.9741e-03,  4.5938e-04, -9.3155e-02, -3.4623e-03,\n",
       "            8.1552e-03,  5.5673e-03,  6.5516e-03,  1.3941e-03, -3.5787e-04,\n",
       "            5.4569e-03,  1.0506e-03,  9.8882e-03, -1.0059e-03, -1.1754e-03,\n",
       "           -3.8625e-03,  4.7805e-03, -8.9329e-03,  8.8835e-03, -1.2115e-03,\n",
       "            1.8757e-03, -3.9934e-03,  1.1528e-02, -3.3068e-05, -3.3613e-03,\n",
       "           -2.2898e-03,  3.8607e-03,  7.7398e-04, -3.8577e-03, -2.1862e-04,\n",
       "           -3.6468e-03,  2.6975e-03, -2.0768e-03, -3.3690e-03, -3.1551e-03,\n",
       "            5.0098e-03,  4.9890e-04, -4.6375e-03, -2.1115e-03,  1.9594e-03,\n",
       "            2.0635e-05, -3.6820e-04, -9.9336e-02, -1.8370e-03,  2.0735e-03,\n",
       "            3.9332e-04, -1.7989e-02,  1.3938e-03,  3.8216e-03,  8.7873e-03,\n",
       "           -5.3270e-03, -7.7243e-04,  1.3753e-02,  6.7858e-04,  3.8743e-03,\n",
       "           -2.2384e-04,  3.4308e-03, -8.3722e-05,  3.4091e-04,  1.9687e-03,\n",
       "            1.6440e-03, -6.5374e-04,  9.6810e-03, -5.6777e-03, -9.8381e-05,\n",
       "           -1.0347e-03,  4.7416e-03, -4.1989e-03,  8.5634e-04,  9.4999e-03,\n",
       "           -2.1915e-03,  6.1277e-03, -4.0137e-03, -3.0119e-03, -5.5214e-03,\n",
       "            2.4286e-03,  3.8597e-02, -5.1107e-04,  5.4048e-04, -1.1099e-03,\n",
       "            4.3837e-03,  4.9343e-03, -1.1863e-04, -8.9733e-03,  8.1650e-04,\n",
       "           -1.8865e-04,  1.2853e-03,  4.5595e-03, -1.3525e-03,  5.0796e-03,\n",
       "           -2.8288e-03,  9.5835e-03,  4.3222e-01,  3.8160e-03,  2.8045e-02,\n",
       "            2.9789e-04, -2.7066e-03,  4.0253e-03, -5.1843e-04,  1.7949e-03,\n",
       "            7.9083e-04,  6.5904e-03,  1.4790e-03,  2.0764e-03, -4.7451e-03,\n",
       "            8.6680e-03, -2.5312e-04, -1.1905e-03,  1.8175e-03, -1.4737e-03,\n",
       "            2.7796e-03, -1.2102e-03,  6.1977e-03, -2.6982e-03,  2.2679e-02,\n",
       "           -2.9265e-03,  6.1453e-04, -1.0359e-02,  4.1365e-03, -3.6442e-03,\n",
       "            8.5439e-03, -3.8658e-03, -3.7215e-04, -7.2049e-03, -4.6232e-03,\n",
       "            1.0694e-02,  3.0254e-03,  7.8633e-03,  7.8768e-05, -1.0105e-03,\n",
       "            5.2513e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.3767,  0.6376, -0.6718,  ...,  0.3387,  0.9273, -0.4481],\n",
       "           [-0.1660, -0.0019,  0.1560,  ..., -0.1041,  0.0663, -0.3551],\n",
       "           [ 0.1159,  0.1720, -0.4740,  ...,  0.1390,  0.6222,  0.1136],\n",
       "           ...,\n",
       "           [-0.2301, -0.2045,  0.5256,  ..., -0.1613, -0.1461,  0.3780],\n",
       "           [ 0.2142,  0.1621,  0.0899,  ..., -0.3391,  0.6587,  0.0080],\n",
       "           [-0.7455, -0.5373,  0.8089,  ..., -0.4297, -1.1762, -0.2198]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.3464,  0.0708, -0.0637,  0.0630,  0.3773, -0.0907, -0.2138,  0.2750,\n",
       "            0.3081, -0.1567,  0.2897, -0.2710,  0.0627,  0.3426,  0.0690, -0.3072,\n",
       "           -0.1136, -0.0359,  0.4827,  0.3377, -0.2954, -0.1868, -0.0766,  0.3847,\n",
       "           -0.1236, -0.5245, -0.1930,  0.0855, -0.1534,  0.3148, -0.4951, -0.3104,\n",
       "           -0.5541, -0.0101,  0.2618,  0.1105, -0.2261,  0.2269, -0.3998,  0.7097,\n",
       "            0.0972,  0.0970, -0.0180,  0.2246, -0.2449, -0.1752,  0.5408,  0.4885,\n",
       "            0.1358, -0.5821,  0.3934,  0.5286,  0.1648, -0.4822,  0.0504, -0.2103,\n",
       "           -0.3405,  0.2077, -0.5695,  0.2502,  0.2401,  0.3995, -0.3435,  0.4640,\n",
       "           -0.0911, -0.0687, -0.0932,  0.2228, -0.1761, -0.0656, -0.1139,  0.0545,\n",
       "           -0.0775, -0.0409,  0.0395, -0.0079,  0.0811, -0.1848,  0.0122, -0.0411,\n",
       "            0.0897,  0.0306,  0.1688, -0.0199, -0.1682, -0.0681, -0.0387,  0.2006,\n",
       "            0.0888, -0.1130, -0.0635, -0.0123, -0.0405,  0.3442,  0.0064, -0.0057,\n",
       "           -0.1120,  0.1172,  0.1782,  0.3114, -0.2446, -0.1068, -0.2735,  0.1808,\n",
       "           -0.1527,  0.1729,  0.0448, -0.0769,  0.2077,  0.0264, -0.1057,  0.2039,\n",
       "            0.1920, -0.0892,  0.3102,  0.1999,  0.2909,  0.0277, -0.1549,  0.1638,\n",
       "           -0.0881, -0.0915,  0.0882,  0.0509, -0.1066,  0.0348,  0.1634, -0.1733,\n",
       "           -0.1237, -0.1721,  0.2908,  0.1569,  0.0536, -0.0920, -0.0917, -0.0765,\n",
       "            0.1204,  0.1416, -0.1782, -0.1500, -0.2268, -0.2426,  0.1944,  0.1511,\n",
       "           -0.2842, -0.0698,  0.0431, -0.0306,  0.0028,  0.3068, -0.3392,  0.1055,\n",
       "           -0.2289, -0.2530, -0.0766, -0.3483, -0.0726, -0.0799, -0.1482, -0.1056,\n",
       "           -0.3567, -0.2426,  0.2020,  0.5577,  0.5650,  0.2622,  0.4186, -0.2759,\n",
       "           -0.3731, -0.3455,  0.0025,  0.2556, -0.1272, -0.4297, -0.1339, -0.2995,\n",
       "            0.1676,  0.1806, -0.4120, -0.2889,  0.2084, -0.1191, -0.2771,  0.1590,\n",
       "            0.1443,  0.3398,  0.3302, -0.2116, -0.3094,  0.1434,  0.0517,  0.5002,\n",
       "           -0.1157,  0.1737, -0.1206, -0.2375, -0.3072, -0.1601, -0.2953,  0.0828,\n",
       "            0.0881,  0.2452, -0.1321,  0.1031,  0.4908, -0.1643,  0.0883, -0.0601,\n",
       "            0.0752, -0.2244, -0.3032,  0.0940, -0.2549, -0.2321, -0.0219,  0.2354,\n",
       "            0.0125, -0.3500, -0.1106,  0.1824,  0.1064, -0.1774,  0.4188,  0.2505,\n",
       "           -0.1310, -0.0906, -0.2285, -0.1070,  0.0550,  0.1310, -0.0253,  0.2615,\n",
       "            0.0012, -0.0401, -0.1562, -0.0403, -0.3930,  0.0200,  0.2804, -0.1994,\n",
       "            0.3491, -0.2109, -0.1002,  0.3443, -0.0379,  0.2246, -0.2223,  0.0274,\n",
       "            0.0325, -0.0110, -0.3980,  0.0081,  0.3507, -0.1573, -0.0305, -0.6495],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0914, -0.0321, -0.2201,  ...,  0.1462, -0.3857, -0.0916],\n",
       "           [ 0.3716, -0.0644, -0.1988,  ...,  0.1670,  0.0517,  0.0156],\n",
       "           [ 0.0384,  0.4189,  0.3220,  ...,  0.1817, -0.1186,  0.0513],\n",
       "           ...,\n",
       "           [ 0.2882,  0.5505, -0.3389,  ...,  0.4041, -0.0727, -0.2234],\n",
       "           [ 0.6656, -0.1958, -0.4057,  ..., -0.1508,  0.0856,  0.2507],\n",
       "           [-0.2396,  0.4349,  0.0584,  ...,  0.0785, -0.3200, -0.2728]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 9.1716e-03, -8.8273e-06,  3.4891e-03,  3.0104e-03,  2.6963e-03,\n",
       "            2.3366e-03, -6.1816e-03,  6.8666e-03,  7.3087e-03, -3.3238e-04,\n",
       "            1.0276e-02, -5.8504e-03,  2.9772e-03,  6.5923e-03,  3.4564e-03,\n",
       "           -5.9843e-03, -3.4902e-03,  1.4623e-03,  9.7337e-03,  1.0143e-02,\n",
       "           -7.0461e-03, -1.4225e-03,  1.6288e-03,  5.7292e-04, -9.8684e-04,\n",
       "           -1.1074e-02, -4.9907e-03,  5.2121e-03, -9.4002e-04,  3.0950e-03,\n",
       "           -8.2430e-03, -7.5918e-03, -2.9687e-04, -8.0747e-04,  3.8978e-04,\n",
       "            1.3485e-05,  2.2075e-04,  9.9942e-05, -2.9371e-04, -3.9596e-04,\n",
       "           -2.0358e-04, -7.4036e-04, -3.6662e-04,  6.0553e-05,  4.6841e-04,\n",
       "            2.5705e-04, -4.7182e-04,  1.5329e-04,  3.5888e-05, -1.6225e-04,\n",
       "            5.9638e-04, -7.1476e-04,  2.2094e-04, -1.4098e-04, -3.2364e-04,\n",
       "           -1.4900e-04,  1.3349e-04, -5.3987e-04, -4.1829e-04, -5.6870e-04,\n",
       "            2.0562e-04,  3.6557e-05,  6.6380e-04,  5.1257e-05, -9.5989e-05,\n",
       "           -2.1442e-04, -1.1530e-06, -2.0021e-04, -8.8875e-05,  1.0012e-04,\n",
       "           -1.0400e-04,  5.6350e-04, -6.8152e-06,  7.2953e-05, -1.9230e-04,\n",
       "            1.3897e-04, -1.4322e-03,  6.5934e-04, -4.9410e-05,  4.0312e-04,\n",
       "           -4.8256e-04,  3.8613e-04, -4.9206e-04,  1.9408e-04,  4.1119e-04,\n",
       "           -3.5759e-04, -1.4929e-04,  2.1202e-04,  2.6396e-04,  3.8314e-04,\n",
       "           -3.4496e-04, -3.9148e-04, -1.6922e-04, -1.3007e-03,  4.7594e-04,\n",
       "            6.0856e-04,  6.4758e-04, -6.2626e-04, -1.0418e-03, -8.2621e-04,\n",
       "           -3.2040e-04, -1.3080e-03, -8.2602e-04, -7.0097e-04,  4.7850e-04,\n",
       "           -1.3817e-03,  1.2236e-04, -4.3218e-04, -7.5997e-04,  4.2367e-04,\n",
       "            9.1217e-04, -8.7108e-04, -1.4490e-03,  1.4256e-03, -7.6201e-04,\n",
       "           -7.6018e-04, -1.2078e-03, -1.9624e-04,  1.3884e-03, -1.2322e-03,\n",
       "            8.5541e-04,  9.0390e-04, -6.0394e-04, -9.4536e-04,  1.4258e-03,\n",
       "           -1.1074e-03, -8.5977e-04,  1.7839e-04, -1.9447e-03, -8.4504e-04,\n",
       "           -1.1410e-03, -7.0466e-04, -2.7621e-03, -6.5599e-04, -2.5487e-03,\n",
       "            2.6761e-03, -2.6284e-03,  6.4086e-04,  7.2104e-04,  2.1420e-03,\n",
       "            6.7940e-04,  8.0303e-04,  5.2097e-04,  1.2458e-03,  2.0308e-03,\n",
       "           -2.4338e-03, -1.6639e-03,  5.5963e-05, -1.6194e-03, -2.7409e-03,\n",
       "            2.4296e-03,  1.0662e-03,  3.1545e-03,  1.6120e-03, -1.9210e-03,\n",
       "            1.6818e-03,  7.6847e-04, -1.0209e-04,  8.4860e-04, -2.4710e-03,\n",
       "           -4.3128e-04,  3.8981e-04, -6.8746e-04, -2.9616e-04,  3.2444e-04,\n",
       "            9.6358e-04,  8.9584e-04, -5.2197e-04, -6.2036e-04, -7.6808e-04,\n",
       "           -3.3454e-04,  6.4428e-05,  2.4378e-04, -3.3430e-04, -4.3821e-04,\n",
       "           -1.3719e-04,  2.7535e-04, -4.0608e-04, -9.3761e-04, -7.2825e-04,\n",
       "            1.1322e-03, -3.7066e-04, -9.5120e-04,  8.5626e-04,  5.8346e-04,\n",
       "            8.8096e-04,  6.2322e-04, -5.2345e-04, -7.3913e-04,  2.6836e-04,\n",
       "            3.2546e-04,  5.3572e-04, -2.0223e-03, -2.0228e-03, -1.5619e-03,\n",
       "            1.5425e-03,  3.8790e-03,  4.0250e-03, -8.6082e-04,  2.1356e-03,\n",
       "            1.7082e-03, -1.5682e-03, -1.7562e-03, -1.4030e-04, -1.9103e-03,\n",
       "            1.1863e-03, -1.4427e-03,  5.9946e-04,  2.3490e-03, -1.9228e-04,\n",
       "            3.3075e-03,  1.7204e-03,  7.1567e-04,  5.9707e-04,  1.8375e-03,\n",
       "           -1.9584e-03,  4.6178e-03,  3.7746e-03,  2.1808e-03,  8.6205e-04,\n",
       "            1.5913e-03,  4.5433e-04,  1.2034e-03, -1.2467e-04,  7.6904e-05,\n",
       "            6.0063e-04,  5.2703e-04,  4.5433e-04, -3.7510e-05,  5.3563e-04,\n",
       "            3.2234e-04, -5.7673e-04,  7.1794e-04, -5.9237e-04, -7.9906e-04,\n",
       "            6.9769e-04,  4.3082e-04, -9.1051e-04, -6.1407e-05,  3.5546e-04,\n",
       "           -2.8046e-04, -1.3383e-04,  2.8152e-04, -4.2652e-04, -7.3678e-04,\n",
       "           -7.0860e-05,  5.4499e-04,  8.8498e-04,  2.5424e-04,  4.4475e-05,\n",
       "            6.9797e-05,  3.9307e-04, -5.0792e-04,  4.7210e-04, -5.9759e-04,\n",
       "           -1.0708e-06], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.1332,  0.0422, -0.0292,  ..., -0.0412,  0.3222,  0.0383],\n",
       "           [ 0.2580,  0.2568, -0.3737,  ...,  0.3700,  0.0873,  0.6314],\n",
       "           [-0.4162, -0.0386,  0.3242,  ..., -0.2537, -0.5399, -0.1950],\n",
       "           ...,\n",
       "           [-0.0154, -0.0426, -0.1525,  ...,  0.3657, -0.4453, -0.3832],\n",
       "           [-0.1558,  0.2363, -0.0924,  ..., -0.1503, -0.0874, -0.2532],\n",
       "           [-0.0902,  0.1231,  0.1830,  ..., -0.6240,  0.3073, -0.0833]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-3.2108e-01,  4.9874e-01, -7.5043e-01, -3.9243e-01,  3.7329e-01,\n",
       "           -3.6289e-01, -6.3154e-01, -8.3701e-02, -5.6915e-01,  2.9007e-01,\n",
       "            5.2066e-01, -4.9705e-01, -3.4819e-01,  2.1424e-01, -2.0198e-01,\n",
       "           -5.5715e-01,  3.0390e-01, -5.0253e-01,  5.9190e-01, -4.4927e-01,\n",
       "            4.9836e-01, -4.7496e-02,  6.0941e-01,  3.2074e-01, -6.2371e-02,\n",
       "            4.9077e-01,  4.1673e-01,  1.0038e-01,  3.2930e-03, -6.0267e-01,\n",
       "           -2.0889e-01,  7.8546e-01,  5.2618e-02,  2.2160e-01,  2.1170e-01,\n",
       "           -3.2987e-01, -2.6246e-02, -3.8128e-01,  1.4031e-01, -5.7627e-01,\n",
       "            2.7398e-01,  2.7689e-01, -9.0964e-02,  2.8372e-02, -2.2063e-02,\n",
       "            6.9261e-02, -5.6236e-02, -1.9999e-01,  1.8862e-01, -1.5326e-01,\n",
       "           -3.6330e-01,  3.2553e-01, -2.9602e-01,  5.4247e-01, -1.0543e-01,\n",
       "            2.4652e-01, -3.1158e-01,  6.0507e-02, -1.1382e-01,  2.1669e-01,\n",
       "           -4.8741e-01, -3.6028e-01, -8.1489e-02,  1.6468e-01,  2.8163e-01,\n",
       "           -4.3885e-01,  2.4529e-01,  1.9741e-01,  4.9871e-01,  1.8778e-01,\n",
       "            3.6798e-01, -3.0779e-01, -1.1230e-01,  2.7424e-01, -2.8933e-01,\n",
       "           -2.9128e-01,  3.4580e-01,  1.7615e-01,  7.9139e-02, -3.5904e-01,\n",
       "            2.8086e-01, -1.1222e-02,  1.9113e-01,  2.0955e-01,  1.5482e-01,\n",
       "            3.4569e-01,  9.5667e-04,  4.3419e-02, -4.2046e-01,  4.8303e-01,\n",
       "            1.6833e-01,  9.0638e-02, -2.5004e-01,  2.0604e-01,  2.4454e-01,\n",
       "            2.2046e-01, -6.1329e-02, -2.2732e-02, -2.1066e-01, -1.4977e-01,\n",
       "           -2.9840e-02,  2.0199e-01, -6.4613e-02, -2.8883e-01,  2.0319e-01,\n",
       "            7.2136e-02,  1.3485e-01,  1.3576e-02,  1.7922e-02,  1.7547e-01,\n",
       "            1.3835e-01, -3.9046e-01,  2.2940e-01,  1.8291e-01,  2.0807e-01,\n",
       "           -2.2569e-01, -2.9900e-02,  6.2334e-02,  2.1889e-02, -5.1538e-02,\n",
       "           -1.4083e-01,  7.7445e-02,  3.0725e-03,  1.4882e-01, -1.7370e-01,\n",
       "            1.5212e-01,  2.7116e-01, -4.5852e-01, -4.8236e-01, -3.5571e-02,\n",
       "            1.1856e-01,  1.7693e-01, -4.2301e-01, -1.0706e-01, -2.0326e-01,\n",
       "           -1.9102e-01, -5.9045e-02,  1.1182e-01, -2.8514e-01,  8.4865e-02,\n",
       "           -4.7489e-03,  9.8063e-02,  3.1238e-02, -9.0909e-03, -2.4478e-01,\n",
       "           -2.5520e-01,  1.5577e-01,  1.2585e-01, -2.5393e-01,  1.0287e-01,\n",
       "            2.3344e-01, -3.1502e-02,  6.0048e-02, -1.9212e-01,  3.4511e-01,\n",
       "            4.1721e-02, -1.4691e-01,  3.2897e-01,  1.4400e-01, -2.1948e-01,\n",
       "           -2.6827e-02, -6.4998e-02,  1.8498e-02, -1.2929e-01,  4.8235e-02,\n",
       "           -5.3204e-02, -8.0775e-02, -2.4531e-02,  8.5210e-02, -8.4754e-02,\n",
       "           -2.6989e-02,  1.2803e-01,  4.3190e-02, -1.9579e-01,  7.2644e-02,\n",
       "            7.5348e-03,  1.8134e-02, -3.6583e-02,  5.6689e-02,  3.2735e-02,\n",
       "           -2.4838e-01, -2.3444e-01, -2.8758e-02,  1.1956e-02, -1.2217e-01,\n",
       "            5.1484e-02, -8.0686e-02,  8.2554e-02,  9.3060e-03,  5.6610e-02,\n",
       "            4.5088e-02,  3.6615e-01,  1.1229e+00,  1.1411e+00, -1.1074e+00,\n",
       "            6.8034e-01, -1.0244e+00, -7.0154e-01, -1.8035e-01,  9.0875e-01,\n",
       "           -7.0264e-01,  9.2362e-01,  1.0179e+00, -1.1040e+00, -1.1280e+00,\n",
       "           -1.1138e+00,  7.5295e-01,  9.6290e-01, -7.6484e-01, -9.8134e-01,\n",
       "           -9.1194e-01,  1.9811e-01, -7.2635e-01,  8.2478e-01, -2.5716e-01,\n",
       "           -8.0051e-01, -6.9300e-01, -1.0991e+00,  2.9620e-01,  2.9356e-01,\n",
       "            9.9227e-01,  1.2062e+00, -5.1108e-01, -1.1595e+00,  3.4521e-02,\n",
       "           -1.6720e-01, -1.3013e-01,  8.4172e-02, -5.7655e-02, -3.0451e-02,\n",
       "           -1.3718e-01, -7.6300e-02, -9.9223e-02,  1.4125e-01, -5.7756e-02,\n",
       "            8.0224e-02,  7.0454e-03,  7.0392e-02,  4.8049e-02, -9.5729e-03,\n",
       "            4.5325e-02, -2.4275e-01,  3.9566e-02,  4.6581e-01, -1.3908e-01,\n",
       "           -2.1035e-02,  1.5880e-01, -1.6166e-01,  1.0456e-01, -7.0207e-02,\n",
       "           -6.2976e-02, -5.6199e-02,  6.0075e-02,  3.1571e-02,  1.5527e-01,\n",
       "            1.7625e-02], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.1257,  0.0188, -0.1270,  ..., -0.3900, -0.1655,  0.0899],\n",
       "           [ 0.0512,  0.0714,  0.1065,  ...,  0.0250, -0.2034, -0.2118],\n",
       "           [-0.1593, -0.3430, -0.0810,  ..., -0.2164,  0.1289,  0.1455],\n",
       "           ...,\n",
       "           [-0.0014,  0.1082, -0.1842,  ..., -0.3206,  0.0028,  0.3726],\n",
       "           [ 0.1291,  0.1831, -0.1222,  ..., -0.0037, -0.0651,  0.0213],\n",
       "           [-0.1274,  0.2012, -0.0424,  ...,  0.0366,  0.2831, -0.1862]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.2129,  0.0708,  0.3235,  0.2044,  0.2338,  0.5157,  0.3921, -0.1766,\n",
       "            0.3268, -0.1852, -0.2869, -0.3719, -0.1355,  0.3783,  0.4396, -0.0867,\n",
       "           -0.4914, -0.4128,  0.3870, -0.3473, -0.3341,  0.4346,  0.2874, -0.4636,\n",
       "            0.3089, -0.4079, -0.4517, -0.4670,  0.2291, -0.4035, -0.2707,  0.2652,\n",
       "           -0.0185,  0.3539, -0.1678,  0.0958,  0.1416,  0.1146, -0.3304,  0.5489,\n",
       "            0.3532,  0.4687,  0.1618,  0.4108, -0.3205,  0.3380, -0.3720,  0.4009,\n",
       "            0.3086, -0.1280,  0.0265,  0.3795,  0.5187, -0.4877, -0.3703,  0.0871,\n",
       "            0.0290, -0.3185, -0.4621, -0.4898, -0.1169,  0.1099,  0.5103,  0.4497,\n",
       "           -0.4157,  0.2584, -0.1614, -0.4541,  0.3324,  0.0158, -0.1064, -0.1152,\n",
       "            0.4524, -0.0882, -0.1214,  0.0062,  0.0243, -0.0285, -0.1949,  0.0921,\n",
       "            0.1243, -0.0256,  0.2623, -0.0712,  0.3705,  0.3943,  0.0526,  0.0708,\n",
       "           -0.2192,  0.4699, -0.3324,  0.2718, -0.3041, -0.2249, -0.2360, -0.2946,\n",
       "            0.0915,  0.2675, -0.4160,  0.2188, -0.3299, -0.0828, -0.3397, -0.3054,\n",
       "           -0.5458, -0.2574,  0.3456, -0.4856,  0.3206, -0.3820,  0.3299,  0.4284,\n",
       "           -0.3138, -0.0102, -0.4691,  0.3842, -0.3225,  0.1141, -0.2729, -0.3984,\n",
       "           -1.2024, -0.1872, -0.5187, -0.5803, -0.3986,  0.2989, -0.2933,  0.4691,\n",
       "            0.7338,  0.4241, -0.3200, -0.4750,  0.3726, -0.3756,  0.1391, -0.4970,\n",
       "            0.0667,  0.2055, -0.5554,  0.1727, -0.3143, -0.7004, -0.0643,  0.3237,\n",
       "            0.2261, -0.2306, -0.2097,  0.4114,  0.2180,  0.0740, -0.4217, -0.4349,\n",
       "            0.0473,  0.2277, -0.2007,  0.2410,  0.5397,  0.3320, -0.5482,  0.0315,\n",
       "            0.2517,  0.0500,  0.1633, -0.0847,  0.4479,  0.1411, -0.0085, -0.5273,\n",
       "            0.1640,  0.1997,  0.1474, -0.2534, -0.1099, -0.3267,  0.4187, -0.5075,\n",
       "            0.3730, -0.2068, -0.0695, -0.3959,  0.0184, -0.0053,  0.5667, -0.1936,\n",
       "           -0.1839,  0.4257,  0.2584,  0.3246,  0.1337, -0.2203,  0.3455,  0.0635,\n",
       "            0.3129,  0.0526,  0.3940, -0.3782,  0.1989,  0.0428,  0.4131,  0.1330,\n",
       "           -0.0354, -0.1824,  0.3899, -0.5007, -0.0421, -0.0861,  0.5231, -0.2925,\n",
       "            0.3246,  0.3882, -0.2517, -0.0771,  0.5569, -0.3671,  0.4050,  0.3874,\n",
       "            0.3885, -0.8694, -0.2221,  0.4782, -0.3390,  0.3855,  0.0205,  0.2502,\n",
       "            0.2356,  0.1492,  0.1361, -0.1551, -0.0047,  0.2335,  0.2594, -0.0024,\n",
       "            0.2886,  0.4765, -0.2309,  0.4672, -0.1407,  0.1231,  0.3604,  0.3547,\n",
       "           -0.0903,  0.4892, -0.1750,  0.5215, -0.2912,  0.1004,  0.3731,  0.0883,\n",
       "            0.1303, -0.0919,  0.0856, -0.2177,  0.5181,  0.3166, -0.3080,  0.0725],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.2886, -0.1608,  0.0127,  ..., -0.2383,  0.0367, -0.1411],\n",
       "           [-0.4584, -0.2055,  0.4530,  ..., -0.1381,  0.0969,  0.0587],\n",
       "           [ 0.2091,  0.0420,  0.0755,  ..., -0.3753, -0.6633, -0.1073],\n",
       "           ...,\n",
       "           [-0.1072, -0.1686, -0.0065,  ...,  0.0666,  0.3668, -0.0413],\n",
       "           [-0.3071, -0.0594,  0.6502,  ..., -0.0578, -0.2205, -0.0119],\n",
       "           [ 0.3003, -0.0919,  0.9990,  ...,  0.4706, -0.5887, -0.1682]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.1583, -0.0868,  0.1694, -0.5429, -0.1704, -0.4705, -0.7822,  0.5029,\n",
       "           -0.0412, -0.2777,  0.5310, -0.2064, -0.2972, -0.5669, -0.8654,  0.2888,\n",
       "           -0.3209, -0.6011, -0.1687,  0.1072, -0.7593,  0.1285, -0.0261,  0.2102,\n",
       "           -0.1287, -0.2923, -0.2095, -0.6938,  0.1800, -0.0759, -0.5673, -0.3806,\n",
       "           -0.0935, -0.1888, -0.1929, -0.2846, -0.2777, -0.3445, -0.5963,  0.6503,\n",
       "           -0.3175, -0.1364, -0.1448,  0.2397, -0.1945, -0.2048, -0.2249, -0.1356,\n",
       "           -0.1585, -0.7704, -0.3532,  0.2690, -0.1956, -0.4606,  0.1378,  0.0183,\n",
       "           -0.2068, -0.3025, -0.2508, -0.6184, -0.4905, -0.6021, -0.2643,  0.2047],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.3314,  0.0149, -0.3376,  ..., -0.0276, -0.0126, -0.0401],\n",
       "           [ 0.2051,  0.1128, -0.2126,  ..., -0.0344, -0.1647,  0.1994],\n",
       "           [ 0.2165, -0.0410,  0.4359,  ...,  0.0055,  0.1389,  0.0701],\n",
       "           ...,\n",
       "           [ 0.0987, -0.0896,  0.1151,  ..., -0.1798, -0.3949, -0.0473],\n",
       "           [ 0.0226, -0.0090,  0.0218,  ...,  0.1454, -0.1108,  0.1104],\n",
       "           [-0.1075, -0.3269,  0.4075,  ..., -0.0113, -0.1220, -0.1101]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 2.5792e-01,  1.3726e-02, -1.8363e-01, -4.0406e-02, -4.9827e-01,\n",
       "           -9.7923e-02,  8.1332e-02,  1.6798e-01, -1.7560e-01,  8.3685e-02,\n",
       "           -3.0248e-01, -7.2391e-02,  2.3567e-01,  4.4169e-02, -2.8409e-01,\n",
       "           -9.8856e-02, -1.8391e-01, -3.6821e-02, -2.2143e-01, -1.2069e-01,\n",
       "           -5.0577e-02, -6.7099e-02,  2.3582e-01, -4.4526e-01, -1.9345e-01,\n",
       "           -6.5287e-02, -3.0388e-01,  1.2247e-01, -3.0117e-02, -5.4691e-02,\n",
       "           -1.1632e-01, -2.5552e-02, -7.5175e-02,  3.2838e-01, -6.8779e-02,\n",
       "           -2.9469e-01,  2.0806e-01, -3.3923e-01,  4.0018e-01,  1.0310e-01,\n",
       "           -4.7325e-02,  2.0724e-02,  3.7268e-01, -6.5824e-02,  1.0880e-01,\n",
       "           -3.5404e-02, -6.7984e-02, -1.4213e-01,  1.1509e-01,  2.3344e-01,\n",
       "           -3.6047e-01, -1.7012e-01,  6.0484e-01,  2.8076e-01,  3.0220e-02,\n",
       "           -7.2612e-02, -4.8011e-02,  1.1474e-01, -5.3860e-02, -4.6950e-01,\n",
       "           -1.2961e-01, -2.4399e-01,  3.6824e-01, -1.8625e-01, -1.9135e-01,\n",
       "            4.8475e-02, -1.0348e-01,  1.4810e-01,  1.9816e-02,  2.4288e-01,\n",
       "           -2.1350e-01,  1.0746e-01,  2.2581e-01,  8.3832e-02, -2.4858e-02,\n",
       "           -1.9320e-01,  3.2203e-01,  4.4515e-01,  1.4884e-02,  3.3071e-01,\n",
       "           -3.1266e-01, -9.2338e-02, -4.1463e-01,  2.7432e-01,  7.7699e-02,\n",
       "           -1.4107e-01, -8.7503e-02, -3.3976e-01, -4.6071e-02,  5.1421e-01,\n",
       "            3.7158e-02,  1.6109e-01, -4.6256e-02, -6.3151e-02,  3.4805e-01,\n",
       "            3.3565e-01,  4.3442e-02,  5.7108e-01,  4.1724e-02, -9.6271e-02,\n",
       "           -6.6659e-02,  1.1721e-01, -1.4063e-01,  3.9944e-01,  5.5004e-01,\n",
       "           -7.3648e-02, -6.4630e-02, -1.1590e-01,  4.2151e-01, -2.6745e-01,\n",
       "           -1.9453e-01, -1.1989e-01,  5.2424e-02, -1.5148e-01, -1.0335e-01,\n",
       "           -3.7835e-02,  1.8488e-02,  2.1373e-01, -2.0846e-01, -2.1964e-02,\n",
       "           -1.5944e+00, -6.0012e-03,  1.2198e+00, -4.0356e-01, -2.2388e-01,\n",
       "           -6.6072e-02, -1.7690e-01, -3.6639e-01,  6.3921e-01, -2.7895e-01,\n",
       "            1.9480e-01, -2.3800e-01, -2.3964e-01, -6.8945e-03,  3.3852e-02,\n",
       "           -9.0014e-02, -3.7821e-03,  3.0840e-01,  9.0375e-02,  3.3011e-01,\n",
       "            2.0458e-01, -5.2025e-02, -1.0834e-01, -8.9757e-02,  3.1592e-01,\n",
       "            1.6520e-01, -5.1326e-02, -6.9553e-03,  1.1419e-01,  7.2876e-02,\n",
       "            2.6494e-02, -6.7960e-02,  3.6899e-01, -3.0736e-02, -2.5939e-01,\n",
       "            1.8087e-01,  2.1681e-01, -2.8852e-01, -1.7782e-01,  5.3519e-01,\n",
       "           -1.1512e-01, -7.8181e-02, -4.1367e-01,  1.7426e-02, -4.7420e-01,\n",
       "           -1.2846e-01,  1.3898e-01,  1.2846e-01, -3.3712e-01, -3.1518e-02,\n",
       "           -2.8143e-01, -7.7984e-01,  3.2275e-01,  1.1352e-01, -2.9728e-01,\n",
       "           -1.9015e-01, -1.0509e-01, -1.3011e-01, -1.1799e-01,  3.2084e-02,\n",
       "            3.6663e-01, -3.1707e-01,  2.3680e-01,  3.5216e-02, -3.2280e-01,\n",
       "            3.1175e-01, -1.2269e-01,  3.9735e-01,  5.1724e-02, -6.6432e-02,\n",
       "           -1.4564e-01, -3.8638e-01, -7.9503e-02,  1.0968e-01,  2.5033e-01,\n",
       "            1.0311e-01, -1.0099e-01, -9.3663e-02,  7.5780e-02,  3.8806e-01,\n",
       "           -2.5264e-01,  1.3469e-01, -6.5376e-02,  2.9613e-02, -2.9669e-01,\n",
       "            1.1134e-01,  8.0730e-01, -2.0752e-01,  3.9414e-02, -2.1269e-01,\n",
       "           -2.2292e-01, -1.4414e-01, -1.0732e-01, -8.9883e-02,  3.8991e-02,\n",
       "           -2.8835e-01,  5.3035e-01, -2.0800e+00,  3.1444e-01,  3.9424e-01,\n",
       "           -2.8614e-01,  1.1115e-01, -2.0513e-01, -1.4581e-02,  2.2385e-02,\n",
       "            1.2317e-01,  1.2514e-01,  5.1560e-02,  1.2702e-01, -1.1014e-01,\n",
       "           -1.2203e-01,  3.3917e-01, -1.6228e-02,  3.1612e-01, -2.6536e-01,\n",
       "            8.4155e-04,  3.7651e-02,  1.4440e-01, -1.1839e-01,  2.7185e-01,\n",
       "           -9.9079e-02, -1.9393e-01, -7.7577e-02, -1.2731e-02, -8.6837e-02,\n",
       "           -2.4403e-01,  9.8975e-03, -1.8952e-01,  8.8677e-03, -2.4391e-01,\n",
       "           -4.8345e-02, -1.9757e-01,  2.9812e-01,  5.6036e-02,  1.6639e-01,\n",
       "           -1.7617e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0390, -0.0053,  0.0362,  ...,  0.0204,  0.0346, -0.0483],\n",
       "           [-0.0224, -0.0128,  0.0247,  ...,  0.0257,  0.0056,  0.0093],\n",
       "           [ 0.0291, -0.0616,  0.0169,  ..., -0.1399, -0.0013, -0.0899],\n",
       "           ...,\n",
       "           [-0.0650, -0.1912,  0.1374,  ..., -0.0614,  0.4259, -0.2113],\n",
       "           [ 0.0896, -0.0102,  0.0419,  ..., -0.2156,  0.3007, -0.3725],\n",
       "           [ 0.4506, -0.3095,  0.3703,  ..., -0.1171, -0.0515,  0.2758]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([1.3208, 0.8040, 1.6904, 1.3186, 1.3691, 1.2836, 1.4757, 1.4393, 1.7165,\n",
       "           1.5560, 1.7824, 1.8129, 1.7671, 1.9374, 1.6311, 2.0751, 1.6129, 1.9293,\n",
       "           1.7629, 2.0692, 1.6239, 1.9671, 1.7085, 1.8293, 1.7676, 1.8467, 1.6994,\n",
       "           1.6169, 1.5119, 2.0778, 1.4899, 1.7043, 1.4381, 1.6516, 1.3834, 1.6733,\n",
       "           1.4778, 1.6499, 1.4350, 1.5690, 1.4942, 1.5905, 1.4694, 1.4707, 1.4089,\n",
       "           1.5109, 1.4631, 1.4659, 1.3926, 1.5326, 1.4295, 1.4731, 1.3933, 1.5538,\n",
       "           1.4340, 1.3999, 1.4433, 1.4913, 1.4918, 1.3692, 1.5193, 1.3457, 1.4597,\n",
       "           1.4589, 1.4420, 1.4204, 1.4114, 1.4420, 1.4045, 1.4802, 1.3923, 1.4690,\n",
       "           1.4045, 1.3979, 1.3821, 1.3135, 1.3910, 1.3280, 1.4448, 1.3378, 1.4206,\n",
       "           1.4352, 1.5085, 1.3290, 1.4617, 1.3043, 1.3504, 1.3935, 1.3735, 1.3857,\n",
       "           1.3984, 1.3734, 1.4468, 1.3413, 1.4384, 1.3660, 1.3925, 1.3262, 1.3832,\n",
       "           1.3649, 1.3807, 1.3614, 1.4458, 1.3587, 1.4006, 1.3179, 1.3924, 1.3385,\n",
       "           1.4001, 1.3913, 1.4148, 1.3514, 1.4705, 1.3987, 1.3966, 1.3255, 1.4200,\n",
       "           1.2873, 1.3254, 1.4349, 1.5036, 1.3700, 1.4885, 1.3239, 1.3824, 1.3424,\n",
       "           1.3970, 1.3158, 1.4345, 1.3824, 1.3766, 1.2855, 1.4020, 1.3336, 2.0190,\n",
       "           1.9406, 1.3796, 1.3083, 1.3711, 1.2974, 1.4134, 1.3718, 1.5182, 1.3012,\n",
       "           1.3343, 1.3306, 1.4578, 2.1992, 1.3912, 1.3545, 1.4050, 1.2746, 1.6221,\n",
       "           1.3380, 1.7964, 1.3078, 1.3829, 1.4754, 1.3343, 1.3276, 1.4371, 1.3243,\n",
       "           1.4311, 1.3641, 1.4831, 1.3975, 1.4227, 1.3873, 1.3664, 1.3508, 1.3470,\n",
       "           1.3517, 1.4080, 1.3132, 1.3137, 1.3449, 1.5695, 1.3331, 1.4605, 1.3218,\n",
       "           1.3954, 1.3246, 1.5522, 1.4074, 1.3703, 1.3258, 1.5298, 1.3076, 1.3346,\n",
       "           1.3776, 2.3943, 1.3529, 1.3995, 1.3128, 1.3821, 1.3684, 1.4241, 1.4427,\n",
       "           1.3677, 1.2540, 1.3732, 1.3544, 1.3344, 1.3655, 1.3416, 1.2825, 1.4290,\n",
       "           1.3309, 1.3841, 1.4015, 2.2799, 1.5031, 1.4239, 1.3292, 1.4201, 1.4084,\n",
       "           1.4095, 1.3016, 1.4247, 1.3781, 1.3330, 1.3160, 1.3456, 1.3011, 1.4271,\n",
       "           1.3233, 1.3958, 1.3036, 1.3886, 1.4225, 1.5033, 1.4079, 1.3736, 1.2829,\n",
       "           1.4373, 1.3960, 1.3893, 1.3517, 1.4574, 1.3286, 1.4742, 1.7314, 1.4194,\n",
       "           1.3629, 1.4204, 1.4041, 1.4507, 1.3558, 1.4249, 1.4458, 1.5146, 1.3662,\n",
       "           1.3666, 1.3271, 1.4167, 1.3355], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0410, -0.9312,  0.6049, -0.0044, -0.1211,  0.0373,  0.0025, -0.1433,\n",
       "            0.1087, -0.1393,  0.1405,  0.0548, -0.2319,  0.0710, -0.1075,  0.1719,\n",
       "           -0.1066, -0.6556, -0.1108, -0.1466, -0.1831,  0.0842, -0.0082, -0.0184,\n",
       "           -0.4106, -0.0465,  0.1267, -0.0810,  0.1217,  1.2941,  0.1727, -0.0846,\n",
       "            0.0687,  0.0819,  0.1556,  0.1422,  0.1837,  0.0578,  0.2552,  0.1264,\n",
       "            0.0663,  0.0737,  0.0864,  0.0945,  0.0148,  0.0824,  0.0214,  0.0769,\n",
       "            0.2168,  0.1315,  0.0623,  0.1134,  0.0865,  0.0820,  0.0517,  0.1103,\n",
       "            0.0953,  0.0727,  0.1751,  0.2353, -0.0305,  0.1738,  0.0268,  0.1825,\n",
       "            0.1191,  0.0609,  0.0767,  0.0467, -0.0701,  0.2342, -0.1371,  0.0261,\n",
       "            0.0291,  0.1500, -0.2218,  0.0282, -0.0599,  0.0067, -0.0367,  0.1042,\n",
       "           -0.0061,  0.1204, -0.0431,  0.1321, -0.0790,  0.1145, -0.1874,  0.0677,\n",
       "           -0.0261, -0.1788, -0.0035,  0.0983, -0.1337,  0.1027,  0.0553, -0.0294,\n",
       "           -0.0508,  0.0128, -0.0667,  0.0964, -0.0411,  0.0867, -0.0400,  0.1407,\n",
       "           -0.0534,  0.1144, -0.0808,  0.1303,  0.0273,  0.1058, -0.0270,  0.1318,\n",
       "           -0.1186,  0.0644,  0.0639,  0.1071,  0.0521,  0.0823, -0.0451,  0.0099,\n",
       "           -0.1932, -0.0126, -0.0802, -0.0882,  0.0098,  0.0854,  0.0242,  0.0179,\n",
       "            0.0319,  0.0481, -0.0526, -0.0386,  0.0576, -0.0796, -1.1547,  0.2248,\n",
       "           -0.0290, -0.0310, -0.1063, -0.0767, -0.0930,  0.1270, -0.0834,  0.0473,\n",
       "           -0.0423,  0.0297, -0.0784,  0.0140, -0.0264, -0.0639, -0.0585,  0.0042,\n",
       "           -0.1598,  0.0796, -0.4139,  0.0277, -0.0212,  0.0640, -0.1870,  0.0241,\n",
       "           -0.0945, -0.0893, -0.0845, -0.0588,  0.0650, -0.1245, -0.1242,  0.1150,\n",
       "           -0.1126, -0.1088, -0.0336,  0.0500, -0.1412,  0.0381,  0.0569, -0.0838,\n",
       "           -0.2534, -0.0430,  0.0329, -0.0406, -0.0888,  0.1226,  0.0988, -0.0820,\n",
       "           -0.0833, -0.0161, -0.1724,  0.1038, -0.1066, -0.0137, -0.5861, -0.0467,\n",
       "           -0.0338, -0.0611, -0.0171,  0.0251, -0.0906,  0.1006, -0.1756, -0.0499,\n",
       "            0.0260,  0.0319,  0.0412,  0.0068, -0.0833, -0.0544, -0.0077, -0.0147,\n",
       "           -0.0685,  0.2479, -0.4986, -0.1000,  0.0278,  0.0052,  0.0070, -0.1044,\n",
       "           -0.1096,  0.0443, -0.0904, -0.2300, -0.1285, -0.0959, -0.7669, -0.0942,\n",
       "            0.0541, -0.0457, -0.0142,  0.0074, -0.0344,  0.0515, -0.0948,  0.1429,\n",
       "            0.0335, -0.0972,  0.0256,  0.0175,  0.0247,  0.0074, -0.0694,  0.0571,\n",
       "            0.0091,  0.1906,  0.0292, -0.0491,  0.0036,  0.0815, -0.1809, -0.0080,\n",
       "           -0.0531,  0.0991, -0.1960,  0.0197, -0.0107,  0.0994, -0.0928,  0.0024],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([1.0860, 0.8771, 2.0231, 1.1606, 1.1374, 1.2474, 1.1428, 1.1461, 1.2404,\n",
       "           1.0615, 0.9521, 1.2000, 1.2680, 1.1976, 1.0667, 1.1858, 1.0406, 0.8980,\n",
       "           1.1821, 1.1538, 1.0176, 1.1620, 1.0925, 1.1323, 1.0991, 1.1653, 1.1020,\n",
       "           1.1202, 1.0988, 2.3962, 1.0619, 1.2032, 1.0847, 1.1381, 1.0598, 1.1117,\n",
       "           1.0872, 1.0989, 1.0535, 1.1008, 1.3230, 1.2842, 1.0942, 1.1082, 1.1273,\n",
       "           1.2112, 1.1574, 1.0970, 1.1420, 1.0692, 1.0997, 1.0722, 1.0963, 1.2038,\n",
       "           1.1117, 1.0273, 1.1490, 1.0642, 1.2385, 1.0934, 1.2247, 1.0402, 1.1357,\n",
       "           1.2806, 1.1579, 1.0580, 1.1123, 1.0928, 1.1229, 1.1117, 1.1229, 1.0491,\n",
       "           1.0846, 1.0840, 1.1383, 1.0389, 1.1004, 1.0845, 1.0929, 1.0467, 1.0860,\n",
       "           1.1127, 1.1425, 1.0675, 1.1225, 1.0342, 1.1585, 1.0756, 1.0933, 1.1873,\n",
       "           1.0893, 1.0953, 1.0882, 1.0476, 1.1217, 1.0756, 1.1034, 1.0934, 1.1162,\n",
       "           1.0871, 1.1037, 1.0782, 1.1323, 1.1006, 1.1326, 1.0932, 1.0982, 1.0941,\n",
       "           1.0809, 1.1462, 1.0991, 1.0870, 1.1932, 1.1684, 1.0895, 1.0673, 1.1924,\n",
       "           1.0941, 1.0548, 1.1145, 1.2651, 1.0944, 1.0747, 1.0884, 1.1144, 1.1506,\n",
       "           1.0737, 1.0529, 1.0651, 1.0841, 1.0803, 1.0716, 1.1126, 1.0812, 2.8010,\n",
       "           2.2244, 1.0683, 1.0493, 1.0787, 1.0330, 1.0633, 1.0358, 1.1947, 1.0907,\n",
       "           1.0852, 1.1262, 1.0859, 2.7670, 1.1646, 1.1136, 1.0383, 1.1313, 1.2151,\n",
       "           1.0874, 1.7670, 1.1422, 1.0840, 1.1773, 1.1277, 1.1374, 1.1465, 1.1200,\n",
       "           1.1324, 1.1039, 1.0817, 1.1782, 1.0924, 1.1295, 1.1207, 1.1833, 1.0970,\n",
       "           1.0915, 1.2170, 1.0826, 1.0607, 1.1343, 1.0806, 1.1162, 1.1475, 1.0765,\n",
       "           1.0753, 1.0730, 1.2227, 1.1710, 1.0778, 1.0536, 1.1313, 1.0685, 1.0940,\n",
       "           1.1114, 2.8002, 1.1337, 1.1182, 1.0987, 1.1105, 1.1401, 1.1189, 1.1027,\n",
       "           1.1034, 1.0802, 1.0847, 1.1190, 1.0580, 1.1292, 1.0952, 1.0789, 1.2402,\n",
       "           1.0960, 1.0676, 1.1074, 2.7069, 1.4916, 1.1144, 1.0629, 1.1136, 1.1488,\n",
       "           1.1505, 1.0414, 1.1245, 0.9340, 1.0386, 1.1012, 1.1762, 1.0870, 1.1264,\n",
       "           1.0596, 1.1176, 1.0321, 1.0878, 1.4740, 1.1579, 1.1156, 1.1120, 1.0974,\n",
       "           1.1032, 1.1519, 1.0795, 1.0859, 1.1587, 1.1465, 1.1156, 1.7993, 1.1238,\n",
       "           1.2102, 1.1441, 1.0568, 1.2293, 1.0588, 1.1365, 1.3776, 1.1509, 1.0720,\n",
       "           1.0623, 1.2308, 1.1656, 1.0540], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-3.1237e-02, -1.3791e+00, -3.8142e-01,  1.3573e-01,  3.8238e-02,\n",
       "           -2.4799e-02, -1.3418e-01, -3.3171e-01, -2.4836e-01, -2.6529e-01,\n",
       "            4.4302e-01, -4.5574e-01, -6.5965e-01, -1.4777e-01,  2.5005e-01,\n",
       "           -1.9632e-01,  4.3457e-01, -1.2945e+00, -4.2477e-02,  1.0083e-01,\n",
       "            2.4803e-01,  2.2944e-01,  2.7097e-01,  3.2239e-01, -1.0701e+00,\n",
       "            2.2292e-01, -3.7294e-02,  7.9247e-02,  1.5509e-01,  5.3140e-01,\n",
       "           -2.1323e-02,  8.7846e-02, -5.2053e-02,  1.5663e-01, -1.3357e-01,\n",
       "            3.3563e-01,  7.6286e-02,  2.2566e-01, -3.2410e-01,  2.3228e-01,\n",
       "           -4.7648e-02, -2.8669e-01, -8.0589e-02, -7.1737e-02, -1.0525e-01,\n",
       "           -2.1365e-01, -7.1355e-02, -3.3017e-02, -1.0670e-01,  3.1414e-01,\n",
       "           -2.1828e-01,  4.7859e-02,  1.4967e-01, -3.1383e-01, -2.7626e-01,\n",
       "            1.6925e-01, -1.2727e-01,  3.2522e-03,  3.8284e-01, -3.3003e-02,\n",
       "           -2.0566e-01,  2.2947e-01,  2.9871e-01, -4.3883e-01,  3.0119e-01,\n",
       "            3.1085e-02,  2.5784e-01,  3.2600e-01,  1.9344e-02,  1.8975e-01,\n",
       "           -1.0993e-01,  3.5318e-01,  3.6069e-02,  2.4771e-01,  1.0513e-02,\n",
       "           -3.1313e-03, -1.7752e-02, -1.7159e-01, -8.3953e-02,  6.6669e-02,\n",
       "           -1.7057e-01, -1.0644e-01, -1.2195e-01,  2.8322e-01,  1.6294e-02,\n",
       "            2.0547e-01, -8.9632e-02,  6.8465e-02,  8.3088e-02, -3.7239e-01,\n",
       "           -4.8635e-02, -4.3152e-02, -4.8619e-01,  1.4182e-01, -1.9054e-01,\n",
       "           -1.1986e-01, -1.4337e-01,  2.7361e-02,  2.7140e-01,  9.7289e-02,\n",
       "           -2.0596e-02,  1.5206e-01, -1.8987e-01, -3.7666e-01, -1.0519e-01,\n",
       "            2.9562e-02,  6.6913e-02,  1.9986e-02,  9.4664e-02,  1.9122e-01,\n",
       "           -4.5405e-02, -7.1230e-02, -3.6743e-02,  2.6222e-01,  3.1755e-01,\n",
       "            6.4550e-02,  7.6282e-03, -2.4279e-02,  8.2120e-02, -1.3037e-01,\n",
       "           -3.0607e-01,  4.9870e-02, -4.0607e-01,  1.0037e-01,  6.0830e-02,\n",
       "           -1.0647e-02, -1.1630e-03, -2.4676e-01,  1.9783e-01, -1.8122e-02,\n",
       "            7.1648e-02, -4.2285e-03,  2.0664e-01, -8.7336e-03, -1.0662e+00,\n",
       "            2.0473e-01,  5.8902e-02,  1.1275e-01,  1.9979e-01, -1.4541e-01,\n",
       "           -3.9071e-01,  8.7159e-04, -8.9622e-02,  8.7056e-02,  6.5491e-02,\n",
       "           -5.0227e-02, -1.3273e-01,  8.8734e-01,  1.7290e-01, -8.9932e-02,\n",
       "           -1.7031e-01,  7.2001e-02, -4.2606e-01, -7.2541e-02, -3.4557e-01,\n",
       "            2.5466e-01, -6.9551e-02,  2.6521e-01,  1.2465e-01,  4.2000e-03,\n",
       "            7.2012e-02,  2.1017e-01, -8.4726e-02, -5.4132e-02,  1.4683e-01,\n",
       "           -9.9310e-02,  3.4109e-03, -6.4507e-02,  6.9219e-02, -2.1476e-01,\n",
       "            2.5784e-03, -4.1149e-02, -2.8390e-01, -6.0265e-02,  9.4272e-02,\n",
       "            4.1985e-02, -6.4671e-01, -2.9280e-02,  1.8579e-01, -1.3113e-01,\n",
       "           -4.2609e-02,  3.3744e-01, -2.0798e-01, -1.1447e-01,  7.5982e-02,\n",
       "            6.3317e-02, -2.8377e-01, -4.2652e-02, -1.0434e-01,  1.5590e-01,\n",
       "            1.6559e-01,  1.0762e-01, -2.0585e-01, -6.6579e-03,  1.1234e-01,\n",
       "            2.6304e-01,  1.2485e-01, -1.2088e-01,  5.7953e-02,  1.2034e-02,\n",
       "            9.0075e-02,  1.6541e-01,  1.1052e-01,  1.6353e-01, -6.7712e-02,\n",
       "           -6.8200e-03, -2.6873e-01,  4.2884e-02,  9.2846e-02,  3.5614e-01,\n",
       "           -5.9072e-01,  2.6658e-01, -8.8225e-02,  1.4170e-01, -1.1120e-01,\n",
       "            2.1793e-01, -1.7775e-01,  8.2745e-03, -1.8748e-02, -8.5423e-01,\n",
       "            1.0413e-01,  1.2811e-01, -9.3022e-01, -6.2013e-02, -1.7098e-01,\n",
       "            1.4385e-01, -1.2415e-01, -3.7781e-03,  2.1823e-01,  5.0148e-01,\n",
       "           -3.6890e-01,  7.1975e-01, -5.2268e-02,  3.9305e-02, -6.4110e-02,\n",
       "            2.2616e-01,  1.2317e-01,  1.2240e-01, -1.8120e-01,  7.4665e-02,\n",
       "           -5.7741e-02,  4.6131e-01,  7.9546e-02,  1.8529e-01, -3.6579e-03,\n",
       "            8.2967e-02, -2.0443e-01,  2.1029e-01, -2.9455e-01,  4.9789e-01,\n",
       "           -3.1540e-01,  8.7406e-02,  9.9104e-02, -5.5879e-02, -4.6545e-03,\n",
       "            8.5855e-02], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0.2968, 0.1550, 0.0417, 0.2047, 0.1707, 0.1739, 0.1841, 0.1853, 0.1874,\n",
       "           0.2096, 0.2343, 0.2038, 0.1563, 0.2373, 0.3050, 0.2673, 0.3323, 0.2360,\n",
       "           0.2941, 0.2514, 0.3367, 0.2878, 0.2922, 0.3491, 0.2082, 0.2988, 0.3047,\n",
       "           0.3340, 0.3392, 0.0133, 0.3506, 0.2715, 0.3155, 0.3273, 0.2957, 0.3020,\n",
       "           0.2926, 0.3246, 0.3639, 0.3558, 0.1763, 0.2615, 0.3006, 0.3199, 0.3107,\n",
       "           0.2727, 0.2704, 0.3632, 0.3032, 0.3205, 0.2838, 0.3509, 0.2676, 0.2806,\n",
       "           0.2904, 0.3138, 0.2733, 0.3188, 0.2181, 0.3339, 0.2674, 0.3270, 0.2802,\n",
       "           0.2269, 0.2722, 0.3280, 0.2977, 0.2985, 0.3058, 0.2823, 0.2839, 0.3260,\n",
       "           0.2910, 0.3216, 0.3105, 0.3457, 0.2474, 0.3400, 0.2665, 0.3433, 0.3017,\n",
       "           0.2911, 0.2930, 0.2977, 0.2917, 0.3182, 0.2323, 0.3068, 0.3651, 0.2757,\n",
       "           0.3237, 0.3015, 0.2737, 0.3082, 0.3019, 0.2546, 0.3067, 0.3278, 0.3021,\n",
       "           0.2906, 0.3084, 0.3284, 0.2968, 0.3174, 0.2511, 0.3494, 0.3158, 0.3038,\n",
       "           0.3193, 0.2236, 0.3182, 0.3034, 0.2322, 0.2355, 0.3275, 0.3263, 0.2915,\n",
       "           0.3099, 0.3046, 0.2889, 0.2032, 0.3094, 0.2509, 0.3081, 0.3144, 0.2770,\n",
       "           0.3164, 0.3225, 0.3342, 0.2779, 0.2907, 0.3225, 0.3019, 0.3280, 0.0295,\n",
       "           0.1145, 0.3272, 0.2930, 0.3034, 0.3452, 0.2364, 0.3220, 0.2727, 0.3118,\n",
       "           0.3227, 0.2324, 0.2863, 0.0363, 0.2696, 0.2890, 0.3139, 0.2455, 0.2508,\n",
       "           0.2668, 0.1425, 0.2801, 0.3221, 0.2681, 0.3189, 0.3037, 0.2852, 0.2555,\n",
       "           0.2872, 0.2773, 0.3132, 0.2446, 0.3080, 0.3058, 0.3083, 0.2760, 0.3200,\n",
       "           0.3088, 0.2319, 0.3169, 0.3123, 0.2814, 0.2512, 0.2365, 0.2780, 0.3007,\n",
       "           0.3190, 0.2821, 0.2545, 0.2890, 0.3178, 0.3281, 0.2693, 0.3216, 0.3157,\n",
       "           0.2741, 0.0182, 0.3002, 0.2837, 0.2956, 0.2635, 0.2480, 0.2893, 0.2936,\n",
       "           0.2418, 0.3304, 0.3425, 0.2904, 0.3080, 0.2944, 0.3306, 0.2881, 0.2505,\n",
       "           0.2691, 0.3132, 0.2603, 0.0824, 0.1695, 0.2587, 0.3056, 0.2895, 0.3068,\n",
       "           0.2881, 0.3189, 0.3067, 0.1901, 0.3029, 0.3231, 0.2942, 0.3072, 0.3095,\n",
       "           0.2444, 0.3241, 0.3240, 0.3182, 0.2080, 0.2757, 0.2276, 0.3017, 0.3174,\n",
       "           0.3400, 0.2965, 0.3112, 0.3487, 0.3045, 0.2700, 0.2837, 0.1526, 0.3169,\n",
       "           0.2233, 0.3089, 0.3142, 0.2532, 0.3130, 0.2644, 0.2254, 0.2290, 0.3230,\n",
       "           0.3275, 0.2091, 0.2964, 0.3035], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-7.0362e-03,  2.5499e-02, -2.6141e-02, -1.5023e-03, -4.6691e-03,\n",
       "           -4.4816e-03, -8.3307e-03,  4.7718e-03, -3.3809e-03,  6.5164e-03,\n",
       "           -1.7691e-02,  4.3046e-04,  1.3443e-02,  2.7850e-03, -1.1400e-02,\n",
       "           -5.4934e-03, -1.8973e-02,  3.6777e-02, -5.6472e-03, -1.0769e-02,\n",
       "           -1.8809e-02, -1.3128e-02, -1.9538e-02, -2.1833e-02,  2.4487e-02,\n",
       "           -1.2289e-02, -1.6129e-02, -1.7260e-02, -1.7710e-02, -9.5069e-02,\n",
       "           -1.5198e-02, -9.5199e-03, -1.0912e-02, -1.7019e-02, -1.0044e-02,\n",
       "           -1.9120e-02, -1.7825e-02, -2.2128e-02, -7.6685e-03, -2.7454e-02,\n",
       "           -1.0604e-02,  4.8053e-03, -1.7547e-02, -6.3266e-03, -9.3005e-03,\n",
       "            7.0924e-04, -6.7597e-03, -1.9332e-02, -4.5116e-03, -3.0391e-02,\n",
       "           -2.2896e-03, -2.5240e-02, -1.5766e-02, -2.6018e-03,  8.0257e-04,\n",
       "           -1.9072e-02,  1.4766e-03, -1.2761e-02, -1.0270e-02, -1.6680e-02,\n",
       "            1.0478e-03, -1.6307e-02, -1.4967e-02,  2.5043e-03, -1.7270e-02,\n",
       "           -1.1487e-02, -1.8961e-02, -1.9665e-02, -1.2155e-02, -2.3062e-02,\n",
       "           -2.9062e-03, -2.0600e-02, -8.2661e-03, -2.2988e-02, -3.2744e-03,\n",
       "           -1.1850e-02, -6.3461e-03, -1.3543e-02, -7.8272e-03, -1.6987e-02,\n",
       "           -4.1606e-04, -1.3003e-02, -1.4669e-03, -2.1144e-02,  3.4273e-04,\n",
       "           -2.3960e-02,  2.6534e-05, -1.5704e-02, -1.1894e-02, -3.9305e-03,\n",
       "           -4.7822e-03, -1.6306e-02,  1.3223e-02, -1.5629e-02,  8.0948e-04,\n",
       "           -8.6656e-03, -5.4973e-03, -1.3901e-02, -9.0318e-03, -1.8467e-02,\n",
       "           -1.2847e-03, -2.3519e-02,  1.1920e-03, -2.4239e-03,  5.8834e-03,\n",
       "           -2.2402e-02, -9.0244e-03, -1.1692e-02, -7.5568e-03, -1.2030e-02,\n",
       "           -6.7571e-03, -1.1054e-02, -3.9115e-03, -1.9234e-02, -1.0987e-02,\n",
       "           -1.6339e-02, -5.5885e-03, -1.6888e-02, -1.1723e-02, -8.4696e-03,\n",
       "            2.3900e-03, -1.7973e-02,  8.4025e-03, -1.9386e-02, -1.1675e-02,\n",
       "           -1.0447e-02, -4.3503e-03, -2.1121e-03, -6.6752e-03, -1.0311e-02,\n",
       "           -9.1924e-03, -1.8419e-02, -1.1030e-02, -1.3227e-02,  5.4040e-02,\n",
       "           -2.2818e-02,  2.6522e-03, -1.8876e-02, -1.2987e-02, -1.0837e-02,\n",
       "            1.0858e-02, -1.2718e-02, -2.3909e-03, -8.3848e-03, -1.1440e-02,\n",
       "           -8.9021e-03, -2.5634e-03,  1.5128e-01, -3.6872e-03, -1.1735e-02,\n",
       "           -1.3771e-04, -1.2352e-02,  1.7806e-03, -1.4119e-02,  7.5362e-03,\n",
       "           -2.1713e-02, -5.1621e-03, -2.1843e-02, -6.9847e-03, -7.1982e-03,\n",
       "           -1.0427e-02, -1.1252e-02, -7.5612e-04, -1.6681e-02, -1.2870e-02,\n",
       "            9.5901e-04, -4.6891e-03, -9.3939e-03, -8.9846e-03, -7.3234e-03,\n",
       "           -5.1041e-03, -1.5243e-02,  8.8352e-03, -8.7216e-03, -9.9038e-03,\n",
       "           -1.6887e-02,  2.1160e-02, -4.3064e-03, -1.0088e-02, -6.7108e-03,\n",
       "           -7.2238e-03, -2.0463e-02,  4.1859e-03, -1.3369e-02, -7.8922e-03,\n",
       "           -1.9464e-02,  8.6673e-03, -8.3168e-03,  4.6485e-04, -2.1741e-02,\n",
       "            2.0144e-01, -1.5206e-02,  3.0929e-03, -1.5543e-02, -7.4260e-03,\n",
       "           -2.1992e-02, -1.0158e-02, -2.2195e-03, -7.2296e-03, -1.3510e-02,\n",
       "           -6.0181e-03, -1.6229e-02, -1.7334e-02, -1.6723e-02, -1.2676e-02,\n",
       "           -1.7691e-02, -1.2724e-04, -1.2358e-02, -3.6685e-03, -2.3377e-02,\n",
       "            5.2299e-02, -2.5290e-02,  4.8525e-03, -2.0258e-02, -5.6918e-03,\n",
       "           -2.0423e-02,  1.4274e-03, -1.7617e-02,  1.4024e-03,  1.2081e-02,\n",
       "           -6.9734e-03, -1.9206e-02,  2.8367e-02, -1.0696e-02,  4.3416e-03,\n",
       "           -1.2591e-02, -8.2099e-04, -8.9454e-03, -1.7526e-02, -1.9544e-02,\n",
       "            7.6451e-03, -3.2511e-02, -9.9748e-04, -1.4259e-02, -5.2089e-03,\n",
       "           -2.5972e-02, -6.6291e-03, -2.3043e-02,  2.4615e-04, -1.0896e-02,\n",
       "            3.6940e-03, -2.5171e-02, -9.6882e-03, -1.3180e-02, -3.9534e-03,\n",
       "           -1.0812e-02, -4.1823e-04, -1.9336e-02,  4.4671e-04, -3.6025e-02,\n",
       "            2.8591e-03, -1.6294e-02, -1.0747e-02, -5.1213e-03, -7.4760e-03,\n",
       "           -9.9389e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.1906,  0.3320, -0.0255,  ..., -0.5697,  0.0248, -0.0948],\n",
       "           [-0.5825,  0.7498, -0.3900,  ...,  0.2143,  0.1446,  0.4017],\n",
       "           [-0.1751,  0.0522, -0.4753,  ...,  0.7009, -0.1644,  0.1399],\n",
       "           ...,\n",
       "           [ 0.8567, -0.4358, -0.3962,  ...,  0.2045,  0.2950, -0.0282],\n",
       "           [ 0.8379,  0.0821, -0.5676,  ...,  0.2466, -0.2216,  0.0146],\n",
       "           [ 0.4304, -0.0720,  0.2920,  ...,  0.6958,  0.3557,  0.3636]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-1.4146e+00, -7.5633e-02,  1.1980e+00, -6.1786e-01,  1.1566e+00,\n",
       "            6.5517e-02,  1.0356e+00, -1.1126e+00,  1.4166e-01, -2.7882e-01,\n",
       "            8.1907e-01,  4.8589e-01,  8.5730e-01, -9.8850e-01,  6.0478e-01,\n",
       "            1.6397e+00, -6.0661e-01,  1.4815e-02, -1.3613e+00, -9.7277e-01,\n",
       "           -6.4981e-01,  1.3737e+00, -5.5879e-01, -8.7871e-02, -9.9829e-01,\n",
       "           -1.1860e+00,  9.9714e-01,  8.6319e-01, -1.1840e+00, -1.0746e+00,\n",
       "            1.4872e+00,  1.7021e-01,  9.3339e-01, -1.1515e+00,  7.4341e-02,\n",
       "           -2.5449e+00,  4.0337e-01, -1.0255e+00, -7.9261e-01, -4.5210e-02,\n",
       "           -8.8526e-01, -1.2616e+00, -1.8206e+00, -1.7168e+00, -7.5475e-01,\n",
       "           -1.5773e+00, -2.7361e-01, -1.2265e+00,  1.1736e+00, -1.7254e+00,\n",
       "           -1.2750e-01,  5.7766e-01,  8.9446e-02, -1.7463e+00,  7.6542e-01,\n",
       "           -1.1429e+00, -1.6707e+00, -1.1895e+00, -7.1944e-01, -9.0884e-01,\n",
       "            8.1434e-01, -1.8180e+00,  2.2784e+00, -7.2079e-01,  2.0670e+00,\n",
       "            1.1758e+00, -1.0830e+00,  1.0276e+00,  9.4614e-01,  4.6101e-01,\n",
       "           -6.0737e-02,  1.9968e+00, -2.1609e-03,  2.0236e+00,  1.7089e+00,\n",
       "           -5.3298e-01, -1.0522e+00, -1.6025e-01, -1.5730e+00,  8.8000e-01,\n",
       "            1.4941e+00,  6.7703e-01, -1.6150e+00, -4.8329e-01,  1.1137e-02,\n",
       "            1.2470e+00,  7.3806e-01,  1.7153e+00, -8.9601e-01,  5.7706e-01,\n",
       "           -1.6881e+00, -6.6272e-01, -5.8336e-01, -7.2536e-02,  1.0228e-01,\n",
       "            4.2442e-01, -4.3263e-02, -7.7763e-01, -1.1042e-01, -1.3309e+00,\n",
       "            8.1612e-02, -6.2729e-01, -2.0114e+00,  1.7953e+00, -1.9358e+00,\n",
       "            2.3403e-01, -6.8330e-01,  6.5878e-01,  8.7927e-01, -5.7818e-01,\n",
       "           -2.1838e-02, -1.8362e+00,  3.0107e-01, -3.8593e-01,  2.1741e+00,\n",
       "           -1.2835e+00, -2.3616e+00,  2.1333e+00,  8.2517e-01, -1.1635e+00,\n",
       "           -8.1146e-01,  1.6087e-01, -2.2282e+00,  5.1216e-01, -2.7954e-01,\n",
       "           -1.1355e+00, -7.5535e-01, -3.8637e-01, -3.3330e-01,  6.2430e-01,\n",
       "           -1.1241e+00,  8.1988e-01, -4.0739e-01,  1.3130e+00,  3.0941e-02,\n",
       "            3.0092e-01, -6.2598e-01,  1.5303e+00, -1.0668e+00,  1.3271e+00,\n",
       "           -3.3510e-01,  1.1664e+00,  9.7909e-01,  1.5176e+00,  1.6172e+00,\n",
       "           -9.8167e-01,  7.7934e-01, -7.6478e-01,  4.8153e-01, -3.3128e-02,\n",
       "            4.1317e-01,  8.9998e-02, -1.1937e+00,  2.0786e+00, -8.5959e-01,\n",
       "           -5.8808e-01, -1.2941e+00,  7.1886e-01, -2.3118e-01,  1.0743e+00,\n",
       "            1.0463e+00, -1.4575e+00,  1.2037e+00,  2.0463e+00, -8.8944e-01,\n",
       "            1.5189e+00,  2.1116e+00,  1.5641e+00, -1.2650e+00, -1.6879e+00,\n",
       "           -7.8424e-03,  2.2376e+00,  1.7888e+00, -4.7129e-01,  2.3882e-01,\n",
       "           -1.2061e+00, -1.5480e+00,  2.0805e+00,  2.2626e+00,  1.2165e+00,\n",
       "            7.8840e-01,  1.2156e+00, -1.3783e+00, -2.5786e-01,  5.9395e-01,\n",
       "            2.0581e+00, -1.2947e-01,  7.3806e-01,  2.9716e-01,  2.1128e+00,\n",
       "            4.2780e-01, -3.7432e-01,  1.0520e+00,  6.0016e-01,  1.1659e+00,\n",
       "           -5.7470e-01, -2.8008e-01,  8.2892e-01,  1.4579e+00,  2.3619e-01,\n",
       "           -1.4098e+00,  3.9433e-01, -4.6633e-01, -1.0576e+00,  6.8849e-01,\n",
       "           -5.9443e-01,  1.0026e+00, -1.2239e+00,  1.2920e+00,  1.1936e+00,\n",
       "            6.6668e-01, -8.1362e-01,  3.8633e-01, -7.1507e-02,  4.6139e-02,\n",
       "            1.3020e+00,  7.2388e-01,  1.4197e+00, -6.4778e-01, -7.8714e-01,\n",
       "            1.3509e+00,  3.7283e-01, -1.1496e+00, -2.3178e-01, -2.6812e-01,\n",
       "           -1.3783e+00,  1.0819e+00, -1.9587e+00,  1.7750e+00, -4.1792e-01,\n",
       "           -7.5161e-01, -7.9179e-01, -1.4077e+00, -1.3849e+00, -1.5551e+00,\n",
       "           -1.9302e+00,  2.8171e-01,  5.1726e-01, -4.0117e-01,  2.0370e+00,\n",
       "           -1.6036e+00, -6.0743e-01, -1.0348e+00,  1.1252e+00,  1.0960e+00,\n",
       "            8.1575e-02,  1.9459e+00, -3.6111e-01, -8.4152e-01,  1.5524e+00,\n",
       "            1.0775e+00,  4.6589e-01, -1.2145e+00,  5.3747e-01,  1.1482e+00,\n",
       "            1.8695e+00], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.1517,  0.0593,  0.3002,  ...,  0.7616, -0.2186,  0.0859],\n",
       "           [-0.2600, -0.5463, -0.1668,  ..., -0.1054,  0.0140,  0.0941],\n",
       "           [ 0.3431, -0.0669, -0.0500,  ..., -0.2393,  0.2132,  0.2835],\n",
       "           ...,\n",
       "           [ 0.0761,  0.1654, -0.0116,  ..., -0.1904, -0.2638,  0.3485],\n",
       "           [ 0.1596, -0.2452,  0.1647,  ..., -0.1704,  0.2334,  0.3334],\n",
       "           [-0.0328,  0.5001, -0.0084,  ..., -0.3601, -0.1974, -0.0442]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 3.6573e-04, -8.2117e-04,  1.8153e-04,  1.0352e-03,  1.2351e-03,\n",
       "            2.0755e-03,  8.0625e-04,  1.2971e-03, -5.9876e-04, -2.4284e-03,\n",
       "           -8.8066e-05,  3.7389e-04,  1.5703e-03, -8.3726e-04, -1.3402e-04,\n",
       "           -1.7450e-04,  9.5806e-04,  1.0298e-03, -3.5731e-04, -4.9162e-04,\n",
       "            1.0702e-03,  6.8124e-04,  6.7307e-05,  7.9191e-04,  9.7889e-04,\n",
       "           -9.3009e-05,  3.8142e-04,  4.4026e-04, -2.0493e-04, -9.6890e-04,\n",
       "            1.3686e-03, -4.1107e-04,  3.4565e-04, -9.3413e-05,  6.5533e-05,\n",
       "           -1.7986e-03,  1.3334e-03, -5.8289e-04, -1.3692e-03, -2.5442e-04,\n",
       "            1.1732e-03, -2.8171e-03, -6.4810e-04, -4.8920e-04, -4.0668e-04,\n",
       "           -6.8668e-04,  1.0015e-03, -5.7223e-04,  8.0309e-04, -1.1057e-03,\n",
       "           -4.8435e-05,  1.5658e-04,  9.6083e-04,  3.6294e-04,  4.4020e-04,\n",
       "           -7.9838e-04, -1.1653e-04,  5.0203e-04,  1.7830e-03, -1.0260e-03,\n",
       "            1.8317e-03, -1.1000e-03,  1.1284e-03, -6.1407e-04,  1.3451e-04,\n",
       "           -2.9907e-03, -3.1460e-04, -2.0890e-03, -1.5326e-03,  2.3639e-03,\n",
       "            6.9731e-04,  6.3822e-04,  1.4062e-03,  1.5168e-03, -2.0415e-03,\n",
       "           -4.1099e-05,  1.0320e-03,  1.1763e-03,  1.3696e-03, -1.0392e-03,\n",
       "           -1.3434e-03, -8.2520e-04, -3.3081e-04, -2.1496e-03,  2.6834e-03,\n",
       "           -2.9374e-03,  2.8489e-04, -1.0376e-03,  2.8924e-03,  3.8030e-04,\n",
       "            2.0463e-03, -7.6445e-04, -5.4462e-04, -3.2490e-04, -1.8357e-03,\n",
       "            9.9690e-04, -2.0739e-04,  4.7528e-04, -7.6725e-04,  3.5297e-03,\n",
       "           -3.0221e-03,  1.1135e-03,  1.3984e-03, -8.0194e-04,  1.0772e-03,\n",
       "            1.4027e-03,  5.6297e-04, -3.9091e-04, -1.1554e-03,  1.6873e-03,\n",
       "           -1.1941e-04,  1.1969e-03,  1.0937e-03, -4.4390e-04, -1.7795e-03,\n",
       "            1.3886e-03,  4.2444e-04, -1.0580e-03, -5.0572e-04,  9.9964e-04,\n",
       "            1.3385e-03, -4.9166e-04, -4.1284e-04,  2.4007e-04, -3.9331e-04,\n",
       "            2.8080e-04,  1.6254e-03, -1.6363e-04, -7.3837e-04, -2.1088e-03,\n",
       "            1.1435e-03,  5.7205e-04,  1.2336e-03,  6.2244e-04, -1.0746e-03,\n",
       "            1.9243e-03,  1.3922e-03, -6.5902e-05,  1.1888e-03,  4.3059e-04,\n",
       "            8.0732e-05,  8.4019e-04,  2.7514e-04,  4.6666e-04,  6.0517e-04,\n",
       "            4.6214e-04,  1.6644e-03, -8.7735e-04, -2.0474e-03,  3.5636e-04,\n",
       "            2.4002e-03,  7.4285e-04, -6.3809e-04,  1.5812e-03,  2.1099e-04,\n",
       "           -1.3166e-03,  1.4051e-03,  1.9174e-03,  3.4898e-04, -1.7978e-03,\n",
       "           -1.2272e-03,  8.7337e-04, -3.2655e-04,  1.9201e-04, -1.0235e-03,\n",
       "           -1.0750e-03, -1.0785e-03, -1.3530e-03,  1.4080e-03,  6.2407e-06,\n",
       "            9.2763e-04, -1.4611e-04, -7.8351e-04,  9.3086e-05, -2.5547e-04,\n",
       "           -3.1738e-04, -3.5511e-05,  1.1069e-05, -7.4318e-04,  1.2517e-03,\n",
       "            8.9904e-04, -1.2937e-03,  1.0688e-03, -1.1172e-03,  1.9650e-03,\n",
       "           -7.2197e-04,  1.3295e-03, -1.2372e-03,  2.8406e-04, -3.7056e-04,\n",
       "            2.8516e-05,  7.0591e-05,  5.2325e-04, -1.8540e-04,  6.3518e-04,\n",
       "           -3.3999e-04,  2.1455e-04,  7.0308e-04,  1.2331e-03,  5.0135e-04,\n",
       "           -1.1098e-03,  1.4237e-03, -1.0980e-04, -1.9658e-04, -6.6636e-04,\n",
       "           -2.2634e-04,  1.1596e-03, -1.0513e-03,  9.4545e-04,  9.1872e-04,\n",
       "            5.6566e-04, -6.7845e-04, -7.7198e-05, -7.0120e-04, -3.5608e-04,\n",
       "            7.1734e-04,  3.1570e-04,  1.4350e-03, -1.0042e-03, -8.5905e-05,\n",
       "            6.7991e-04, -5.4420e-04, -8.3216e-05,  9.1347e-04, -9.5445e-04,\n",
       "           -2.2189e-03,  2.0085e-03, -5.1619e-04,  1.9809e-05,  1.7048e-03,\n",
       "            2.3936e-03, -6.2994e-04,  1.2006e-04, -1.8412e-03, -1.7115e-03,\n",
       "           -5.4319e-05,  2.4232e-04,  2.4400e-03,  2.3953e-03,  3.0062e-03,\n",
       "           -1.4696e-03, -3.6276e-04, -2.1396e-04,  6.7700e-04,  3.5290e-03,\n",
       "            2.4683e-04,  2.3997e-03,  8.1027e-04, -5.1210e-04, -1.1796e-03,\n",
       "           -4.7139e-04,  3.0229e-03, -1.3877e-03, -1.3452e-03, -9.1838e-04,\n",
       "            2.8352e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0218, -0.0034,  0.0047,  ...,  0.0481,  0.0345, -0.0242],\n",
       "           [-0.0278, -0.0429,  0.0138,  ...,  0.0272, -0.0855, -0.0003],\n",
       "           [ 0.0527, -0.0338, -0.0566,  ..., -0.0038,  0.0491,  0.0198],\n",
       "           ...,\n",
       "           [-0.0115,  0.0342,  0.0003,  ..., -0.0895,  0.0141, -0.0053],\n",
       "           [-0.0161,  0.0619,  0.0131,  ..., -0.0398,  0.0431,  0.0167],\n",
       "           [ 0.0111, -0.0186,  0.0105,  ...,  0.0086, -0.0196, -0.0829]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-8.2759e-03,  4.5400e-02,  1.1308e-02,  8.3729e-02, -6.5162e-02,\n",
       "            5.1925e-03,  5.5046e-02,  3.9663e-03, -2.9847e-02, -2.6344e-03,\n",
       "            4.0671e-02,  1.1288e-04, -1.1711e-01,  1.3990e-01,  8.9345e-02,\n",
       "            7.1144e-03,  1.7487e-01, -1.0610e-02, -1.6759e-02, -4.1163e-02,\n",
       "           -1.2009e-01, -3.6206e-02, -5.8552e-02, -5.9580e-02, -7.4017e-03,\n",
       "           -7.4717e-02,  4.9792e-03, -1.0722e-01, -1.7668e-02, -3.8496e-02,\n",
       "           -2.1463e-01,  7.1548e-02, -6.5206e-02,  7.9535e-02,  1.9779e-02,\n",
       "           -7.3788e-02,  1.6817e-01,  2.1638e-01, -6.9356e-02, -3.3410e-02,\n",
       "            4.2691e-03, -1.2926e-01, -1.3360e-02, -7.8539e-02,  1.0931e-01,\n",
       "           -4.4739e-02, -6.3724e-02, -1.8083e-02,  5.9208e-02,  1.5999e-02,\n",
       "           -3.9468e-03, -1.1924e-01, -5.8072e-02,  8.2416e-02,  3.8038e-02,\n",
       "            6.2274e-02, -3.0806e-02,  5.0859e-03, -1.1165e-01, -8.3874e-02,\n",
       "           -6.1611e-02, -8.3391e-04,  1.5479e-02, -8.3132e-02,  5.4647e-03,\n",
       "           -6.4286e-02, -3.9683e-02, -7.1153e-03,  3.5874e-02, -9.1888e-02,\n",
       "           -4.1714e-02, -9.9272e-02,  3.7627e-02, -1.0979e-01, -6.9678e-03,\n",
       "           -1.2850e-02, -3.7671e-02,  1.6940e-01,  1.2208e-01, -3.2277e-02,\n",
       "           -1.4308e-01,  3.9772e-02,  3.9548e-02, -8.1460e-02,  1.2807e-01,\n",
       "           -7.0932e-02,  1.4929e-02, -5.8534e-02, -1.8930e-02,  5.1668e-02,\n",
       "           -4.9034e-02, -7.1165e-02,  7.0810e-02,  5.4153e-03, -2.7934e-02,\n",
       "            9.3049e-02, -8.7281e-02,  3.9792e-02, -7.6330e-02,  5.3942e-02,\n",
       "           -4.3292e-02,  5.0712e-02, -6.7585e-02,  3.2877e-02,  3.1555e-02,\n",
       "           -5.4510e-02, -1.3106e-01, -7.6404e-02,  5.2214e-02, -1.9105e-02,\n",
       "            8.9749e-02, -1.0124e-01,  3.0456e-02,  9.4526e-03, -1.2396e-02,\n",
       "            5.8441e-03,  1.4567e-02,  1.0248e-01,  6.6805e-02, -4.8233e-02,\n",
       "            4.4859e-02, -8.2433e-02,  1.0473e-01, -4.5882e-02, -5.8990e-02,\n",
       "           -1.7855e-02,  1.1823e-01,  1.1545e-01,  4.8152e-02,  9.6035e-02,\n",
       "            3.5008e-03, -6.5867e-02, -7.1357e-02, -4.6186e-02,  8.0909e-02,\n",
       "            3.7356e-02,  3.3986e-02, -1.4756e-01,  1.5059e-02,  1.5491e-02,\n",
       "           -8.8038e-02,  6.6520e-02, -1.9209e-02, -1.7778e-01,  5.0642e-02,\n",
       "           -2.4753e-02, -1.0088e-01,  8.8254e-02,  1.0380e-01,  4.4448e-02,\n",
       "            5.5731e-02, -3.3228e-02,  1.2353e-01,  9.6135e-02, -1.5451e-02,\n",
       "            5.2348e-02, -1.5225e-01, -1.4180e-02, -5.3596e-02,  6.4138e-03,\n",
       "           -4.9880e-02, -5.4938e-02, -4.5869e-03, -2.3368e-02, -1.6374e-02,\n",
       "           -5.8125e-02,  1.0835e-01,  2.0213e-02, -6.4870e-02,  1.3558e-02,\n",
       "           -6.2102e-02, -1.0976e-01,  6.5848e-02, -9.7435e-02,  9.9674e-02,\n",
       "            1.6480e-02,  7.3937e-02, -4.3629e-02, -2.5499e-02,  5.7578e-02,\n",
       "           -8.8916e-02, -3.8291e-02,  8.3569e-02,  2.0037e-01,  7.9413e-02,\n",
       "            3.7096e-02, -2.8742e-02,  3.0539e-02,  6.5987e-03, -4.0458e-02,\n",
       "            8.3832e-02,  7.0776e-02, -7.9979e-02, -2.8584e-02, -3.6531e-02,\n",
       "            1.2812e-02,  6.6321e-02, -3.7360e-02, -5.9863e-02,  3.5234e-02,\n",
       "           -5.9332e-02, -3.2735e-02,  5.9748e-02,  5.9747e-02,  9.8020e-03,\n",
       "            1.1094e-02, -6.1900e-02, -2.3102e-02, -2.6966e-02, -1.1523e-01,\n",
       "            2.5872e-02, -7.3025e-03, -2.9692e-02,  2.4649e-03, -6.7151e-02,\n",
       "           -1.2691e-02, -3.4248e-02, -5.2511e-02,  1.3434e-01,  9.9623e-02,\n",
       "           -8.1749e-02, -1.4660e-03, -6.4204e-02, -2.5861e-02,  5.3190e-02,\n",
       "            1.2375e-02,  1.7550e-02,  8.2715e-02, -3.5705e-02, -9.4260e-02,\n",
       "           -1.4307e-01, -3.4964e-02, -4.7639e-02, -1.8581e-02, -5.8826e-02,\n",
       "           -5.4651e-02,  1.9312e-02,  5.0492e-02, -1.0388e-01, -4.1851e-02,\n",
       "           -6.6575e-02, -6.5726e-02, -7.6160e-02,  1.0627e-02,  4.8681e-02,\n",
       "           -1.1612e-01,  6.7319e-02,  1.0387e-02,  6.2716e-02, -4.3867e-02,\n",
       "            3.8048e-02, -1.2001e-01, -1.2100e-01, -1.2538e-01, -5.2319e-02,\n",
       "            5.3213e-02], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0530,  0.0205,  0.0175,  ...,  0.0606,  0.0174,  0.0063],\n",
       "           [-0.1417,  0.0217,  0.0166,  ...,  0.0170, -0.0144,  0.0903],\n",
       "           [ 0.0451, -0.0521,  0.0014,  ...,  0.0179, -0.0385, -0.0200],\n",
       "           ...,\n",
       "           [-0.0496,  0.0220,  0.0507,  ..., -0.0448, -0.0335,  0.0387],\n",
       "           [-0.0738,  0.0230,  0.0085,  ..., -0.0043, -0.0202, -0.0064],\n",
       "           [-0.0394,  0.0174,  0.0307,  ..., -0.0310, -0.0368, -0.0699]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 1.2908e-01, -1.7831e-01,  3.3373e-01,  1.7470e-01,  9.7832e-02,\n",
       "            2.5177e-01,  1.4196e-01,  1.5556e-01,  2.4843e-01,  2.3040e-01,\n",
       "           -5.1220e-02,  2.2513e-01,  1.9852e-01,  1.6689e-01,  8.9839e-03,\n",
       "            1.7876e-01, -1.6084e-01, -2.2106e-02,  1.0049e-01,  1.9568e-02,\n",
       "            1.9988e-02, -5.1263e-02,  2.7976e-02, -4.8420e-02,  1.3166e-01,\n",
       "           -1.3308e-02,  6.8591e-02,  4.9514e-02, -2.7622e-02,  1.1157e+00,\n",
       "            2.7900e-02,  3.2113e-03,  6.9029e-02,  5.9423e-02,  8.2086e-02,\n",
       "            4.1341e-02,  8.3739e-02,  5.0133e-02,  1.1467e-01,  1.6789e-02,\n",
       "            8.1852e-03,  4.1712e-02,  1.8552e-01,  4.5727e-02,  6.4852e-02,\n",
       "            8.4954e-02,  9.1145e-02,  1.3157e-01,  4.6980e-02,  8.9604e-02,\n",
       "            1.2209e-01,  5.3544e-02,  1.4239e-01,  2.0574e-01,  1.3521e-01,\n",
       "            1.0607e-01,  1.3952e-01,  9.1655e-02, -2.1442e-01,  3.5303e-02,\n",
       "            1.1017e-01,  9.1629e-02, -1.3719e-01,  2.6291e-01, -4.5713e-03,\n",
       "            8.7636e-02, -6.4710e-02,  3.7845e-02,  6.7470e-02,  1.1249e-01,\n",
       "            2.4176e-02, -7.1647e-02, -5.9951e-02, -6.4233e-02, -9.8052e-03,\n",
       "            1.3458e-01, -7.1781e-02,  1.1441e-01,  4.7859e-02,  1.1157e-01,\n",
       "            4.6374e-02,  9.9628e-02, -5.4357e-02, -4.4101e-02,  8.1407e-02,\n",
       "            2.3414e-02, -1.8925e-01,  2.0353e-02, -1.7568e-02,  1.4955e-01,\n",
       "            5.7034e-03,  7.8821e-02,  1.0450e-01,  2.9988e-02,  9.3453e-02,\n",
       "            1.0547e-01,  6.0861e-02,  4.7508e-02, -2.1720e-01,  6.6426e-02,\n",
       "           -5.7463e-02, -5.6751e-02, -4.1589e-03,  2.1912e-01, -5.8217e-02,\n",
       "           -5.5454e-02, -1.3131e-02,  4.7345e-02, -1.3224e-01,  1.6572e-02,\n",
       "           -4.7330e-02,  4.9272e-02, -8.1020e-02, -1.5642e-01, -1.5994e-01,\n",
       "           -8.3126e-02, -3.7161e-04, -2.4215e-02, -1.4385e-01, -6.2479e-03,\n",
       "            7.5857e-03,  2.7338e-02, -4.5966e-02,  4.0764e-02, -1.0346e-01,\n",
       "            3.4927e-02, -3.7001e-02,  8.1295e-02, -1.8648e-01,  8.4072e-02,\n",
       "           -1.5405e-02, -5.6737e-02, -1.4767e-01,  3.2785e-03, -6.9911e-01,\n",
       "            1.0013e-01, -5.4573e-02,  3.1910e-02, -1.1146e-01,  1.3686e-01,\n",
       "           -4.5204e-02, -5.8459e-03, -8.4469e-03, -2.5125e-02, -1.8658e-02,\n",
       "            4.0601e-02, -9.9931e-02, -2.9628e-01, -1.3111e-01, -5.7906e-02,\n",
       "            1.0284e-02, -4.3854e-02,  8.7100e-02,  4.7003e-02,  2.7571e-02,\n",
       "           -1.4980e-01, -5.6572e-02, -4.6052e-02, -1.1307e-01, -5.6816e-02,\n",
       "           -8.3887e-03, -1.1507e-01,  1.6833e-01, -4.7705e-02, -8.7090e-02,\n",
       "           -3.3342e-02,  1.6495e-03, -2.6319e-02, -2.0506e-02,  7.7126e-02,\n",
       "            3.4616e-02,  1.3986e-02,  7.4908e-03,  3.4064e-02, -1.4104e-01,\n",
       "           -1.1906e-01,  7.3133e-02, -8.0962e-02, -1.1911e-01,  1.2504e-01,\n",
       "           -3.0337e-02, -1.5056e-01,  5.6264e-02, -5.7890e-02, -7.4264e-02,\n",
       "           -9.7551e-02, -5.3266e-02,  5.9455e-03, -1.0711e-02, -1.3340e-01,\n",
       "           -4.7955e-01, -6.6973e-02, -1.0982e-01,  7.2200e-02, -1.5582e-01,\n",
       "           -6.5363e-02, -1.4437e-01,  5.2235e-02, -8.6767e-02, -4.8752e-02,\n",
       "           -5.7191e-02, -6.2327e-02, -1.0722e-01, -9.8165e-02,  6.7823e-02,\n",
       "           -5.2064e-02,  1.4469e-01, -1.1381e-01, -1.1204e-01, -1.5306e-01,\n",
       "           -2.3789e-01, -3.6977e-02,  1.1103e-02, -1.4427e-01,  5.9460e-02,\n",
       "           -1.4681e-01, -6.1851e-03, -7.2338e-02, -5.8911e-02,  1.5380e-01,\n",
       "            3.0993e-03, -1.0430e-01, -9.7301e-03,  1.1766e-02, -1.3033e-02,\n",
       "           -2.8189e-02,  7.4738e-02, -2.9849e-02, -1.7588e-01, -1.3887e-01,\n",
       "            4.2915e-03, -1.6844e-01, -3.3105e-02, -9.6961e-02,  2.4332e-02,\n",
       "           -1.4817e-01, -1.8880e-02, -6.8493e-02,  7.8504e-02, -2.0345e-01,\n",
       "           -1.2935e-01, -7.0174e-02, -3.9188e-02, -3.1071e-01, -4.7258e-02,\n",
       "           -5.3772e-03,  1.5324e-01, -1.3539e-01,  1.1992e-01, -1.2268e-01,\n",
       "           -1.2780e-02, -7.8495e-02, -1.4620e-01, -1.5464e-01, -3.0954e-02,\n",
       "           -7.4576e-02], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0695, -0.4812,  0.0955,  ...,  0.0877, -0.0350,  0.0921],\n",
       "           [-0.0408, -0.4566, -0.0040,  ..., -0.0657, -0.0954,  0.0682],\n",
       "           [ 0.0232, -0.4102,  0.2254,  ...,  0.0382, -0.2114, -0.1352],\n",
       "           ...,\n",
       "           [ 0.0903,  0.2579,  0.0364,  ..., -0.0842,  0.0361, -0.0305],\n",
       "           [-0.0485, -0.1245,  0.0542,  ...,  0.0509, -0.1569,  0.3740],\n",
       "           [ 0.1279, -0.3811, -0.0803,  ...,  0.0599,  0.0368, -0.0552]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 3.8599e-01,  1.0938e+00,  1.6878e+00, -6.7074e-01,  1.4271e-01,\n",
       "           -1.9925e+00, -6.8138e-01,  7.4780e-01,  1.3053e+00, -9.1250e-01,\n",
       "            1.3152e+00, -3.9541e-01, -5.9370e-01,  1.1975e+00, -3.4425e-01,\n",
       "            1.1822e+00,  1.7034e+00,  9.1584e-01, -1.0088e+00, -5.3804e-01,\n",
       "            2.0393e+00, -1.3067e+00, -1.1733e+00,  5.9265e-01, -1.2113e+00,\n",
       "            3.3233e-01, -3.9914e-01,  1.3129e-01, -9.7977e-01, -1.0862e+00,\n",
       "           -1.9147e+00,  1.8649e+00, -1.1693e+00, -1.0479e+00,  1.4828e+00,\n",
       "            1.1599e+00, -1.5549e+00, -7.1509e-01,  1.3779e+00,  1.6666e-01,\n",
       "           -1.3014e+00, -8.5200e-01, -1.1483e+00, -1.4038e+00,  2.7005e-01,\n",
       "            1.1251e+00, -3.2936e-01, -9.1302e-01,  1.9504e-01, -1.7776e-01,\n",
       "            3.1522e-01, -7.0827e-01, -7.7837e-01, -1.5317e+00, -2.5966e-01,\n",
       "           -4.7040e-01, -1.3044e+00, -5.2922e-01, -2.2991e-01, -1.2790e+00,\n",
       "            6.6966e-01, -1.1069e+00,  3.6017e-01, -1.5176e+00, -6.4053e-01,\n",
       "            1.0787e-01,  3.1981e-02,  1.0395e+00,  5.4715e-01, -1.3875e+00,\n",
       "           -2.9968e-01, -7.0373e-01, -1.1108e-01,  1.8997e-01, -1.3037e+00,\n",
       "           -6.7404e-01, -1.2807e+00, -1.1652e+00,  2.6697e-01, -6.3970e-01,\n",
       "            6.6442e-01,  1.2878e+00, -9.6826e-01,  3.2722e-02, -2.9985e-02,\n",
       "           -5.8084e-01,  6.7395e-01,  8.2401e-01,  7.3871e-01,  7.4653e-01,\n",
       "           -5.9922e-01,  1.6503e-01, -1.4990e+00,  9.6292e-01,  7.3522e-02,\n",
       "           -2.9017e-01,  1.4969e+00,  2.4240e+00,  2.4136e+00,  1.2155e+00,\n",
       "           -2.2224e+00,  2.7729e-03,  2.5545e+00,  1.7296e+00,  4.8503e-01,\n",
       "            1.2347e+00,  6.2103e-01, -2.4456e+00, -1.3051e+00, -1.0426e+00,\n",
       "            9.7285e-01, -8.5600e-02, -2.0191e+00,  1.7410e+00,  1.5207e+00,\n",
       "            1.9066e+00,  2.0304e+00,  2.4409e+00,  2.0178e+00, -3.0128e-01,\n",
       "           -2.0298e+00, -1.6730e+00, -1.6997e+00,  1.6232e+00,  1.7075e+00,\n",
       "            2.8242e+00, -8.1200e-01,  2.6864e-01, -9.8764e-01, -9.4115e-01,\n",
       "            1.3514e+00, -5.3335e-01, -9.1410e-01, -1.4480e+00,  1.1337e+00,\n",
       "            4.1239e-01, -7.5588e-01,  4.7651e-01,  1.0894e+00,  1.0836e+00,\n",
       "            2.9844e-01, -7.3077e-01, -6.1419e-02,  1.0151e+00,  1.2177e+00,\n",
       "           -3.5354e-01,  7.4476e-01,  5.1197e-01, -5.5634e-01, -5.0338e-01,\n",
       "            1.4413e+00, -6.6215e-01,  4.8381e-01, -6.0342e-01,  1.0445e+00,\n",
       "            7.4819e-01,  3.7910e-02, -9.6797e-01,  1.2942e+00, -5.1263e-01,\n",
       "            5.2349e-01,  1.0131e+00,  1.2241e+00, -1.1883e+00, -2.2324e-01,\n",
       "           -5.2960e-01,  8.0459e-01, -8.9065e-01, -9.5363e-01, -6.7294e-02,\n",
       "            6.4632e-01, -8.9471e-01, -6.2343e-01,  6.1347e-01,  7.8701e-03,\n",
       "           -7.2251e-01,  7.4811e-01,  6.1117e-02, -4.4539e-01,  1.1576e+00,\n",
       "            9.0792e-01,  1.0344e+00,  3.3845e-01,  6.7712e-01, -9.7078e-01,\n",
       "           -7.5638e-01,  7.8566e-01,  1.1366e+00, -1.1704e+00, -4.9971e-01,\n",
       "            5.6061e-01, -5.8433e-01, -5.2980e-01,  4.5857e-01,  2.2701e-01,\n",
       "           -9.9923e-01, -8.6945e-01, -4.4083e-01,  1.0469e+00, -2.1047e-01,\n",
       "           -4.4525e-01,  1.0077e+00,  7.9344e-01, -2.2434e-01,  3.4707e-01,\n",
       "           -2.1220e-01, -1.1755e-02, -4.8267e-02, -8.9321e-01, -8.9757e-01,\n",
       "           -8.9061e-01, -1.0798e+00, -5.2045e-01, -8.4261e-01,  2.5803e-01,\n",
       "           -9.6949e-01,  6.7151e-01,  2.2237e-01, -4.4363e-01, -4.2660e-01,\n",
       "            6.6559e-01, -1.0357e-01,  8.3480e-01,  7.0396e-01,  1.6601e-01,\n",
       "           -9.6825e-01, -3.3154e-01, -1.0461e-02, -1.0306e+00,  4.7616e-01,\n",
       "           -2.2795e-01,  7.4182e-01,  5.1426e-01, -8.6329e-01,  4.4470e-01,\n",
       "            1.1152e+00, -1.4007e+00,  1.2472e-01,  1.6689e-01, -8.5762e-01,\n",
       "           -7.1120e-01, -1.9125e-01,  1.3697e-01,  6.0234e-01,  9.1873e-01,\n",
       "            5.5609e-01, -2.2108e-01,  1.8978e-01,  1.0227e+00,  9.0933e-02,\n",
       "           -1.0195e+00, -4.8508e-01,  1.2216e+00,  7.1331e-01, -6.1837e-01,\n",
       "            3.7865e-02], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.2605, -0.0246, -0.0644,  ..., -0.3272, -0.0949,  0.1336],\n",
       "           [ 0.2449, -0.1229,  0.2451,  ...,  0.1404, -0.0773,  0.1270],\n",
       "           [ 0.0225, -0.0932,  0.0179,  ...,  0.0802,  0.0869,  0.1171],\n",
       "           ...,\n",
       "           [ 0.3929, -0.0277,  0.1808,  ...,  0.0547, -0.1934,  0.0109],\n",
       "           [ 0.1145, -0.0214,  0.1946,  ...,  0.2425, -0.1138, -0.0810],\n",
       "           [ 0.2811, -0.1717,  0.4127,  ..., -0.3218, -0.0629, -0.2922]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 2.0619e-02,  2.1120e-02,  2.0965e-02, -2.5371e-02,  5.6922e-05,\n",
       "           -1.9747e-02, -7.6854e-03,  2.9478e-02,  2.0687e-02, -6.2160e-03,\n",
       "            1.8905e-02, -1.1412e-02, -7.0018e-03,  1.9022e-02, -3.7332e-03,\n",
       "            2.2833e-02,  8.3953e-03,  9.5071e-03, -2.0603e-02, -4.6947e-03,\n",
       "            1.8845e-02, -8.0244e-03, -1.5536e-02,  3.5021e-03, -1.6758e-02,\n",
       "            9.3449e-03, -5.6666e-03, -7.9113e-03, -3.5066e-03, -2.5296e-02,\n",
       "           -1.1223e-02,  2.4057e-02, -1.4287e-03,  1.5704e-03, -2.4990e-04,\n",
       "            8.7524e-04, -7.5840e-04, -2.1463e-04, -4.7349e-04, -3.6474e-04,\n",
       "           -3.1889e-06, -5.1320e-04, -3.7284e-04, -5.0141e-04,  1.1063e-03,\n",
       "            9.3486e-04, -5.8563e-04, -1.3979e-04, -1.8893e-04, -1.8038e-03,\n",
       "           -5.6412e-04,  7.6080e-04,  4.9449e-05, -2.9606e-04, -1.8295e-04,\n",
       "           -2.8514e-04, -2.1003e-04,  4.8681e-04, -1.4947e-04,  2.0953e-04,\n",
       "            1.5013e-04, -2.7985e-04, -7.3962e-05, -2.4535e-04, -3.3124e-03,\n",
       "           -2.8759e-03,  3.9103e-04,  1.9157e-03,  1.5300e-03, -4.7551e-03,\n",
       "           -1.3491e-04, -4.0522e-03,  2.7600e-04, -4.0731e-03, -3.9762e-03,\n",
       "           -2.7432e-03, -4.4337e-03, -3.0028e-03,  1.0682e-03, -4.2289e-03,\n",
       "            5.1408e-03,  2.6447e-03, -1.9008e-03,  4.0175e-03, -2.6862e-03,\n",
       "            8.5705e-04,  3.3810e-03,  1.8584e-03,  4.8532e-03,  3.2324e-03,\n",
       "            5.6099e-04, -2.3060e-03,  3.4905e-04,  6.6471e-03,  3.8367e-03,\n",
       "           -2.9036e-04, -2.8908e-03, -4.6685e-03, -2.6430e-03, -1.7868e-03,\n",
       "            4.9194e-04, -3.8930e-03,  2.0783e-03, -1.7026e-04,  1.9951e-04,\n",
       "           -8.8379e-04, -1.6585e-03, -4.4713e-04,  1.2525e-03, -1.0504e-03,\n",
       "            3.2274e-03,  2.1516e-03,  3.4926e-03, -1.1441e-03, -1.2385e-03,\n",
       "           -1.7998e-04, -4.8881e-04, -1.9123e-03, -2.0164e-03,  1.3157e-03,\n",
       "            5.8554e-03, -4.2129e-04,  1.2233e-03, -1.4588e-03, -3.5893e-03,\n",
       "           -4.5866e-03, -7.3232e-04, -1.9886e-03,  5.5929e-05, -1.0552e-03,\n",
       "           -1.8992e-03, -7.0394e-04,  1.5895e-04,  1.1569e-03, -6.2808e-04,\n",
       "           -1.1899e-03,  1.2543e-03,  1.2886e-04, -2.2182e-03, -4.8140e-04,\n",
       "           -1.4732e-03, -5.7964e-04, -1.4053e-03, -2.2218e-03, -6.9668e-04,\n",
       "            1.5000e-03, -1.4365e-04, -2.1689e-03,  1.6115e-03,  3.7267e-04,\n",
       "           -1.4079e-03,  2.2399e-03,  8.1438e-04, -9.9542e-04, -1.2936e-03,\n",
       "           -2.2945e-03,  1.1623e-03,  2.3146e-04, -1.4161e-03,  4.8889e-04,\n",
       "           -2.2524e-03,  8.1017e-04,  1.6562e-03,  8.6764e-04,  1.8445e-03,\n",
       "           -5.0768e-04, -2.7303e-03, -2.3514e-03,  3.0754e-03,  1.7803e-03,\n",
       "           -3.2552e-03, -3.4800e-03, -1.2244e-03,  4.2343e-03,  1.5146e-03,\n",
       "           -1.7291e-03,  4.8262e-03, -2.7953e-04,  3.3170e-03, -1.3208e-04,\n",
       "            3.7671e-03,  4.5167e-04, -2.1613e-03,  2.2176e-03,  5.2371e-04,\n",
       "            2.2614e-04, -1.1653e-03, -7.9442e-04, -1.1355e-04, -4.6933e-03,\n",
       "            1.7613e-03, -3.8037e-03,  7.6479e-04,  7.7159e-04, -2.0978e-03,\n",
       "           -7.9689e-04,  8.8614e-05, -7.3685e-04,  2.0189e-04,  2.1446e-04,\n",
       "           -2.5354e-04,  5.7802e-04,  4.4156e-04, -9.7790e-04,  8.1583e-04,\n",
       "           -1.5453e-03,  5.4022e-04, -4.6673e-04,  5.6429e-04, -5.0294e-04,\n",
       "           -1.3576e-03,  7.5318e-05,  1.6974e-04, -7.2775e-07,  9.8986e-04,\n",
       "           -3.6163e-04, -1.7237e-03,  1.2207e-03,  7.6085e-04, -1.6871e-04,\n",
       "           -1.2211e-04, -2.2997e-04,  5.3710e-04, -7.7757e-04,  4.7594e-02,\n",
       "           -2.6293e-02, -2.5340e-02, -1.3556e-02, -9.1101e-02,  6.8582e-02,\n",
       "           -3.2647e-02,  9.8358e-02,  5.2048e-02, -9.2596e-02,  3.6872e-02,\n",
       "            9.8438e-02, -4.0868e-02,  4.1713e-03,  1.9916e-02, -8.2231e-02,\n",
       "           -8.0683e-02, -4.5237e-02,  4.4255e-02,  1.0501e-01,  9.0235e-02,\n",
       "            3.5780e-02,  2.4230e-02,  1.6472e-02,  8.8683e-02,  2.2118e-03,\n",
       "           -8.7278e-02, -7.3303e-02,  9.2594e-02,  7.7037e-02, -8.6525e-02,\n",
       "            1.7830e-02], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0402, -0.1571,  0.0700,  ..., -0.0778, -0.0554,  0.1156],\n",
       "           [-0.0258,  0.0827, -0.1200,  ..., -0.0669,  0.0126, -0.0348],\n",
       "           [-0.0059,  0.1068, -0.0139,  ..., -0.0361,  0.0431, -0.0287],\n",
       "           ...,\n",
       "           [ 0.0651, -0.0838,  0.0061,  ..., -0.0126,  0.0554,  0.1658],\n",
       "           [-0.0920, -0.0544,  0.0335,  ...,  0.0021, -0.0994,  0.0358],\n",
       "           [-0.0115, -0.1274, -0.1440,  ..., -0.0083,  0.0144, -0.0729]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-9.8991e-03, -5.0328e-03,  5.9453e-04, -4.0174e-03,  1.5501e-03,\n",
       "            5.7057e-03,  9.9946e-04, -1.8684e-03, -2.1004e-03, -1.0445e-03,\n",
       "            2.0909e-03, -2.8533e-04, -1.0445e-02, -1.2099e-03, -3.9715e-04,\n",
       "           -1.2293e-02,  3.0638e-04, -5.5845e-03, -2.6975e-04,  1.7044e-02,\n",
       "            9.4612e-03,  5.4598e-03,  3.2423e-02, -2.1851e-03, -1.1307e-03,\n",
       "           -1.8345e-03,  1.0086e-03,  5.7685e-03,  4.2720e-03,  2.8807e-03,\n",
       "            1.9241e-04, -4.9086e-03,  2.1995e-03,  7.8750e-04, -1.6687e-03,\n",
       "           -2.9773e-03, -3.4468e-03, -2.0695e-03,  1.0665e-02, -5.7759e-03,\n",
       "            7.8282e-04,  6.0531e-03, -2.2368e-04, -1.0392e-02, -5.9556e-03,\n",
       "           -5.0702e-04, -6.6474e-03,  2.0225e-04, -2.9711e-04,  4.0936e-03,\n",
       "            6.0246e-03,  4.1610e-03, -4.6730e-04, -8.2676e-03,  1.8017e-03,\n",
       "            2.2136e-04, -4.1924e-04,  6.6935e-03,  3.5831e-03,  5.1432e-03,\n",
       "           -5.6595e-03,  2.7395e-04,  8.5292e-03, -3.5580e-03,  1.5109e-02,\n",
       "            6.8061e-03,  1.0865e-02,  5.8628e-03,  6.8542e-04, -1.4816e-03,\n",
       "            3.8316e-02, -5.0642e-03,  1.1694e-02,  6.8770e-03, -1.7941e-03,\n",
       "            5.7981e-04,  3.4374e-02,  5.2981e-03,  1.7942e-03,  2.2093e-03,\n",
       "           -4.4076e-03, -1.3717e-02, -2.2177e-03, -4.8675e-03,  4.3563e-03,\n",
       "           -4.7434e-02,  7.6797e-03,  2.3393e-03, -5.0016e-03,  1.8677e-02,\n",
       "            1.6390e-03,  1.5376e-02,  1.0428e-01,  5.3177e-03,  3.9150e-03,\n",
       "           -8.6732e-04,  9.4756e-04,  2.7166e-03, -6.3279e-04, -7.1728e-03,\n",
       "            2.7178e-03, -4.1465e-03, -3.3905e-03, -3.3474e-03, -5.3085e-03,\n",
       "            1.3150e-03,  8.9705e-04,  1.3828e-03, -5.2890e-03,  1.5162e-03,\n",
       "           -5.7857e-03, -2.4911e-03, -9.7272e-03, -3.2093e-04, -2.9721e-03,\n",
       "           -2.6727e-03, -2.9173e-02, -3.6102e-03, -8.0257e-03, -6.8752e-03,\n",
       "            1.5883e-03,  5.0974e-02, -9.6683e-04, -1.5891e-03,  3.4017e-04,\n",
       "            2.3656e-03,  4.2805e-03,  1.3651e-02,  2.8326e-03,  1.5521e-02,\n",
       "           -8.2363e-04,  9.4952e-03, -2.2841e-03, -3.3783e-03,  3.8016e-03,\n",
       "           -3.0102e-03, -2.7695e-03,  4.3965e-03,  4.2397e-03, -6.2400e-03,\n",
       "           -1.6657e-03,  6.2613e-03,  3.6300e-03, -3.4306e-03, -2.8586e-03,\n",
       "            3.3857e-04, -4.8124e-03,  7.8273e-03,  5.8144e-03,  5.7197e-05,\n",
       "            2.7790e-03, -6.1479e-03, -4.1001e-04,  4.2053e-03, -9.6640e-03,\n",
       "            7.1172e-03,  3.9028e-03,  1.3272e-03, -3.4132e-04, -1.3172e-03,\n",
       "           -4.5433e-04,  2.2725e-03, -4.2386e-03,  3.1753e-03,  2.0465e-03,\n",
       "            4.1036e-03,  1.0404e-02, -1.2684e-02,  6.2061e-03,  4.3308e-03,\n",
       "            7.7781e-03,  8.9385e-04, -6.1245e-03,  1.9642e-03,  1.3920e-02,\n",
       "           -1.1204e-02, -1.7155e-03,  1.0022e-03, -4.9126e-03, -1.5026e-02,\n",
       "            2.2169e-03, -3.7189e-03, -1.7327e-04,  1.2014e-02, -1.2299e-03,\n",
       "            4.9909e-04,  5.8326e-03,  6.1227e-03,  8.6280e-04, -1.7379e-03,\n",
       "            3.3367e-02, -1.4822e-03,  4.2533e-04, -8.3261e-03,  1.9438e-03,\n",
       "           -1.2176e-03,  4.9746e-03, -2.3531e-04, -7.1239e-03, -2.4404e-04,\n",
       "            8.4576e-03, -6.3359e-03,  3.9468e-03,  3.7746e-03, -2.1917e-03,\n",
       "           -2.7710e-03, -7.6675e-04, -2.5708e-03, -2.4262e-03,  6.9690e-04,\n",
       "            2.8945e-03,  2.3998e-03, -4.7698e-03, -6.2887e-03, -3.1179e-03,\n",
       "           -4.8604e-03,  8.7594e-03, -4.1387e-04, -3.5387e-03,  4.2544e-03,\n",
       "            3.8308e-03,  1.3344e-03, -4.1283e-03, -4.0881e-03,  1.8557e-03,\n",
       "            7.2589e-03,  4.4107e-03, -7.9921e-03, -7.8844e-04,  1.8668e-02,\n",
       "           -6.9216e-03,  1.5693e-02,  6.9837e-03, -3.7019e-03,  5.9224e-03,\n",
       "           -1.6097e-02,  2.1524e-03, -4.2721e-03, -3.7280e-03,  3.8130e-03,\n",
       "           -3.2810e-03, -1.0423e-02,  2.2010e-03,  6.8576e-03, -5.8328e-03,\n",
       "           -1.9909e-03,  2.1979e-03,  6.8298e-04,  3.0031e-03, -3.2855e-03,\n",
       "           -4.4391e-03,  5.3208e-03, -4.9095e-04, -2.4108e-05, -8.8163e-03,\n",
       "           -7.6851e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0109,  0.0639, -0.0768,  ..., -0.1213,  0.0181,  0.0533],\n",
       "           [-0.1145, -0.1957,  0.0466,  ..., -0.1897, -0.2254, -0.0621],\n",
       "           [-0.1812,  0.3190,  0.1717,  ...,  0.4112, -0.0269, -0.1448],\n",
       "           ...,\n",
       "           [ 0.0721,  0.1295,  0.0313,  ...,  0.0321, -0.0243,  0.0145],\n",
       "           [-0.0854,  0.0673,  0.0498,  ...,  0.0259, -0.0331,  0.0357],\n",
       "           [ 0.0057,  0.0831,  0.0671,  ..., -0.1343, -0.0653, -0.1644]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0075, -0.1080, -0.1770,  0.0147,  0.0027, -0.0059,  0.0464,  0.0071,\n",
       "           -0.0293, -0.0490,  0.0240, -0.0395,  0.0415, -0.0166,  0.0290,  0.0246,\n",
       "            0.0553, -0.0545, -0.0222,  0.0185,  0.0362,  0.0165,  0.0516,  0.0182,\n",
       "           -0.0721, -0.0450,  0.0245,  0.0070, -0.0101,  0.1048, -0.0224,  0.0054,\n",
       "           -0.0127, -0.0231, -0.0126,  0.0183, -0.0159,  0.0236, -0.0463, -0.0406,\n",
       "            0.0128, -0.0311,  0.0173, -0.0332,  0.0082,  0.0121, -0.0070,  0.0132,\n",
       "            0.0054, -0.0125,  0.0291, -0.0398,  0.0182, -0.0493,  0.0039,  0.0299,\n",
       "            0.0116, -0.0593,  0.0563,  0.0136,  0.0256,  0.0132,  0.0344, -0.0609,\n",
       "            0.0355, -0.0334,  0.0391,  0.0007,  0.0165, -0.0514, -0.0043, -0.0060,\n",
       "           -0.0043,  0.0082,  0.0165, -0.0232,  0.0441, -0.0466, -0.0210, -0.0258,\n",
       "            0.0361,  0.0011,  0.0344,  0.0272,  0.0336,  0.0304, -0.0127,  0.0013,\n",
       "            0.0215, -0.0191,  0.0283, -0.0405, -0.0149,  0.0282,  0.0371, -0.0339,\n",
       "            0.0310, -0.0068,  0.0433, -0.0158,  0.0281,  0.0024, -0.0026, -0.0210,\n",
       "            0.0058, -0.0200,  0.0261,  0.0173,  0.0261,  0.0148,  0.0298,  0.0089,\n",
       "            0.0302, -0.0162,  0.0470, -0.0348,  0.0084, -0.0047,  0.0566, -0.0032,\n",
       "           -0.0152, -0.0111, -0.0180, -0.0011,  0.0214, -0.0117, -0.0227,  0.0145,\n",
       "            0.0063, -0.0043,  0.0454, -0.0195,  0.0190, -0.0125, -0.0679, -0.0761,\n",
       "            0.0077, -0.0052,  0.0011, -0.0256, -0.0655, -0.0143,  0.0461, -0.0059,\n",
       "            0.0329, -0.0082,  0.0364,  0.0912,  0.0125, -0.0040, -0.0273,  0.0084,\n",
       "           -0.0005, -0.0184,  0.0290,  0.0260,  0.0087,  0.0015, -0.0009, -0.0497,\n",
       "           -0.0015, -0.0060, -0.0098, -0.0121,  0.0301, -0.0115,  0.0179, -0.0061,\n",
       "            0.0493, -0.0266,  0.0290,  0.0238,  0.0301,  0.0189,  0.0430, -0.0428,\n",
       "           -0.0191, -0.0542,  0.0224, -0.0217,  0.0064,  0.0012,  0.0071, -0.0263,\n",
       "           -0.0097,  0.0144, -0.0116, -0.0059, -0.0010,  0.0065,  0.1030,  0.0177,\n",
       "           -0.0198, -0.0005,  0.0783, -0.0229,  0.0282, -0.0088,  0.0482, -0.0113,\n",
       "            0.0040,  0.0083,  0.0596, -0.0060,  0.0318, -0.0625, -0.0071, -0.0346,\n",
       "            0.0541, -0.0020, -0.0511, -0.0502,  0.0114, -0.0019, -0.0004, -0.0146,\n",
       "           -0.0249, -0.0431,  0.0127, -0.0862,  0.0205,  0.0304, -0.0620, -0.0269,\n",
       "           -0.0035, -0.0119, -0.0101, -0.0212,  0.0433, -0.0224, -0.0063,  0.0099,\n",
       "            0.0344,  0.0393, -0.0444,  0.0311, -0.0149,  0.0269, -0.0302, -0.0376,\n",
       "           -0.0412, -0.0742,  0.0196, -0.0034,  0.0295, -0.0171, -0.0110,  0.0346,\n",
       "           -0.0470, -0.0059,  0.0141,  0.0234,  0.0267, -0.0433,  0.0019,  0.0082],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.1904,  0.3054, -0.1146,  ..., -0.2387,  0.0355, -0.0540],\n",
       "           [ 0.0875,  0.4036, -0.1690,  ..., -0.1750,  0.0984, -0.0563],\n",
       "           [-0.0319,  0.3439, -0.1145,  ..., -0.1634,  0.2317, -0.1259],\n",
       "           ...,\n",
       "           [-0.0937,  0.1920, -0.0606,  ..., -0.1663, -0.0332, -0.0280],\n",
       "           [ 0.0818,  0.7844,  0.1514,  ..., -0.0623,  0.4244, -0.1104],\n",
       "           [ 0.0752,  0.3782, -0.1399,  ..., -0.1302, -0.0296, -0.1696]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.4828, -0.6192, -0.7557, -0.7516, -0.5981, -0.6865, -0.4834, -0.5608,\n",
       "           -0.6290, -0.5739, -0.6698, -1.1933, -0.6300, -1.4437, -0.8551, -0.5130,\n",
       "           -0.7282, -0.5297, -0.5854, -0.5705, -0.7195, -0.5885, -0.6239, -0.5411,\n",
       "           -1.2798, -0.6190, -0.6825, -0.5781, -0.8319, -0.6424, -0.5631, -0.5321,\n",
       "           -0.5463, -0.5317, -0.6291, -0.6564, -0.4891, -1.3658, -0.6228, -0.6042,\n",
       "           -1.2703, -0.5740, -0.5980, -0.5871, -0.5840, -0.5904, -0.5752, -0.6609,\n",
       "           -0.6622, -0.4991, -0.5815, -0.5404, -0.6453, -0.5847, -0.6094, -0.6275,\n",
       "           -0.8894, -0.8140, -0.7175, -0.6411, -0.5723, -0.5703, -0.8698, -0.7142],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.1624, -0.0791,  0.0223,  ...,  0.1143,  0.1312, -0.0074],\n",
       "           [ 0.0742, -0.1903,  0.1839,  ..., -0.5861,  0.4291, -0.1707],\n",
       "           [-0.2716, -0.2788,  0.0325,  ..., -0.2352,  0.9964,  0.1953],\n",
       "           ...,\n",
       "           [-0.3685, -0.1614,  0.2724,  ...,  0.2574, -0.0273, -0.2932],\n",
       "           [ 0.0441,  0.1312,  0.1750,  ..., -0.1121, -0.4294, -0.0610],\n",
       "           [ 0.1392,  0.2884,  0.0189,  ..., -0.1431,  0.1181,  0.1910]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-2.2400e-02, -6.9559e-02, -1.6985e-01,  1.4129e-02,  4.6729e-02,\n",
       "            2.0272e-02,  5.5675e-02,  6.7412e-02,  4.0185e-02,  3.4387e-02,\n",
       "            3.5443e-02, -1.1503e-04,  1.4590e-02,  5.1263e-02,  1.3764e-02,\n",
       "            3.3198e-02,  1.2586e-02, -3.3586e-02,  4.7604e-02,  3.1499e-02,\n",
       "           -2.8217e-02,  2.3539e-02,  1.6822e-02,  3.3427e-02,  7.2341e-03,\n",
       "            2.1145e-02,  3.1140e-02,  2.7527e-02, -1.0689e-02,  5.7691e-01,\n",
       "            1.3256e-02,  4.7707e-02,  1.9439e-02, -1.8234e-03,  3.9411e-03,\n",
       "            1.0725e-02,  1.1512e-02,  2.2543e-02, -2.4131e-02,  7.0299e-03,\n",
       "           -7.3261e-03,  4.6933e-02, -2.0628e-02,  1.4498e-02, -1.5234e-02,\n",
       "            1.1161e-02, -1.4395e-02,  1.7596e-02, -2.9253e-03, -1.5164e-02,\n",
       "            6.0462e-03,  1.4736e-02,  7.7105e-05,  3.2250e-03, -2.7320e-02,\n",
       "            1.5570e-02, -2.3657e-02,  2.2542e-03, -1.7895e-02,  2.6719e-02,\n",
       "            2.9269e-02, -1.1617e-05, -3.7126e-02,  9.2840e-03,  1.0906e-02,\n",
       "           -2.4720e-03,  1.3271e-02, -1.8912e-02, -1.5528e-02,  6.1026e-04,\n",
       "            9.9221e-03, -1.4616e-02,  2.5426e-02,  1.0185e-02, -1.0938e-02,\n",
       "            1.1039e-03,  7.3657e-03, -1.6863e-02,  5.5348e-02,  1.2828e-02,\n",
       "            7.7864e-03,  1.9828e-02,  1.1772e-02, -2.4401e-02,  2.4513e-02,\n",
       "           -5.4226e-05,  2.4143e-02, -2.1844e-02, -3.3130e-03, -2.4677e-03,\n",
       "            9.0693e-03, -1.2910e-02,  1.2525e-02,  3.0763e-03, -1.0069e-03,\n",
       "            2.5559e-02, -2.6804e-03, -1.2008e-02,  3.4663e-02, -1.8878e-02,\n",
       "           -5.0796e-03,  2.1641e-02,  3.2518e-02,  4.1418e-02,  2.1848e-02,\n",
       "           -2.9896e-02, -2.5008e-02,  8.0280e-03,  1.3958e-02,  2.7872e-03,\n",
       "           -3.9658e-03, -1.7383e-02, -6.5679e-03, -4.8500e-02,  4.3461e-03,\n",
       "           -6.7133e-04, -3.3851e-03, -1.4460e-02,  1.3405e-02,  1.7593e-03,\n",
       "           -2.2747e-02,  1.4980e-02,  4.7311e-02,  6.1428e-04,  3.5266e-02,\n",
       "            4.4923e-03,  1.2253e-02, -2.6578e-03,  2.3282e-02, -2.0410e-02,\n",
       "            1.4740e-02, -1.6678e-02,  1.4759e-02, -6.4676e-03, -3.8645e-01,\n",
       "           -6.6890e-02,  3.5626e-02,  7.6122e-03, -6.4670e-03,  1.2036e-02,\n",
       "            1.4255e-03,  1.4155e-03, -7.7733e-03,  1.4764e-02,  6.0600e-03,\n",
       "           -1.9491e-02,  7.3442e-03,  7.2362e-02,  7.0312e-04,  2.5383e-02,\n",
       "           -7.2439e-03, -2.8088e-02, -2.2216e-04, -3.5023e-02,  7.9307e-02,\n",
       "           -2.5620e-02, -1.9973e-02, -1.2974e-02,  2.1420e-03, -8.1033e-03,\n",
       "           -1.4263e-02,  2.4569e-02,  2.6878e-02, -3.6163e-02, -5.1471e-02,\n",
       "           -1.9001e-02, -8.3830e-03, -3.5535e-02, -2.5858e-02, -3.2944e-02,\n",
       "           -1.3436e-02,  3.0614e-03,  6.5743e-02,  3.4803e-03,  1.4106e-02,\n",
       "           -3.0417e-02, -5.0734e-03, -2.9319e-02,  1.9339e-03, -4.7017e-03,\n",
       "            3.0194e-02, -1.5312e-02,  2.1353e-02, -1.4757e-02,  2.5758e-02,\n",
       "           -5.9920e-03,  1.1357e-02, -1.3164e-02,  1.5751e-02, -3.5428e-02,\n",
       "           -1.0232e-01, -2.5196e-02,  5.9426e-03, -2.2616e-02, -5.6873e-03,\n",
       "           -3.8354e-02,  1.1413e-02, -9.3850e-03, -5.7764e-04, -1.2771e-02,\n",
       "            1.2822e-02,  4.1051e-03,  9.3137e-03, -5.3446e-02,  2.9776e-02,\n",
       "            8.9906e-03, -2.5186e-02, -3.3043e-02, -1.1631e-02,  1.6140e-02,\n",
       "           -1.0615e-01, -7.1741e-02,  3.6748e-02, -1.5882e-03,  6.6461e-03,\n",
       "           -2.0881e-02,  1.8465e-02, -1.8158e-02, -1.7899e-02, -5.2841e-02,\n",
       "           -3.6059e-03, -2.8664e-02, -2.1493e-02, -1.8773e-02, -3.0576e-03,\n",
       "            7.4167e-03, -3.6496e-03, -3.0464e-03, -3.4117e-02, -7.1282e-02,\n",
       "           -2.7419e-02,  8.9882e-03,  8.0258e-03,  2.9549e-02,  1.0796e-02,\n",
       "           -2.6476e-02, -1.5074e-02, -8.2238e-03,  2.6801e-02,  9.0502e-03,\n",
       "            6.3305e-03, -1.0114e-01, -1.3292e-02, -6.9418e-02,  9.6735e-03,\n",
       "           -1.1453e-02,  2.6763e-03,  3.0264e-03,  1.2367e-02, -4.1536e-02,\n",
       "           -1.1820e-02, -2.1245e-03, -3.3984e-03, -6.1148e-02,  2.0557e-02,\n",
       "           -7.6445e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([1.4169, 0.1144, 1.0658, 0.9912, 0.8528, 0.8413, 0.9969, 1.1760, 1.1740,\n",
       "           1.1952, 1.0842, 1.3629, 0.8828, 1.2441, 1.3319, 1.2527, 1.2800, 1.2743,\n",
       "           1.4239, 1.1627, 1.4202, 1.2329, 1.3213, 1.2281, 1.1636, 1.2238, 1.3633,\n",
       "           1.4352, 1.3056, 1.1535, 1.4639, 1.3139, 1.3365, 1.2889, 1.2858, 1.2426,\n",
       "           1.3571, 1.4109, 1.3453, 1.4221, 1.1732, 1.4138, 1.4376, 1.3792, 1.3886,\n",
       "           1.4581, 1.4452, 1.4003, 1.3917, 1.4269, 1.3959, 1.4392, 1.3352, 1.4451,\n",
       "           1.3570, 1.3448, 1.3355, 1.4317, 1.3264, 1.4307, 1.3465, 1.3386, 1.3687,\n",
       "           1.4656, 1.3499, 1.4857, 1.4395, 1.3739, 1.3992, 1.4165, 1.3983, 1.4483,\n",
       "           1.3873, 1.3822, 1.4064, 1.3864, 1.3206, 1.3888, 1.3722, 1.3945, 1.4426,\n",
       "           1.3679, 1.4602, 1.3522, 1.2437, 1.4390, 1.1803, 1.3763, 1.4344, 1.4222,\n",
       "           1.4964, 1.3888, 1.4584, 1.4112, 1.4855, 1.1548, 1.4175, 1.4028, 1.4494,\n",
       "           1.3857, 1.4294, 1.4101, 1.4112, 1.4298, 1.3810, 1.4494, 1.4153, 1.3628,\n",
       "           1.4380, 1.2637, 1.4071, 1.4392, 1.3480, 1.2421, 1.4238, 1.4417, 1.4096,\n",
       "           1.3922, 1.3144, 1.3609, 1.2322, 1.4142, 1.3715, 1.4135, 1.4624, 1.4311,\n",
       "           1.4104, 1.4885, 1.4526, 1.4795, 1.3519, 1.3613, 1.3945, 1.4402, 1.6493,\n",
       "           1.4308, 1.4180, 1.3951, 1.3707, 1.5146, 0.5191, 1.4066, 1.4723, 1.3986,\n",
       "           1.3638, 1.2674, 1.5091, 1.5821, 1.4385, 1.3692, 1.4332, 1.2752, 1.4071,\n",
       "           1.3825, 1.4137, 1.4197, 1.4729, 1.4543, 1.3922, 1.4003, 1.4718, 1.3637,\n",
       "           1.4312, 1.3327, 1.4315, 1.2547, 1.4774, 1.4482, 1.4033, 1.4136, 1.4429,\n",
       "           1.3951, 1.2190, 1.4199, 1.4237, 1.4862, 1.5677, 1.2495, 1.3998, 1.4706,\n",
       "           1.4274, 1.3944, 1.4404, 1.4800, 1.4359, 1.5003, 1.3592, 1.3924, 1.4450,\n",
       "           1.3033, 2.1313, 1.4364, 1.3729, 1.3702, 1.3224, 1.4564, 1.4408, 1.4210,\n",
       "           1.3032, 1.4039, 1.4198, 1.4288, 1.4755, 1.4383, 1.4333, 1.4383, 1.4736,\n",
       "           1.4036, 1.4259, 1.3533, 3.0287, 1.4394, 1.3597, 1.4289, 1.4979, 1.4710,\n",
       "           1.4189, 1.4250, 1.4092, 1.0078, 1.3799, 1.4436, 2.3715, 1.4620, 1.3598,\n",
       "           1.3530, 1.4986, 1.5167, 1.4370, 1.4641, 1.5067, 1.3439, 1.3663, 1.3786,\n",
       "           1.4231, 1.4456, 1.4404, 1.4160, 1.4804, 1.3642, 1.4886, 1.4526, 1.5098,\n",
       "           1.2707, 1.4855, 1.4669, 1.4276, 1.4459, 1.6072, 1.4573, 1.2543, 1.3889,\n",
       "           1.4161, 1.2134, 1.3798, 1.3622], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-6.0683e-02, -1.6474e+00, -2.9504e-01,  2.6561e-01,  6.3586e-01,\n",
       "            4.4186e-01,  1.7927e-01,  6.5964e-03, -4.4181e-01, -3.3679e-01,\n",
       "            5.5187e-01,  1.8688e-01,  4.3937e-01,  9.9335e-02, -1.6003e-02,\n",
       "           -1.8805e-01,  5.9554e-02,  1.3403e-01, -1.4667e-01,  3.1025e-01,\n",
       "           -1.5641e-02, -5.3934e-02,  1.2588e-01,  3.9472e-01, -3.4004e-01,\n",
       "           -1.9609e-01, -1.1758e-01,  9.7162e-02,  1.3905e-01, -2.4551e-01,\n",
       "           -6.9620e-02, -6.6539e-02,  6.4542e-03,  2.9247e-01,  1.9441e-01,\n",
       "            8.6297e-03, -2.2175e-01, -1.1043e-01, -5.4008e-02,  9.7598e-02,\n",
       "           -5.0525e-01,  2.3332e-01, -3.0956e-02, -3.3887e-03,  7.1992e-03,\n",
       "            1.0686e-01, -2.0275e-01,  2.0866e-01,  3.2457e-02, -2.6485e-02,\n",
       "           -2.7269e-02, -3.9618e-02, -1.8586e-01,  2.2526e-02,  1.7086e-01,\n",
       "           -5.1999e-03, -1.6203e-01,  8.8653e-02,  5.4024e-01,  7.6000e-03,\n",
       "           -1.6198e-01,  1.0797e-01,  1.4954e-01,  5.6552e-02, -6.8683e-02,\n",
       "            4.3055e-03,  2.9366e-02,  1.4721e-01,  4.7513e-02, -1.6737e-01,\n",
       "            4.2715e-02,  4.3827e-01, -1.3769e-02,  1.8818e-01,  3.6193e-02,\n",
       "            5.2468e-02,  1.6362e-01,  1.5759e-02, -4.9355e-02,  2.0240e-01,\n",
       "            3.1617e-02,  1.3499e-02,  1.9803e-01, -1.1611e-01, -2.0522e-03,\n",
       "            5.1533e-02,  1.5169e-01,  1.5625e-01, -1.3000e-01,  7.2410e-02,\n",
       "           -8.5544e-02, -1.2410e-01,  1.7405e-01, -2.1969e-01, -6.8313e-02,\n",
       "            3.3304e-01, -6.4593e-02,  7.2912e-02,  1.9330e-01,  1.9135e-02,\n",
       "            4.7282e-03,  2.5828e-01,  4.1011e-02,  8.6752e-02,  1.2842e-01,\n",
       "            1.4747e-01, -7.5316e-02,  1.0849e-01,  1.0892e-01, -5.0241e-02,\n",
       "           -7.7712e-03,  6.8401e-02, -9.9306e-02,  9.8015e-02, -6.7421e-03,\n",
       "            9.8646e-02,  2.5942e-02,  1.5137e-02,  3.3665e-02,  1.5385e-01,\n",
       "            3.9481e-02,  8.9206e-04,  5.7597e-02, -1.1702e-02,  7.1221e-02,\n",
       "            1.7469e-01, -1.0302e-01, -1.8899e-02,  7.7929e-02, -2.2541e-01,\n",
       "            1.7692e-01,  3.5543e-02,  9.6298e-02,  1.6671e-02, -1.8719e+00,\n",
       "           -1.7215e-01,  1.3409e-01,  3.7455e-02,  5.4070e-02, -9.4661e-02,\n",
       "           -9.6469e-01,  1.9362e-02,  1.3497e-01,  1.0097e-01, -1.1022e-01,\n",
       "            1.1246e-01, -9.2032e-03, -5.6948e-01, -9.8488e-02,  8.5982e-02,\n",
       "           -6.7471e-02,  5.1968e-02,  9.4767e-02, -2.2697e-02,  3.6126e-02,\n",
       "            1.2310e-01, -2.1966e-02, -1.7664e-01,  1.7368e-01, -1.5302e-01,\n",
       "           -1.1981e-01,  1.1311e-01, -6.7891e-02,  2.5746e-01,  1.2248e-01,\n",
       "            4.0107e-01,  5.7855e-02,  8.0503e-03, -3.0207e-02,  1.4299e-01,\n",
       "           -8.5888e-02,  1.9223e-01, -5.4757e-02, -1.0168e-02,  3.0699e-02,\n",
       "            1.2175e-03, -3.1653e-01, -7.6430e-02, -1.7198e-01,  2.1256e-02,\n",
       "            3.8168e-03,  1.0453e-01,  4.0855e-02,  1.0439e-01,  3.1213e-01,\n",
       "            9.0559e-02,  3.3639e-01,  1.3241e-01, -3.7062e-02, -6.4128e-02,\n",
       "           -3.9488e-02,  3.1025e-02, -3.5458e-01,  5.0172e-03,  5.8987e-02,\n",
       "           -3.0321e-01, -1.0001e-01,  3.3302e-02, -2.5259e-02,  5.6163e-02,\n",
       "            2.5708e-02, -9.1418e-02, -1.3770e-01, -1.8198e-02, -4.3327e-02,\n",
       "           -2.3874e-02, -5.7217e-03, -4.8132e-02,  1.0013e-01, -6.0167e-02,\n",
       "           -8.2750e-01, -4.2188e-02, -4.0725e-01, -7.4448e-03, -1.0484e-01,\n",
       "            1.2860e-01,  1.4838e-01,  5.3655e-02,  1.4363e-01, -2.3184e-01,\n",
       "            2.4886e-02,  1.1310e-01,  2.7563e-01,  3.6339e-02,  9.0160e-02,\n",
       "            1.3377e-02, -3.3349e-01, -1.0266e-01,  6.4504e-02, -2.2634e-02,\n",
       "           -6.6596e-02, -1.6432e-01, -1.7516e-02, -5.1188e-02,  2.8912e-02,\n",
       "            1.1100e-01, -6.6124e-02, -3.4829e-02, -1.9633e-01,  2.0044e-01,\n",
       "           -7.3541e-02, -1.6129e-01, -2.2064e-01,  2.8757e-01,  1.0727e-01,\n",
       "            3.6586e-03, -6.9329e-02,  1.7031e-01, -1.8677e-02, -1.8518e-02,\n",
       "           -1.2114e-02,  7.2338e-02,  1.6533e-01,  2.1207e-01,  4.9093e-02,\n",
       "            1.6313e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([1.1076, 1.0011, 0.8769, 0.8676, 0.7973, 0.9400, 0.8634, 1.0143, 1.1773,\n",
       "           1.1341, 0.9484, 1.0896, 0.8949, 1.0235, 1.0486, 1.1172, 1.0946, 1.2297,\n",
       "           1.1810, 0.9668, 1.1430, 1.0365, 1.0727, 1.0156, 1.1935, 1.0859, 1.1594,\n",
       "           1.0774, 1.0770, 1.0960, 1.1341, 1.1575, 1.0412, 1.0617, 1.0568, 1.0495,\n",
       "           1.0392, 1.1083, 1.1156, 1.1176, 1.0869, 1.1579, 1.1396, 1.1479, 1.1178,\n",
       "           1.2133, 1.1376, 1.1133, 1.0546, 1.0463, 1.1188, 1.1240, 1.0701, 1.1812,\n",
       "           1.0799, 1.0279, 1.0490, 1.0989, 1.2303, 1.0990, 1.1243, 1.0408, 1.1292,\n",
       "           1.1180, 1.1174, 1.1510, 1.0758, 1.1117, 1.1200, 1.0911, 1.1233, 1.2019,\n",
       "           1.0894, 1.1325, 1.1346, 1.0746, 1.0220, 1.0963, 1.1193, 1.0826, 1.1510,\n",
       "           1.0880, 1.1342, 1.0654, 0.9198, 1.1165, 1.0362, 1.0931, 1.1119, 1.1105,\n",
       "           1.1612, 1.1121, 1.1509, 1.0985, 1.2078, 1.0376, 1.1437, 1.0883, 1.0873,\n",
       "           1.1301, 1.1433, 1.1204, 1.0814, 1.1437, 1.1012, 1.1509, 1.1196, 1.0904,\n",
       "           1.0701, 1.0436, 1.1536, 1.1408, 1.1129, 1.0683, 1.1311, 1.1584, 1.1471,\n",
       "           1.0761, 1.1206, 1.1115, 0.9131, 1.1591, 1.1144, 1.1104, 1.1312, 1.1313,\n",
       "           1.1391, 1.1574, 1.1319, 1.0981, 1.0820, 1.0935, 1.0358, 1.1540, 2.3910,\n",
       "           1.1234, 1.0937, 1.0927, 1.0832, 1.1194, 0.6564, 1.1257, 1.1224, 1.1185,\n",
       "           1.0849, 1.0381, 1.1735, 1.3945, 1.1467, 1.1111, 1.1660, 1.0635, 1.1983,\n",
       "           1.1108, 1.1255, 1.1279, 1.1383, 1.0900, 1.0493, 1.1027, 1.1049, 1.0206,\n",
       "           1.0977, 1.0546, 1.1149, 1.0017, 1.1555, 1.1187, 1.1447, 1.0841, 1.1776,\n",
       "           1.1317, 1.0859, 1.1083, 1.1487, 1.0997, 1.3564, 1.0556, 1.1614, 1.1593,\n",
       "           1.1533, 1.1286, 1.1062, 1.1408, 1.1045, 1.1412, 1.1370, 1.1139, 1.1438,\n",
       "           1.0956, 2.6429, 1.1253, 1.2167, 1.0638, 1.0420, 1.1312, 1.1349, 1.1191,\n",
       "           1.0537, 1.0530, 1.1409, 1.1615, 1.1898, 1.1229, 1.1029, 1.1107, 1.1828,\n",
       "           1.1353, 1.0663, 1.1050, 2.8314, 1.0841, 1.1720, 1.0858, 1.1771, 1.1403,\n",
       "           1.1467, 1.0776, 1.0554, 1.0170, 1.0996, 1.1344, 2.4386, 1.1638, 1.1149,\n",
       "           1.0315, 1.1740, 1.1708, 1.1487, 1.1733, 1.2205, 1.1690, 1.0879, 1.1148,\n",
       "           1.1079, 1.0885, 1.1263, 1.1023, 1.1647, 1.0930, 1.1471, 1.1316, 1.1630,\n",
       "           1.0820, 1.1095, 1.1254, 1.2038, 1.0823, 1.4563, 1.1329, 1.1253, 1.1066,\n",
       "           1.0829, 0.9697, 1.0921, 1.0890], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 7.2118e-02, -1.5996e+00, -3.8756e-01,  1.3140e-01,  5.7390e-01,\n",
       "            4.5677e-01,  2.9649e-02,  9.4640e-03, -4.5023e-01, -5.8344e-02,\n",
       "            6.2844e-01, -2.6854e-02,  7.1070e-01,  9.6296e-02,  1.6965e-03,\n",
       "           -1.0080e-01, -6.5262e-02,  2.4614e-01, -1.3582e-01,  2.5631e-01,\n",
       "            5.4212e-02, -7.9022e-02,  1.0721e-01,  2.9353e-01, -3.0149e-01,\n",
       "           -2.9348e-05, -1.1689e-01,  1.5573e-01,  1.2807e-01, -1.2126e-01,\n",
       "           -1.9850e-01,  6.1978e-02,  6.0883e-02,  2.1212e-01,  1.1222e-01,\n",
       "            6.2033e-02, -1.4868e-01, -2.9017e-02, -1.9932e-01,  7.0828e-02,\n",
       "           -4.2443e-01,  2.2484e-01, -2.5035e-02,  2.2487e-03,  7.8319e-02,\n",
       "            6.0821e-02, -1.4381e-01,  1.2692e-01, -3.9742e-02, -2.3451e-02,\n",
       "           -6.1416e-02, -6.6770e-02,  5.9372e-02,  9.8104e-02,  1.3415e-01,\n",
       "           -2.9250e-02, -1.0076e-01,  1.1419e-01,  4.2535e-01,  4.8272e-02,\n",
       "           -2.9277e-02,  1.1809e-01,  1.6065e-01,  7.6345e-02, -3.7368e-02,\n",
       "            8.9832e-02, -8.3609e-02,  1.5276e-01, -1.3849e-02, -1.1163e-01,\n",
       "            7.5337e-03,  4.0927e-01,  3.0973e-02,  2.1610e-01,  8.3987e-02,\n",
       "            2.8005e-02,  4.5653e-02,  7.8798e-02, -6.1335e-02,  2.5511e-01,\n",
       "           -3.1034e-03,  5.6908e-02,  9.3278e-02, -1.6774e-02,  1.6935e-01,\n",
       "           -3.6738e-02,  7.6430e-02,  1.6684e-01, -1.6044e-01,  9.4214e-02,\n",
       "           -1.2499e-02,  2.2483e-02,  1.1600e-01, -1.4703e-01, -9.0793e-02,\n",
       "            3.2539e-01, -2.0971e-03,  9.4797e-02,  1.5752e-01, -4.1723e-03,\n",
       "            5.4358e-02,  1.6869e-01,  7.7348e-03,  1.0201e-01,  1.1297e-01,\n",
       "            1.2581e-01, -4.4211e-02, -5.6023e-02,  1.1004e-01, -3.7008e-02,\n",
       "            2.4571e-02,  1.0804e-01, -1.5610e-01,  1.7180e-01, -9.3186e-02,\n",
       "            3.3848e-02, -5.2949e-02,  6.5231e-02,  3.6774e-02,  1.2129e-01,\n",
       "           -7.4193e-02,  2.1981e-02, -3.7429e-02, -1.6839e-02, -1.2613e-03,\n",
       "            1.4436e-01, -4.0831e-02, -1.7672e-02, -1.6158e-03,  1.6355e-02,\n",
       "            1.9593e-01,  1.6664e-02,  3.5169e-02, -2.5774e-02, -2.0999e+00,\n",
       "           -9.5566e-02,  2.0224e-02, -2.8032e-02, -2.9826e-02, -2.6248e-02,\n",
       "           -1.1726e+00,  7.9950e-03,  7.6862e-02,  1.3543e-02, -8.7237e-02,\n",
       "            5.2615e-02,  4.0801e-03, -4.2378e-01, -1.3761e-01,  7.0578e-02,\n",
       "           -5.5633e-02, -5.2422e-02, -8.8487e-02, -5.6033e-02,  5.2602e-02,\n",
       "            1.1149e-01, -1.0151e-01, -1.1327e-01,  1.0767e-01, -1.9465e-02,\n",
       "           -1.2175e-01,  7.3580e-02, -1.9249e-02,  2.6542e-01,  1.2148e-01,\n",
       "            1.6578e-01,  3.7831e-03, -7.1252e-02, -8.5969e-02,  1.7025e-01,\n",
       "            4.7207e-03,  2.0076e-02, -4.7574e-02, -7.8152e-04,  2.9676e-02,\n",
       "            5.7351e-02, -4.5120e-01,  7.7728e-02, -1.9800e-01, -5.0154e-02,\n",
       "           -4.1522e-03,  8.8891e-02, -7.2947e-02,  7.0135e-02,  9.6525e-02,\n",
       "            6.8182e-02,  2.0534e-01,  8.6019e-02, -1.0650e-02,  2.7948e-02,\n",
       "           -2.0099e-01,  2.5790e-02, -2.9160e-01,  8.7053e-02,  1.1002e-02,\n",
       "           -2.1811e-01, -6.5056e-02,  8.0871e-02, -4.4853e-02,  2.1971e-03,\n",
       "            4.2764e-04, -1.2513e-01, -1.5123e-01,  1.6115e-03, -1.3170e-01,\n",
       "            9.9101e-03, -1.3754e-02, -2.6075e-02,  2.9498e-02,  3.9324e-03,\n",
       "           -8.3574e-01, -1.0830e-01, -3.9311e-01, -5.3737e-02, -1.5275e-01,\n",
       "            5.7313e-02,  9.8158e-02, -3.3847e-02,  1.1562e-01, -1.6990e-01,\n",
       "            4.9737e-02,  1.8156e-01, -3.5009e-02,  2.2942e-02,  7.3181e-02,\n",
       "            5.5072e-02, -2.8056e-01, -8.1590e-02, -2.1424e-02,  3.5630e-02,\n",
       "           -3.9854e-02, -7.1413e-02,  6.4152e-02,  2.2740e-02,  2.5779e-02,\n",
       "           -2.0855e-03, -9.7783e-03, -3.9356e-02, -1.9034e-01,  8.1320e-02,\n",
       "           -1.5994e-02, -1.2324e-01, -2.1006e-01,  1.9136e-01,  8.7074e-02,\n",
       "            1.9275e-02, -1.5874e-01,  1.3299e-01,  9.0937e-03,  2.5140e-02,\n",
       "           -4.8050e-02,  3.2489e-02,  5.9075e-02, -1.3133e-05,  3.8529e-02,\n",
       "            1.7298e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0.3585, 0.3766, 0.1910, 0.2892, 0.1766, 0.1956, 0.2493, 0.2877, 0.2058,\n",
       "           0.2835, 0.2231, 0.3260, 0.1896, 0.3533, 0.3487, 0.2892, 0.3384, 0.2571,\n",
       "           0.3138, 0.3233, 0.3430, 0.2944, 0.3670, 0.3293, 0.1745, 0.3227, 0.3053,\n",
       "           0.3845, 0.3999, 0.2366, 0.3603, 0.3043, 0.3625, 0.3721, 0.3587, 0.3109,\n",
       "           0.3046, 0.3292, 0.3764, 0.3468, 0.2001, 0.3658, 0.3392, 0.3288, 0.3455,\n",
       "           0.2944, 0.3367, 0.3795, 0.3261, 0.3945, 0.3499, 0.3565, 0.3466, 0.3394,\n",
       "           0.3693, 0.3649, 0.3233, 0.3509, 0.2672, 0.3603, 0.3217, 0.3239, 0.3309,\n",
       "           0.3293, 0.3669, 0.3823, 0.3778, 0.3579, 0.3501, 0.3505, 0.3791, 0.3033,\n",
       "           0.3360, 0.3404, 0.3569, 0.4034, 0.3238, 0.4078, 0.3397, 0.3487, 0.3558,\n",
       "           0.3588, 0.3434, 0.3728, 0.4078, 0.3714, 0.3071, 0.3619, 0.3507, 0.4033,\n",
       "           0.3387, 0.3426, 0.3468, 0.3165, 0.3135, 0.3150, 0.3892, 0.3849, 0.3255,\n",
       "           0.3516, 0.3858, 0.3934, 0.3467, 0.3717, 0.3327, 0.3790, 0.3806, 0.3435,\n",
       "           0.3727, 0.2947, 0.3565, 0.3877, 0.3115, 0.3042, 0.3825, 0.3765, 0.3729,\n",
       "           0.3806, 0.3485, 0.3593, 0.2925, 0.3646, 0.3024, 0.3690, 0.3679, 0.3548,\n",
       "           0.3497, 0.3414, 0.3669, 0.3225, 0.3182, 0.3659, 0.3695, 0.3804, 0.0009,\n",
       "           0.3863, 0.3500, 0.3893, 0.3501, 0.3736, 0.5295, 0.3642, 0.3753, 0.3877,\n",
       "           0.3392, 0.3266, 0.3359, 0.3994, 0.3529, 0.3546, 0.3142, 0.3388, 0.3441,\n",
       "           0.3506, 0.3320, 0.3692, 0.3624, 0.3583, 0.3601, 0.3709, 0.3780, 0.3273,\n",
       "           0.3634, 0.3534, 0.4133, 0.3460, 0.3930, 0.3492, 0.3656, 0.3855, 0.3654,\n",
       "           0.3787, 0.2948, 0.3774, 0.3658, 0.4021, 0.2403, 0.3534, 0.3250, 0.3462,\n",
       "           0.3916, 0.3409, 0.3425, 0.3611, 0.3544, 0.3578, 0.3603, 0.3912, 0.3540,\n",
       "           0.3391, 0.0496, 0.3710, 0.2590, 0.3546, 0.3568, 0.3501, 0.3572, 0.3515,\n",
       "           0.3234, 0.3796, 0.3848, 0.3728, 0.3411, 0.3821, 0.3691, 0.3529, 0.3658,\n",
       "           0.3312, 0.3743, 0.3539, 0.0297, 0.3951, 0.2459, 0.3839, 0.3171, 0.3959,\n",
       "           0.3627, 0.3903, 0.3743, 0.2197, 0.3939, 0.3741, 0.0924, 0.3696, 0.3684,\n",
       "           0.3386, 0.3064, 0.3633, 0.3987, 0.3489, 0.3097, 0.3130, 0.3932, 0.3758,\n",
       "           0.3982, 0.3887, 0.3461, 0.3859, 0.3417, 0.3328, 0.3455, 0.3811, 0.3464,\n",
       "           0.3403, 0.3741, 0.3816, 0.3178, 0.4020, 0.2747, 0.3839, 0.2510, 0.3972,\n",
       "           0.3691, 0.2914, 0.3877, 0.3375], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0290,  0.0100, -0.0006, -0.0291, -0.0207, -0.0157, -0.0249, -0.0282,\n",
       "           -0.0069, -0.0204, -0.0288, -0.0208, -0.0304, -0.0243, -0.0324, -0.0206,\n",
       "           -0.0306, -0.0167, -0.0229, -0.0259, -0.0333, -0.0213, -0.0385, -0.0386,\n",
       "           -0.0153, -0.0243, -0.0227, -0.0405, -0.0387, -0.0198, -0.0330, -0.0228,\n",
       "           -0.0314, -0.0335, -0.0296, -0.0256, -0.0202, -0.0379, -0.0260, -0.0320,\n",
       "           -0.0060, -0.0257, -0.0284, -0.0270, -0.0320, -0.0237, -0.0156, -0.0390,\n",
       "           -0.0265, -0.0380, -0.0247, -0.0258, -0.0293, -0.0359, -0.0322, -0.0418,\n",
       "           -0.0264, -0.0376, -0.0257, -0.0347, -0.0268, -0.0313, -0.0332, -0.0230,\n",
       "           -0.0312, -0.0324, -0.0256, -0.0375, -0.0257, -0.0297, -0.0287, -0.0392,\n",
       "           -0.0342, -0.0466, -0.0327, -0.0370, -0.0239, -0.0487, -0.0169, -0.0445,\n",
       "           -0.0230, -0.0267, -0.0302, -0.0271, -0.0396, -0.0294, -0.0225, -0.0373,\n",
       "           -0.0286, -0.0346, -0.0255, -0.0335, -0.0325, -0.0213, -0.0213, -0.0367,\n",
       "           -0.0241, -0.0326, -0.0268, -0.0342, -0.0294, -0.0401, -0.0259, -0.0387,\n",
       "           -0.0333, -0.0384, -0.0260, -0.0269, -0.0283, -0.0218, -0.0315, -0.0245,\n",
       "           -0.0151, -0.0337, -0.0324, -0.0337, -0.0249, -0.0314, -0.0313, -0.0311,\n",
       "           -0.0313, -0.0416, -0.0140, -0.0350, -0.0291, -0.0365, -0.0199, -0.0238,\n",
       "           -0.0310, -0.0274, -0.0374, -0.0360, -0.0379, -0.0300,  0.0344, -0.0356,\n",
       "           -0.0221, -0.0265, -0.0293, -0.0293, -0.0125, -0.0302, -0.0382, -0.0326,\n",
       "           -0.0282, -0.0370, -0.0223, -0.0364, -0.0287, -0.0325, -0.0167, -0.0343,\n",
       "           -0.0215, -0.0313, -0.0228, -0.0450, -0.0213, -0.0245, -0.0263, -0.0366,\n",
       "           -0.0310, -0.0292, -0.0263, -0.0353, -0.0371, -0.0382, -0.0341, -0.0260,\n",
       "           -0.0277, -0.0329, -0.0242, -0.0369, -0.0211, -0.0299, -0.0353, -0.0403,\n",
       "           -0.0091, -0.0293, -0.0224, -0.0291, -0.0294, -0.0384, -0.0242, -0.0349,\n",
       "           -0.0280, -0.0342, -0.0263, -0.0277, -0.0290, -0.0309,  0.1111, -0.0319,\n",
       "           -0.0088, -0.0313, -0.0276, -0.0296, -0.0255, -0.0395, -0.0233, -0.0411,\n",
       "           -0.0292, -0.0228, -0.0132, -0.0320, -0.0208, -0.0283, -0.0274, -0.0356,\n",
       "           -0.0296, -0.0349,  0.1985, -0.0415,  0.0030, -0.0346, -0.0161, -0.0396,\n",
       "           -0.0321, -0.0330, -0.0310, -0.0128, -0.0297, -0.0408, -0.1325, -0.0391,\n",
       "           -0.0293, -0.0297, -0.0127, -0.0273, -0.0311, -0.0343, -0.0231, -0.0307,\n",
       "           -0.0352, -0.0350, -0.0292, -0.0319, -0.0249, -0.0271, -0.0177, -0.0379,\n",
       "           -0.0161, -0.0332, -0.0201, -0.0330, -0.0304, -0.0349, -0.0184, -0.0343,\n",
       "           -0.0247, -0.0424, -0.0137, -0.0344, -0.0312, -0.0237, -0.0356, -0.0372],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0583, -0.2131, -0.0133,  ..., -0.2133, -0.2227, -0.0496],\n",
       "           [ 0.1043,  0.1506,  0.1972,  ..., -0.2962, -0.0581, -0.0551],\n",
       "           [-0.0359,  0.0115,  0.3408,  ...,  0.3724, -0.0762, -0.1155],\n",
       "           ...,\n",
       "           [ 0.0653, -0.3002,  0.2599,  ..., -0.1356,  0.7493, -0.0168],\n",
       "           [ 0.0573, -0.4087,  0.1463,  ..., -0.2584,  0.2388,  0.2124],\n",
       "           [ 0.2001,  0.0187, -0.2743,  ...,  0.1070, -0.1473, -0.2208]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 2.3638e-02, -2.2955e-01,  3.4106e-02, -1.0178e+00,  1.9278e-01,\n",
       "            4.3409e-01, -2.2988e-01, -3.9701e-02, -3.0875e-01,  2.7732e-01,\n",
       "           -1.6394e+00,  3.5602e-01,  1.2676e-01, -2.7721e-01, -9.9924e-01,\n",
       "           -5.8075e-01,  1.3515e-02,  1.6880e-01,  6.9774e-01,  3.2102e-01,\n",
       "            1.9245e-01,  3.5330e-01,  2.2057e-02,  4.6364e-01, -2.2714e-01,\n",
       "           -4.4583e-01, -7.1404e-01, -4.5217e-01, -1.6212e-01, -1.1331e+00,\n",
       "           -6.2467e-01, -2.6892e-01, -5.1161e-01, -2.1377e-01,  3.8668e-01,\n",
       "            1.0703e+00,  5.7346e-02,  3.3601e-01,  7.9778e-02, -4.8860e-01,\n",
       "            1.9067e-01, -1.5912e-01, -7.0959e-01, -4.3246e-01,  7.8693e-02,\n",
       "           -1.2654e-01,  3.9586e-01, -2.1940e-01, -2.0176e-01,  4.2478e-01,\n",
       "            8.4289e-01,  1.9410e+00,  3.3079e-01,  2.4239e-01,  6.0100e-01,\n",
       "           -7.1543e-01, -7.6716e-02,  2.2085e-01, -6.6188e-01,  1.9251e-01,\n",
       "            6.8363e-01, -2.8353e-01, -6.5245e-01, -9.5304e-02,  1.4618e-01,\n",
       "           -1.4236e+00, -3.3280e-01,  5.3819e-01, -7.5569e-01, -1.2026e+00,\n",
       "            1.3710e-01, -3.3767e-01, -2.4895e-01, -2.2886e-01,  5.1188e-01,\n",
       "           -8.9177e-02, -1.1397e-01,  1.0936e-01,  3.7124e-01,  9.6954e-01,\n",
       "           -4.0258e-01, -2.8658e-01, -7.9564e-02,  1.0578e+00,  6.0869e-01,\n",
       "            7.5906e-02, -9.7617e-01,  5.4435e-01,  1.2349e+00, -2.9409e-02,\n",
       "           -5.2563e-02, -2.6613e-01,  3.7005e-01,  5.0323e-01, -3.6341e-01,\n",
       "           -1.6169e-01, -2.2512e-01, -3.0101e-02,  1.6728e-01,  7.3488e-01,\n",
       "           -1.0707e-01, -5.6553e-01, -5.0664e-01, -3.9517e-01,  7.7753e-01,\n",
       "           -2.0981e-01, -9.8681e-03,  1.5786e+00,  3.8828e-01, -1.8641e-01,\n",
       "           -1.1631e-01, -1.5065e-01,  1.5687e-02, -1.0724e-01, -5.5562e-01,\n",
       "           -3.3841e-01,  2.3887e-01,  1.9795e-01,  5.9357e-01,  2.7081e-01,\n",
       "            5.6111e-01, -2.6653e-01,  2.0351e-02,  1.7466e-01, -9.9309e-01,\n",
       "           -1.4229e-01,  6.6674e-01,  9.6182e-01,  1.1102e-01, -1.8329e-01,\n",
       "            4.9742e-01, -1.4290e-03, -1.6277e-01,  3.8670e-01,  2.9360e-01,\n",
       "           -2.5346e-01, -1.2521e+00, -3.5369e-01, -2.8529e-02, -6.1879e-01,\n",
       "           -6.5617e-01, -6.3808e-01,  7.3321e-02,  2.4595e-01,  1.6181e+00,\n",
       "            4.2299e-01,  8.7627e-01, -8.9141e-01, -4.2750e-01, -4.9993e-01,\n",
       "            3.8802e-05, -1.1780e+00, -2.3809e-01, -2.8938e-01, -1.1886e+00,\n",
       "            1.7981e-01, -4.7224e-01, -1.5461e-01, -4.4337e-03,  5.5208e-01,\n",
       "            1.9878e-01,  7.7891e-01, -2.7767e-01, -9.2288e-01,  5.3507e-01,\n",
       "           -9.4638e-02,  9.3105e-01,  3.4234e-01, -2.7102e-01,  5.3143e-01,\n",
       "           -4.2076e-01,  1.9502e-01, -8.8844e-01, -3.9239e-01,  4.8026e-02,\n",
       "            1.4506e-01,  6.7603e-01,  1.0749e+00,  7.8920e-02,  2.7557e-01,\n",
       "            6.7226e-01, -1.7034e+00,  1.4370e-01,  1.7826e-01, -1.4898e-01,\n",
       "           -2.3564e-01,  1.9691e-01, -9.4671e-01,  2.4999e-03, -6.4849e-01,\n",
       "           -4.2661e-01, -2.1745e-01, -3.1505e-01,  1.8416e-01, -8.2257e-01,\n",
       "            1.6889e-01, -8.0996e-01,  4.5395e-01, -5.5289e-01, -2.3199e-01,\n",
       "            3.9206e-01,  1.0032e-01, -5.7384e-02,  1.2720e+00,  4.6126e-01,\n",
       "            4.2287e-01, -1.9835e-01,  2.2660e-01,  3.9975e-01,  1.5760e+00,\n",
       "           -1.3280e-01,  6.9233e-02, -4.2143e-01, -4.3841e-01, -4.3512e-01,\n",
       "           -3.8311e-03,  7.0418e-01,  1.9244e-01,  4.5742e-01,  1.2446e-01,\n",
       "           -9.2335e-01,  1.2255e+00,  2.7270e-01, -4.0348e-01,  3.6852e-01,\n",
       "           -1.1424e+00,  5.3877e-02, -5.2892e-02, -3.4598e-01,  4.3471e-02,\n",
       "           -4.6746e-01, -1.8868e-01, -2.8028e-01, -4.2547e-01,  8.9068e-01,\n",
       "           -2.7442e-01, -5.2255e-02, -3.8296e-01, -3.0937e-01,  4.0637e-01,\n",
       "            1.0587e-01,  2.5710e-02, -3.8220e-01, -1.2573e-01, -1.1249e+00,\n",
       "            7.0486e-02,  2.2670e-01,  6.8105e-01, -1.6240e+00,  5.1819e-01,\n",
       "            4.0220e-01,  1.0821e-02, -1.2751e+00, -5.5329e-01,  4.7974e-01,\n",
       "           -1.6475e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.2784,  0.1743, -0.5014,  ...,  0.0942, -0.0029,  0.1530],\n",
       "           [ 0.1101, -0.2763, -0.5944,  ..., -0.0445, -0.0423, -0.0251],\n",
       "           [-0.1141,  0.1898,  0.0056,  ..., -0.2165, -0.1854, -0.1147],\n",
       "           ...,\n",
       "           [ 0.2132, -0.2107, -0.2208,  ..., -0.1755, -0.2149,  0.0638],\n",
       "           [-0.1701,  0.0915, -0.0402,  ..., -0.2235,  0.2090, -0.1912],\n",
       "           [-0.4920,  0.3299, -0.2307,  ...,  0.0772, -0.0610,  0.0582]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-4.4317e-03, -2.6245e-03, -3.1108e-04, -3.7865e-03, -5.6366e-04,\n",
       "            2.4925e-03,  3.7832e-03,  1.8710e-03,  5.5946e-03,  2.4380e-03,\n",
       "            6.6975e-03,  3.1128e-03,  5.7524e-03,  5.1902e-03, -1.9526e-03,\n",
       "            6.4261e-03, -1.5372e-03,  1.5237e-03, -2.5573e-03,  2.6775e-03,\n",
       "            3.0950e-03,  4.6768e-03,  5.4472e-04, -5.8491e-05, -1.0544e-03,\n",
       "            3.3966e-03,  3.6199e-03, -3.6455e-04, -4.4342e-03,  4.8229e-03,\n",
       "            6.3123e-03, -2.7409e-03, -1.1957e-03,  1.3115e-03,  3.2146e-03,\n",
       "           -9.8611e-03, -4.9339e-04, -1.6933e-03, -1.5435e-03,  3.0349e-03,\n",
       "           -4.4876e-03,  1.0422e-04, -2.4340e-03, -9.3462e-04,  1.7226e-03,\n",
       "            3.0203e-03, -1.0125e-03, -5.9593e-03,  5.4118e-04, -2.6579e-04,\n",
       "            1.8865e-04, -3.9234e-04,  1.3342e-03, -5.0482e-03, -3.2021e-03,\n",
       "           -5.0977e-03, -2.0209e-03, -2.0884e-03, -4.1491e-03,  4.4235e-03,\n",
       "           -1.0148e-03,  2.0809e-04,  2.4329e-03, -1.4827e-03, -6.7512e-03,\n",
       "           -2.6170e-03, -5.3465e-03,  3.8585e-03,  6.6188e-03,  5.3834e-04,\n",
       "            2.2038e-03, -3.6051e-03, -1.2247e-03, -1.7332e-03,  1.4787e-03,\n",
       "            4.3731e-04, -1.7433e-03,  4.3336e-04, -5.7297e-04, -3.1947e-03,\n",
       "           -1.3804e-04, -1.6148e-03,  3.3307e-03,  1.2729e-03,  4.8582e-03,\n",
       "           -2.8704e-03,  1.0905e-03, -4.3637e-04,  5.5442e-03,  1.7830e-03,\n",
       "           -2.7133e-03, -2.5579e-03, -3.7059e-03,  1.1326e-03,  5.4317e-03,\n",
       "            5.0932e-03, -1.3235e-03,  1.2897e-03,  1.5688e-03,  1.0824e-04,\n",
       "           -3.8625e-04,  3.3996e-03, -2.9927e-04, -4.0834e-03, -4.6896e-03,\n",
       "           -1.9724e-03, -2.2536e-03,  2.7967e-03,  2.3986e-03, -2.4970e-03,\n",
       "            1.7207e-03,  1.6786e-03, -5.5478e-04,  5.7787e-04, -4.9330e-04,\n",
       "            4.6438e-03,  8.3667e-04, -1.7430e-03, -5.3335e-03, -2.8246e-03,\n",
       "           -1.0516e-03,  4.5833e-03,  5.2108e-03,  4.0955e-03, -2.1067e-03,\n",
       "            4.9136e-03,  2.9817e-03, -1.0229e-02,  3.5207e-03, -2.8693e-04,\n",
       "            2.8487e-03, -3.3788e-03, -8.8806e-04,  3.7235e-03, -9.5513e-04,\n",
       "            3.2541e-04, -6.0305e-03,  1.2457e-03, -4.5310e-03, -1.9132e-03,\n",
       "            1.1549e-03,  3.2009e-03, -1.6617e-03, -2.1286e-03,  6.5823e-03,\n",
       "           -3.0669e-04,  2.1933e-03,  5.1302e-05,  1.1691e-03, -1.0266e-03,\n",
       "            2.5453e-04, -6.4668e-04, -1.4280e-03, -7.4312e-03,  2.1459e-03,\n",
       "            2.8530e-03, -1.4583e-03,  3.0499e-03, -7.2997e-04, -5.4429e-03,\n",
       "           -4.5419e-03,  8.9402e-03, -4.4430e-04, -4.6230e-03,  1.4097e-03,\n",
       "           -1.9680e-03,  2.7237e-03, -2.3044e-03,  4.9422e-03,  3.6238e-03,\n",
       "           -4.4327e-03,  5.7054e-03, -4.1038e-04,  1.3035e-03,  3.1447e-03,\n",
       "           -9.4455e-03, -2.3546e-03, -1.6129e-03,  2.8568e-03, -2.4417e-04,\n",
       "            6.5866e-03,  8.7667e-03, -4.8198e-03,  1.5453e-03, -3.5181e-03,\n",
       "            1.8993e-03,  4.3844e-04, -5.7069e-03,  3.9751e-03,  4.4582e-03,\n",
       "            5.1827e-03, -2.6931e-03, -1.2995e-03, -6.9070e-04, -5.4996e-03,\n",
       "           -1.2454e-03,  1.9579e-03,  3.0180e-04, -2.5155e-03,  1.4135e-03,\n",
       "           -7.2476e-04, -1.3516e-04, -4.5670e-03, -5.4181e-04, -7.5808e-03,\n",
       "            5.3164e-04,  3.8076e-03, -4.7551e-04,  9.6914e-04, -8.2693e-04,\n",
       "           -7.7546e-04, -6.2988e-04,  1.9415e-03, -5.2637e-03, -4.7116e-03,\n",
       "            4.5173e-04, -2.9686e-03,  8.4038e-04, -1.3012e-03, -4.8257e-04,\n",
       "            1.4066e-04,  1.1793e-03,  1.1645e-03,  2.5243e-03, -1.5939e-03,\n",
       "           -3.4420e-03,  2.2981e-03, -7.7286e-04, -1.5799e-03, -3.3537e-03,\n",
       "            2.4781e-03,  1.9892e-03,  5.3454e-04, -8.6430e-04, -4.3252e-03,\n",
       "           -2.8275e-03,  3.1091e-03,  1.7909e-03,  2.6186e-04,  8.7014e-04,\n",
       "            3.3562e-04, -2.3756e-03,  4.4557e-03, -1.4580e-03, -4.9681e-05,\n",
       "            5.8136e-04, -2.8529e-03,  2.6080e-03, -4.3119e-03, -2.1565e-03,\n",
       "            2.6490e-03,  2.3084e-03, -2.2020e-03, -1.7539e-03,  2.2711e-03,\n",
       "           -5.4060e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.2522,  0.1907,  0.0264,  ...,  0.0430,  0.1528,  0.0664],\n",
       "           [-0.0617,  0.2607, -0.0767,  ..., -0.1473,  0.1454,  0.0489],\n",
       "           [ 0.0092,  0.1109, -0.0912,  ..., -0.4372,  0.1691, -0.1512],\n",
       "           ...,\n",
       "           [ 0.0383,  0.0272,  0.0064,  ..., -0.0102,  0.1423, -0.1476],\n",
       "           [-0.1063, -0.1617, -0.0031,  ..., -0.1241,  0.0803,  0.2508],\n",
       "           [ 0.0740, -0.1495, -0.0401,  ...,  0.0051, -0.1455, -0.0281]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0078, -0.0065, -0.0047, -0.0121,  0.0022, -0.0042, -0.0093,  0.0026,\n",
       "           -0.0047, -0.0015,  0.0038, -0.0060, -0.0081, -0.0014, -0.0012,  0.0008,\n",
       "            0.0022, -0.0020, -0.0049,  0.0070,  0.0021,  0.0065,  0.0018,  0.0036,\n",
       "            0.0038,  0.0004,  0.0010,  0.0067,  0.0001, -0.0018, -0.0025,  0.0101,\n",
       "            0.0068,  0.0108,  0.0038,  0.0180, -0.0026, -0.0025,  0.0136, -0.0254,\n",
       "           -0.0020,  0.0010, -0.0123, -0.0029, -0.0026,  0.0025,  0.0012, -0.0041,\n",
       "            0.0054,  0.0034,  0.0086, -0.0029,  0.0034, -0.0146,  0.0012,  0.0107,\n",
       "           -0.0124,  0.0107, -0.0109,  0.0025,  0.0067,  0.0049,  0.0023, -0.0114,\n",
       "            0.0060,  0.0026,  0.0027, -0.0097, -0.0093,  0.0068,  0.0208,  0.0005,\n",
       "            0.0037,  0.0110,  0.0077,  0.0001, -0.0004,  0.0012,  0.0025, -0.0047,\n",
       "            0.0014,  0.0006, -0.0142, -0.0060,  0.0051,  0.0010, -0.0075, -0.0033,\n",
       "           -0.0066, -0.0121,  0.0006,  0.0031,  0.0028, -0.0015, -0.0040, -0.0094,\n",
       "           -0.0045, -0.0072, -0.0040,  0.0107,  0.0104, -0.0223, -0.0072,  0.0014,\n",
       "           -0.0028, -0.0055, -0.0029,  0.0129,  0.0073,  0.0009, -0.0049, -0.0065,\n",
       "           -0.0067, -0.0164,  0.0047, -0.0251, -0.0067, -0.0051,  0.0026,  0.0024,\n",
       "            0.0018,  0.0101, -0.0122,  0.0040, -0.0052, -0.0143,  0.0034, -0.0125,\n",
       "            0.0035,  0.0081,  0.0028, -0.0024, -0.0124,  0.0034, -0.0007,  0.0104,\n",
       "            0.0072,  0.0057,  0.0009, -0.0055,  0.0050,  0.0056,  0.0006,  0.0049,\n",
       "           -0.0085, -0.0006, -0.0023,  0.0010,  0.0026,  0.0004,  0.0154, -0.0081,\n",
       "           -0.0082, -0.0064, -0.0020, -0.0110, -0.0171, -0.0102,  0.0068, -0.0045,\n",
       "            0.0081,  0.0019, -0.0044,  0.0032,  0.0021,  0.0022,  0.0042,  0.0099,\n",
       "            0.0071, -0.0039, -0.0035,  0.0012, -0.0012, -0.0033,  0.0048,  0.0023,\n",
       "           -0.0404,  0.0025,  0.0024,  0.0093,  0.0020,  0.0005,  0.0052, -0.0040,\n",
       "            0.0056,  0.0140, -0.0109, -0.0043, -0.0057, -0.0067,  0.0013, -0.0041,\n",
       "            0.0565,  0.0144,  0.0012,  0.0011,  0.0004, -0.0012, -0.0030, -0.0006,\n",
       "            0.0073, -0.0110, -0.0117,  0.0003, -0.0114, -0.0089, -0.0066,  0.0076,\n",
       "            0.0059, -0.0149,  0.0074,  0.0032, -0.0085, -0.0009, -0.0032,  0.0036,\n",
       "           -0.0150,  0.0342,  0.0031,  0.0072,  0.0004, -0.0066, -0.0222, -0.0112,\n",
       "            0.0137,  0.0089, -0.0122, -0.0161, -0.0031, -0.0009,  0.0014, -0.0117,\n",
       "            0.0109, -0.0124,  0.0026,  0.0159,  0.0065, -0.0058,  0.0080, -0.0005,\n",
       "            0.0046,  0.0032, -0.0044, -0.0061, -0.0023,  0.0008,  0.0042, -0.0016,\n",
       "            0.0039, -0.0074,  0.0010,  0.0005,  0.0008,  0.0039,  0.0101,  0.0046],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0277,  0.2034,  0.0745,  ..., -0.0254, -0.0402, -0.1522],\n",
       "           [-0.1291, -0.3126, -0.2319,  ..., -0.0210, -0.3527, -0.0703],\n",
       "           [-0.3626,  0.1297,  0.2713,  ...,  0.3749,  0.0482,  0.1335],\n",
       "           ...,\n",
       "           [ 0.0824, -0.1482,  0.0007,  ...,  0.1006, -0.4172, -0.0100],\n",
       "           [-0.0803,  0.0893, -0.0201,  ...,  0.0456, -0.2309,  0.0328],\n",
       "           [ 0.0200,  0.2083, -0.1193,  ...,  0.2803,  0.2041,  0.0998]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 1.1211e-02, -1.6331e-01, -1.6700e-04,  1.9191e-02, -2.3633e-01,\n",
       "           -9.6352e-02,  1.8073e-02, -1.6284e-02,  4.4634e-04,  7.6496e-02,\n",
       "           -5.1574e-02, -6.9440e-03,  2.4074e-01,  1.6725e-02,  2.1610e-03,\n",
       "            4.8865e-02, -3.6406e-02,  6.8758e-02,  9.0112e-03,  9.6577e-03,\n",
       "           -2.4924e-03,  1.4940e-02,  1.4120e-02, -1.4470e-02,  2.2292e-01,\n",
       "            4.7722e-02,  8.5748e-03,  1.8005e-03, -8.5060e-03,  1.0226e-01,\n",
       "           -3.9158e-03,  7.3845e-03,  1.7356e-02, -2.1965e-02, -9.9753e-03,\n",
       "            1.2834e-02,  3.6944e-02,  3.9146e-02,  1.2639e-02, -1.3227e-02,\n",
       "            7.1442e-02,  2.5744e-02,  3.6002e-02,  1.8582e-02,  5.0094e-02,\n",
       "            4.7756e-02, -5.9801e-04, -1.9071e-03,  1.8542e-02,  1.5626e-02,\n",
       "            2.4840e-02,  1.4093e-02,  4.4735e-02,  2.2230e-02, -1.3147e-02,\n",
       "            2.5594e-02,  1.6042e-02,  1.2232e-02, -6.7736e-02, -9.4870e-03,\n",
       "            2.1288e-02,  4.9193e-03, -2.3832e-02,  4.7102e-02, -7.1482e-03,\n",
       "            3.8908e-02, -2.4770e-02,  4.0406e-02, -1.1186e-02,  2.5552e-02,\n",
       "           -1.6411e-02, -3.1023e-02, -3.0118e-02,  6.7058e-04,  2.0814e-04,\n",
       "            1.8033e-02, -3.7312e-02,  2.8617e-02, -3.1992e-04,  2.6014e-02,\n",
       "           -2.6126e-02,  6.9945e-03, -3.2937e-02,  2.8165e-02,  8.4338e-02,\n",
       "            8.8337e-03, -1.6336e-02, -1.8331e-02, -1.4975e-02,  2.3307e-02,\n",
       "            1.0425e-02,  4.1550e-02,  2.6606e-03,  1.3923e-02,  1.9726e-02,\n",
       "            3.2870e-02, -2.9880e-02,  2.2940e-03, -3.5814e-02,  8.9877e-03,\n",
       "           -1.3798e-02,  7.0824e-03,  4.2070e-02,  4.4636e-02,  9.7863e-03,\n",
       "            2.2891e-03, -1.7010e-02,  1.1233e-02, -3.6449e-02,  3.0008e-02,\n",
       "            3.6748e-03,  1.6821e-02, -1.2100e-03, -3.4101e-02, -2.4240e-02,\n",
       "            1.5582e-02, -3.0487e-02,  2.2691e-04, -1.9487e-02,  5.0281e-03,\n",
       "            3.6999e-02, -2.5328e-04,  1.2663e-02, -5.7864e-03, -1.2254e-02,\n",
       "            1.7185e-02,  1.4421e-03,  2.5721e-02, -1.9232e-02,  3.0397e-02,\n",
       "           -4.4797e-02,  3.6693e-02, -1.9961e-02,  9.7080e-03, -3.0681e-01,\n",
       "            1.6862e-02, -7.1985e-03, -1.0432e-02, -4.0656e-02,  3.1218e-02,\n",
       "           -2.0943e-01, -2.1068e-02, -2.2422e-02, -1.0806e-03,  1.3949e-02,\n",
       "            2.8573e-03,  2.5820e-03,  7.6545e-03, -1.5768e-02,  3.4498e-02,\n",
       "           -3.8528e-03,  2.7571e-02, -5.8779e-03, -8.7103e-03, -8.9813e-03,\n",
       "            2.5737e-03, -1.2023e-02,  1.3146e-02, -4.3159e-02,  4.2785e-02,\n",
       "           -6.7266e-03, -3.2579e-03,  1.5796e-02,  2.8789e-02, -5.2169e-02,\n",
       "           -1.8466e-02, -1.8319e-02, -1.8565e-03,  1.3530e-02,  9.2541e-03,\n",
       "            3.9766e-02, -2.8740e-03, -2.6469e-02,  3.6067e-02, -4.7411e-03,\n",
       "            7.9855e-03,  9.8360e-03,  3.9404e-02, -1.3818e-02, -1.8328e-02,\n",
       "            2.3345e-03, -2.7739e-02, -1.2277e-03, -1.4997e-02, -1.1459e-02,\n",
       "            1.3110e-02, -4.5253e-03,  1.9533e-02, -2.2695e-03, -2.3379e-02,\n",
       "           -8.8255e-02, -1.0315e-02,  2.7658e-03,  2.7564e-02,  1.2910e-02,\n",
       "           -6.3840e-05,  3.2058e-03,  3.9236e-02, -1.0684e-02,  2.1520e-02,\n",
       "           -1.8838e-02, -8.4327e-03, -3.1965e-02,  3.1544e-03,  1.3748e-02,\n",
       "           -3.1015e-02, -3.9551e-03,  7.8157e-03, -4.7216e-02, -9.6379e-03,\n",
       "           -9.8551e-02, -5.6034e-03, -2.1655e-02, -4.8854e-03, -1.8855e-02,\n",
       "           -6.6005e-03, -4.4042e-03,  1.9294e-02, -3.1168e-02,  1.3986e-01,\n",
       "            2.1182e-03,  1.6493e-03, -2.4489e-02,  1.6568e-02, -1.4845e-02,\n",
       "           -7.9525e-03,  2.9267e-02,  1.7627e-02, -3.3218e-02, -3.1024e-03,\n",
       "            1.1617e-02, -2.4518e-02,  1.3957e-02,  1.7635e-02, -6.9678e-04,\n",
       "            2.2489e-03, -2.8480e-02,  9.2546e-03, -1.5010e-02, -2.0336e-02,\n",
       "            2.4907e-03,  2.0665e-02, -1.2882e-02, -5.8995e-02, -1.9543e-02,\n",
       "            1.4339e-03,  2.4333e-03, -1.2005e-04,  1.5295e-02,  5.9782e-03,\n",
       "           -3.6266e-02, -5.5483e-03, -4.2611e-02, -3.4258e-02, -1.2513e-02,\n",
       "           -2.7210e-02], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-9.6225e-02,  6.1948e-02,  1.2572e+00,  ...,  5.9147e-02,\n",
       "            -1.6920e-01,  2.5558e-01],\n",
       "           [ 2.2674e-02, -3.6141e-01, -3.8022e-01,  ..., -3.6353e-01,\n",
       "            -1.5644e-01,  7.9536e-04],\n",
       "           [ 2.5933e-01,  8.9037e-01,  2.3981e-01,  ...,  1.1111e-01,\n",
       "             1.8453e-01,  3.8471e-01],\n",
       "           ...,\n",
       "           [ 1.6637e-01, -1.2529e-01, -2.8504e-01,  ..., -4.1998e-01,\n",
       "             9.5660e-02, -3.8030e-01],\n",
       "           [-4.3380e-01, -4.4145e-01,  9.8901e-02,  ...,  1.4984e-01,\n",
       "             2.9751e-01,  3.5937e-01],\n",
       "           [ 3.4604e-01,  2.1062e-01, -1.0253e-01,  ...,  1.0299e-01,\n",
       "            -3.9958e-02, -2.6239e-01]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 2.7125e-01,  6.2211e-01, -8.3502e-01, -8.6183e-01,  1.6224e-01,\n",
       "           -7.7877e-01, -7.9350e-01, -8.1260e-01,  3.3522e-01,  1.1686e-01,\n",
       "           -1.4702e-01, -6.3896e-01, -2.0776e-01, -6.4597e-01, -7.7705e-01,\n",
       "            8.8201e-02,  3.1417e-01, -5.8252e-01,  7.2734e-02,  8.0776e-01,\n",
       "            6.5542e-02, -4.0827e-02, -7.6121e-01, -4.5727e-01, -4.6780e-01,\n",
       "           -6.0052e-02, -3.9671e-01,  5.0727e-01,  5.8850e-01, -7.6643e-01,\n",
       "            7.2935e-01,  7.5541e-01,  5.8972e-01, -2.1391e-01,  3.8004e-01,\n",
       "           -6.3862e-01,  4.7538e-01,  4.6416e-01, -3.3952e-01, -1.0336e-01,\n",
       "            7.6004e-01,  2.2009e-01,  4.3427e-01,  1.3700e-01, -3.5034e-01,\n",
       "            5.9069e-01, -1.2764e-01,  1.2020e-01,  1.6962e-01,  3.5576e-01,\n",
       "           -5.4598e-01,  4.8533e-01, -6.8693e-01,  4.5118e-01, -4.3137e-01,\n",
       "           -9.7053e-01,  6.2307e-01,  2.3352e-01,  5.5806e-02, -2.8341e-01,\n",
       "           -1.5749e-01,  3.0511e-01, -3.6751e-01,  6.1273e-01,  2.4204e-01,\n",
       "            7.7498e-02, -9.3000e-02, -1.5837e-02,  1.8448e-01, -3.8567e-01,\n",
       "            2.2965e-01,  3.6786e-01,  3.0860e-01, -6.8131e-02,  1.9246e-01,\n",
       "           -1.7828e-01, -7.8484e-01,  2.4671e-01, -1.9203e-01,  2.5562e-01,\n",
       "            2.1095e-01, -1.0041e-01, -4.2274e-01, -1.4318e-01, -6.6635e-01,\n",
       "            2.6820e-01, -5.6469e-02, -5.0031e-01, -4.0734e-01,  1.1365e-01,\n",
       "            5.0849e-01,  1.1405e-01, -4.7150e-02,  4.7099e-01,  2.5177e-02,\n",
       "           -6.3003e-01, -9.2417e-01, -4.1027e-02, -1.1097e+00,  8.8885e-01,\n",
       "           -4.3688e-01, -5.7067e-01,  7.9866e-01,  1.0604e+00,  8.7754e-01,\n",
       "            6.5730e-01, -1.0175e+00, -7.6179e-01, -3.4063e-01,  7.3774e-01,\n",
       "            4.1359e-01, -6.8100e-01, -8.9977e-01,  4.4418e-01, -1.8893e-01,\n",
       "           -3.9923e-01, -8.7340e-01,  1.7856e-01,  8.3093e-01, -1.1640e+00,\n",
       "           -6.1766e-01, -4.9348e-01, -1.0507e+00,  4.1007e-01,  2.1382e-01,\n",
       "            6.5425e-02,  2.4946e-01,  9.4245e-01,  5.2365e-01,  1.0764e+00,\n",
       "            1.3678e+00,  4.2196e-01, -1.6556e-01, -1.7929e+00,  7.3713e-01,\n",
       "            9.6796e-01, -1.7227e+00,  7.7184e-01,  2.1976e-01,  8.2077e-01,\n",
       "           -1.2181e-03, -4.4196e-01, -5.3909e-01,  9.1876e-01,  1.0127e+00,\n",
       "           -1.0983e+00, -6.7646e-01,  3.8535e-01, -1.2361e+00,  8.2001e-01,\n",
       "            3.1145e-01, -4.8144e-01,  9.9831e-03,  6.2302e-01, -3.8867e-01,\n",
       "           -1.6617e-01, -1.5229e-01,  8.0626e-02, -9.4440e-01,  1.1298e-01,\n",
       "           -2.6135e-01,  5.3652e-01,  4.1736e-01, -6.7794e-01,  5.3194e-01,\n",
       "           -4.5086e-02, -4.8825e-01,  1.5415e-01,  2.9959e-02, -7.8967e-01,\n",
       "            5.8688e-01, -2.6382e-01, -7.5495e-02,  6.2968e-01, -4.2357e-02,\n",
       "            5.4050e-01, -4.9304e-01, -5.9185e-01,  1.6924e-01, -8.5479e-02,\n",
       "           -3.8470e-01, -3.1180e-01,  4.6799e-01, -3.5823e-01, -3.8430e-01,\n",
       "            5.6411e-01, -2.3361e-01,  7.7712e-01,  1.8371e-01, -9.4922e-01,\n",
       "           -7.3527e-02, -8.0899e-02,  7.4480e-01,  5.5442e-01, -3.3853e-01,\n",
       "            1.0185e+00,  9.2926e-01,  1.0118e+00, -4.4848e-01,  4.0343e-01,\n",
       "           -6.8756e-01, -5.7681e-01,  1.2414e+00, -4.2510e-01, -4.9118e-01,\n",
       "           -4.2211e-01, -1.8757e-02,  7.1235e-02,  4.6799e-01,  2.7178e-01,\n",
       "           -8.4759e-01,  1.9536e-01, -6.2849e-01,  1.1279e-01,  5.6343e-01,\n",
       "            4.4750e-01, -3.8602e-01, -9.5275e-02, -7.7625e-01, -1.6530e-01,\n",
       "            2.1233e-01,  4.6775e-01,  5.5895e-01, -1.0110e-01, -2.2572e-01,\n",
       "           -5.0094e-02,  7.3395e-01, -8.1002e-02, -1.9856e-01, -4.7581e-01,\n",
       "           -1.3602e-01,  5.3767e-01,  3.2554e-01,  4.8107e-01, -6.6084e-01,\n",
       "            2.9149e-01,  7.0629e-02, -4.4568e-01, -2.2236e-02, -9.7515e-02,\n",
       "           -9.0850e-01, -3.5446e-02,  3.1928e-01,  3.6949e-01,  1.7670e-03,\n",
       "            3.2811e-01,  2.9773e-01, -1.6850e-01, -3.6276e-02,  5.5261e-01,\n",
       "            7.2665e-01,  1.8575e-01, -2.6417e-01, -6.5408e-02,  6.5245e-01,\n",
       "           -3.1785e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.1443,  0.1271,  0.2587,  ...,  0.0406, -0.0911,  0.1677],\n",
       "           [ 0.0801, -0.0628, -0.2078,  ...,  0.2176,  0.3073,  0.1067],\n",
       "           [-0.1749,  0.0863,  0.1918,  ...,  0.1169,  0.0049, -0.3667],\n",
       "           ...,\n",
       "           [-0.6929, -0.1976,  0.5285,  ...,  0.4843,  0.1537,  0.3669],\n",
       "           [-0.1478,  0.0179,  0.1903,  ...,  0.0481, -0.0455,  0.0914],\n",
       "           [-0.2759,  0.0616, -0.2615,  ...,  0.0436, -0.2990, -0.1418]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-1.6805e-03, -1.8501e-03,  1.4941e-03,  2.7686e-03,  2.4472e-03,\n",
       "            2.9661e-03,  2.7257e-03,  1.3954e-03, -2.1595e-04, -1.0025e-04,\n",
       "            2.3035e-03,  1.1538e-03, -1.1992e-03, -1.1417e-03,  5.0604e-04,\n",
       "            1.4766e-03,  1.1945e-04,  2.1905e-03,  1.9569e-03, -2.5124e-03,\n",
       "           -9.4613e-05,  8.5310e-04,  1.2211e-03,  6.9301e-04, -1.2169e-04,\n",
       "           -3.2713e-04, -3.4011e-04,  1.3846e-03, -8.7045e-04, -1.6379e-03,\n",
       "           -1.1135e-03, -7.1935e-04,  2.5127e-03, -1.9639e-03, -2.8149e-03,\n",
       "            2.1657e-03, -8.4289e-05,  3.4217e-03, -6.3301e-04, -1.9192e-03,\n",
       "           -7.7546e-04,  2.0249e-03, -4.5511e-04, -5.6965e-03,  6.5741e-04,\n",
       "           -7.8495e-04, -1.3389e-03,  8.7958e-04,  1.2787e-03,  1.1280e-03,\n",
       "            7.9373e-04, -2.3593e-03,  1.3710e-04,  2.7043e-03, -2.8308e-03,\n",
       "           -1.7871e-03,  3.0101e-03,  1.8927e-03,  3.4827e-03, -2.2529e-03,\n",
       "            9.3287e-04,  1.6342e-03, -1.0795e-03, -2.8164e-03,  3.3874e-03,\n",
       "           -1.4891e-03, -2.0258e-03,  2.1457e-03, -4.4559e-03,  8.8100e-04,\n",
       "           -3.0169e-03,  3.5361e-03,  3.7781e-04, -1.1554e-03, -3.4062e-04,\n",
       "           -3.1988e-04,  2.4576e-03,  4.9676e-03, -1.4091e-04,  3.0120e-03,\n",
       "            4.3199e-04, -3.4770e-03, -4.4917e-03, -1.8102e-04, -2.0348e-03,\n",
       "            5.2936e-03, -2.9235e-03, -1.1970e-03, -5.2194e-05,  2.5094e-03,\n",
       "           -2.5511e-03,  2.6840e-03,  2.4201e-03,  7.2476e-04,  1.8120e-03,\n",
       "            2.0120e-03, -2.1968e-03, -3.3387e-03, -3.6078e-03, -5.5155e-04,\n",
       "           -3.8553e-03, -1.9342e-03,  2.0574e-03,  3.2003e-03,  2.3259e-03,\n",
       "            3.5353e-03, -7.2481e-03,  4.6770e-04,  3.0637e-03, -1.1661e-03,\n",
       "            1.1955e-03, -1.1339e-03, -6.0056e-04, -1.8845e-03,  2.2304e-03,\n",
       "           -5.2753e-05, -3.7269e-03, -2.7281e-03, -1.2205e-03, -4.4045e-03,\n",
       "           -1.6690e-03, -1.7123e-03, -4.5332e-03,  5.0384e-04, -2.2402e-03,\n",
       "           -3.5607e-03,  2.3820e-03,  1.8428e-03, -3.4326e-03,  8.2207e-04,\n",
       "            2.0642e-03,  3.5307e-03,  4.5732e-03,  7.3483e-04, -1.2540e-03,\n",
       "           -1.7288e-03,  3.1301e-03, -1.7725e-03,  5.7458e-04, -3.3309e-03,\n",
       "           -3.7626e-04,  6.5416e-04,  5.3879e-04,  6.7843e-04, -3.5651e-03,\n",
       "           -1.3898e-03,  1.0433e-03, -1.7646e-03,  3.5155e-03, -5.4810e-03,\n",
       "           -4.4369e-03,  3.6445e-04, -5.3003e-04, -3.9258e-04,  2.8878e-04,\n",
       "           -3.7345e-03,  1.2361e-03, -3.5807e-03, -1.6853e-03, -3.5601e-03,\n",
       "            4.0036e-05,  2.2769e-04,  1.4977e-04,  1.5591e-03, -1.2566e-03,\n",
       "           -6.8437e-04, -6.6769e-04,  1.6086e-03,  1.6045e-04,  1.4544e-03,\n",
       "           -1.5455e-03,  8.8938e-04,  1.9442e-04,  6.1498e-04, -2.3778e-03,\n",
       "            5.1758e-04,  3.2692e-04, -2.1043e-04, -2.1645e-04,  1.0124e-03,\n",
       "           -4.0652e-04, -1.1931e-03,  4.1604e-06,  2.4364e-03,  1.5259e-03,\n",
       "            1.4918e-03, -1.2238e-04,  9.4973e-04, -2.5595e-05,  1.7158e-03,\n",
       "           -3.7707e-04, -1.2617e-03,  1.6486e-03,  9.6282e-04, -1.2746e-03,\n",
       "            3.2407e-04,  3.1009e-03,  1.9957e-04, -1.4755e-03, -2.9783e-04,\n",
       "           -1.2623e-03,  1.9742e-03,  3.1924e-03, -1.0593e-03, -1.8595e-03,\n",
       "           -2.8192e-03, -1.7974e-03,  2.1005e-03,  2.1707e-03,  1.2458e-04,\n",
       "           -9.6020e-04, -3.0916e-03, -4.5954e-04,  7.4636e-04, -6.7859e-04,\n",
       "            1.1493e-03, -2.8202e-03, -2.9762e-03, -4.7933e-04, -2.0150e-03,\n",
       "            1.5864e-03,  1.1982e-03, -8.9131e-04, -4.7869e-04,  2.1563e-03,\n",
       "            7.0997e-03,  6.2752e-03,  1.1163e-03, -3.9128e-03, -4.0227e-03,\n",
       "            9.5112e-03,  4.3224e-03,  7.3189e-03,  6.5172e-03, -5.9002e-03,\n",
       "            1.9486e-03,  3.7589e-03, -7.3621e-03,  5.0543e-03,  7.1928e-03,\n",
       "           -6.7036e-03,  4.4397e-03,  2.5924e-03,  3.4875e-03, -8.2732e-04,\n",
       "            6.6003e-03,  2.5557e-03, -4.5472e-03,  4.0853e-03,  3.2818e-03,\n",
       "            9.2595e-03, -1.6311e-03, -2.0843e-03, -6.8014e-04,  7.3009e-03,\n",
       "           -7.7120e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0531, -0.0512, -0.0338,  ..., -0.0300,  0.0214,  0.0872],\n",
       "           [ 0.0467, -0.0440, -0.0155,  ...,  0.1205, -0.0454, -0.0804],\n",
       "           [-0.0710,  0.0429,  0.0579,  ..., -0.0337, -0.1452,  0.0279],\n",
       "           ...,\n",
       "           [-0.0581, -0.0945,  0.0579,  ..., -0.0238, -0.0187,  0.1805],\n",
       "           [ 0.0479,  0.0077,  0.0592,  ...,  0.0802,  0.0119, -0.0524],\n",
       "           [ 0.0371, -0.0318,  0.2691,  ..., -0.0642,  0.0563, -0.0452]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-5.0788e-03,  8.1893e-04,  1.3885e-03,  6.1210e-03,  1.5187e-03,\n",
       "           -4.7098e-03, -3.5521e-03, -1.8826e-03,  1.0397e-03, -2.2403e-02,\n",
       "           -6.3585e-03, -9.9166e-03, -1.9232e-03, -3.1238e-03, -4.0146e-03,\n",
       "           -8.6697e-03,  3.0151e-03, -2.3465e-03, -2.1114e-03, -2.0185e-02,\n",
       "            3.6466e-03, -7.5561e-04,  6.0559e-04,  9.7665e-03,  3.9648e-03,\n",
       "           -1.2565e-04,  1.0064e-03,  3.4512e-03, -3.2252e-03, -8.1038e-03,\n",
       "           -4.0265e-03,  1.3011e-03, -1.0167e-03,  3.2094e-03,  6.9067e-04,\n",
       "           -2.5903e-03,  3.7933e-03, -4.8722e-03,  2.3668e-02, -6.1649e-03,\n",
       "            8.3691e-03,  6.6035e-03, -1.8141e-02,  5.2796e-03,  9.2171e-04,\n",
       "            2.6223e-04, -1.6724e-03, -5.8438e-03, -7.9368e-03, -1.1897e-03,\n",
       "           -3.7727e-03, -2.9146e-03, -4.0592e-03, -1.1007e-02,  2.6770e-03,\n",
       "           -3.4725e-03, -4.5769e-03, -8.4875e-03,  3.5824e-03,  1.9227e-03,\n",
       "           -3.4436e-03, -6.2924e-03, -1.7191e-03,  9.1101e-04, -4.2834e-03,\n",
       "            3.3061e-04,  7.1682e-03,  7.5689e-04,  4.4219e-05,  3.3089e-02,\n",
       "            4.1395e-03, -7.4006e-03, -1.2023e-02,  1.7486e-03,  1.1637e-02,\n",
       "           -1.3198e-03, -2.6484e-02, -7.1938e-03,  5.6589e-03,  5.0900e-03,\n",
       "            7.9921e-03,  1.1211e-02,  6.1572e-04,  6.3204e-03, -2.0420e-05,\n",
       "            7.8830e-03,  1.3086e-03,  4.4447e-03,  8.1166e-03,  2.4522e-03,\n",
       "            1.3540e-03, -2.2326e-03,  1.9290e-03,  4.8234e-03,  1.4000e-03,\n",
       "           -9.0798e-03,  6.7045e-03, -3.2262e-03, -4.7402e-03,  3.6757e-04,\n",
       "            1.4063e-03,  9.0503e-03, -1.5068e-03, -2.5350e-03, -4.9131e-03,\n",
       "            1.3020e-02,  3.6043e-03,  8.8871e-03, -2.0707e-03,  6.5969e-03,\n",
       "           -5.9313e-03, -1.8223e-02, -1.1778e-02,  1.5783e-02,  3.0021e-02,\n",
       "           -5.5809e-03,  9.8672e-03,  7.4454e-03, -8.9816e-03, -1.9420e-03,\n",
       "            1.2872e-02,  8.7508e-03, -4.2025e-03, -1.5249e-02,  1.8798e-03,\n",
       "            9.0412e-03,  4.8796e-03,  9.9712e-03, -1.5154e-02,  1.0289e-02,\n",
       "           -4.2470e-03, -9.3309e-03,  3.8157e-03, -3.0598e-04, -3.5266e-03,\n",
       "            3.1067e-03, -1.0007e-02, -2.2276e-02, -6.4702e-03, -4.5575e-03,\n",
       "            3.8646e-03,  1.3402e-03,  9.2322e-03,  1.0626e-03, -4.7862e-03,\n",
       "           -1.3878e-02,  2.5659e-03,  7.1734e-03, -2.1690e-03,  2.1346e-03,\n",
       "           -6.6977e-03,  8.1123e-03,  1.1802e-02, -2.0465e-03,  5.0172e-03,\n",
       "           -5.4373e-03,  9.4298e-03, -5.5639e-03,  1.1749e-02, -1.2762e-02,\n",
       "           -2.1636e-03,  1.1390e-02,  4.3400e-03, -5.5528e-03,  4.7529e-03,\n",
       "           -4.8568e-03,  6.7673e-03,  1.8562e-03, -7.4006e-04,  6.3603e-03,\n",
       "            1.5966e-03, -2.0510e-03,  5.2148e-03, -1.0334e-02,  6.7966e-03,\n",
       "            7.5753e-03,  2.4128e-03, -4.3250e-03,  6.1817e-03,  1.3341e-03,\n",
       "            2.6669e-03,  4.9609e-04, -3.6881e-03, -5.7174e-05,  3.7004e-03,\n",
       "           -7.3340e-05,  4.6428e-03, -3.2603e-03,  4.0603e-03, -9.2300e-03,\n",
       "           -1.5915e-04, -2.5602e-03,  6.2734e-03, -6.2513e-03,  1.7430e-03,\n",
       "            4.5149e-04,  3.5746e-04,  9.5486e-03, -9.3531e-03, -4.2176e-02,\n",
       "            6.1027e-03,  3.1056e-03,  6.6629e-03, -6.9341e-03, -3.4150e-03,\n",
       "            7.8774e-03, -1.4014e-02,  8.4607e-04,  1.2073e-02, -5.0635e-03,\n",
       "            6.6043e-03,  6.8810e-03,  5.1349e-03,  5.1710e-03, -5.4123e-04,\n",
       "            4.4218e-03,  3.5509e-03,  4.4775e-04,  5.9761e-04, -1.4332e-03,\n",
       "           -9.1353e-03,  4.6941e-03,  8.6746e-03, -9.9633e-03,  7.0317e-03,\n",
       "            1.9018e-03, -2.4652e-03,  1.1776e-02, -5.6906e-04,  6.0398e-04,\n",
       "           -2.9997e-03, -5.9355e-03, -1.7101e-03,  3.0522e-03, -1.5735e-03,\n",
       "            4.7706e-04,  1.5064e-05, -4.4323e-03,  4.8333e-03,  1.4947e-03,\n",
       "            4.8695e-04,  1.0635e-03,  1.6232e-04,  7.3480e-03,  7.9042e-03,\n",
       "           -2.9693e-02,  7.3894e-03,  2.6076e-03, -1.2534e-03, -7.1981e-03,\n",
       "           -2.5081e-03, -1.0871e-02, -6.8247e-03,  9.4858e-03, -6.6518e-03,\n",
       "            4.0414e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0503,  0.0115,  0.0487,  ..., -0.3857, -0.1445, -0.0716],\n",
       "           [-0.1676,  0.1421,  0.0237,  ...,  0.1485, -0.0409,  0.0344],\n",
       "           [-0.2460,  0.0613,  0.0721,  ...,  0.0117, -0.2194,  0.0110],\n",
       "           ...,\n",
       "           [-0.1630, -0.1083, -0.0105,  ..., -0.0332,  0.0375,  0.0460],\n",
       "           [ 0.0482,  0.0097,  0.1487,  ...,  0.0410, -0.0243,  0.0100],\n",
       "           [-0.0265,  0.0294,  0.0294,  ...,  0.3804, -0.1467,  0.0313]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 7.5659e-03, -8.9094e-02, -6.5648e-02, -1.9960e-02, -3.6031e-02,\n",
       "            3.1892e-02,  6.1023e-02, -3.5311e-02,  2.9823e-02,  3.6264e-02,\n",
       "           -1.2673e-02,  1.0677e-02,  4.9773e-02, -5.0820e-02,  2.6828e-02,\n",
       "            2.7722e-03,  4.1147e-02,  1.2946e-01,  8.4039e-02, -5.8080e-03,\n",
       "            4.6445e-02,  6.8134e-03, -4.9733e-02, -1.8967e-02,  3.7083e-02,\n",
       "            6.5865e-02,  2.4081e-02,  2.6150e-02,  1.5159e-02, -2.7970e-02,\n",
       "            3.1484e-02,  6.9114e-02,  4.3324e-03,  3.1621e-02, -9.2921e-04,\n",
       "            3.9450e-02,  2.4510e-04,  9.7474e-03, -1.5153e-02, -6.5309e-03,\n",
       "           -6.5205e-02,  2.7648e-02, -4.7252e-02,  1.6877e-03,  3.1742e-02,\n",
       "            3.8916e-02,  2.1398e-02, -1.3149e-02, -1.5613e-02, -2.5492e-02,\n",
       "            4.2329e-02,  9.3881e-03, -2.1821e-02,  4.4659e-02, -1.7160e-02,\n",
       "            3.6748e-02,  1.0739e-02, -4.1105e-02, -4.0655e-02,  4.0535e-02,\n",
       "           -3.0072e-02,  1.2654e-02, -3.4230e-02, -2.0780e-03,  3.3012e-02,\n",
       "            4.7170e-03, -2.5711e-02, -5.9418e-03, -3.2323e-02,  4.9894e-02,\n",
       "            4.6704e-02,  1.9818e-02,  1.1917e-02,  6.9849e-03, -1.3689e-02,\n",
       "            1.3372e-02, -2.2743e-02, -2.1320e-02, -1.6921e-02,  1.4704e-02,\n",
       "            2.9810e-02,  1.9052e-02,  3.0473e-02, -2.0100e-03, -4.9943e-03,\n",
       "            1.4771e-02, -4.8438e-02,  1.0452e-02, -1.8468e-02,  4.3619e-02,\n",
       "           -1.4393e-02, -1.9626e-02,  4.9498e-02,  2.5118e-02, -3.0322e-02,\n",
       "            5.2204e-02, -1.0567e-02, -7.3490e-03, -4.3825e-02, -2.3364e-02,\n",
       "           -1.4712e-02, -4.7957e-02,  1.6071e-02,  1.9099e-02,  1.7141e-02,\n",
       "           -9.5275e-03,  5.3057e-04, -3.0365e-02, -1.6485e-02, -6.2676e-02,\n",
       "           -6.9654e-03,  2.8786e-02, -1.0638e-02,  2.0852e-02, -1.5010e-02,\n",
       "            1.7023e-02,  1.9336e-02,  3.0530e-02, -2.6365e-02,  2.8162e-02,\n",
       "           -5.3308e-02,  2.3250e-02,  6.1814e-02, -1.2627e-02,  1.1062e-02,\n",
       "            1.7917e-02,  4.5129e-03, -2.4952e-02, -2.0733e-02, -1.1800e-02,\n",
       "           -7.3628e-03,  1.9372e-02, -2.8630e-02, -8.7045e-03, -2.8919e-01,\n",
       "           -4.2884e-03,  3.5368e-03, -2.3923e-02, -1.8597e-02,  3.9492e-02,\n",
       "           -1.3466e-02, -9.5859e-03,  2.5206e-03, -2.3755e-02, -3.9077e-03,\n",
       "            6.8911e-02,  1.3199e-02, -5.2567e-02, -8.1967e-03, -3.3792e-03,\n",
       "            8.3027e-03, -1.7395e-02, -2.2570e-02,  3.4074e-02, -8.1229e-03,\n",
       "           -2.5441e-03,  8.8097e-03,  8.5716e-03, -1.7510e-02,  3.8220e-02,\n",
       "           -7.9277e-03, -2.8573e-02, -2.3180e-02,  5.5512e-03,  1.3279e-02,\n",
       "            1.6027e-02,  1.5504e-02,  4.3934e-03, -1.5077e-02,  1.4113e-02,\n",
       "           -1.7511e-02, -2.4153e-02, -2.7064e-03,  1.2436e-02, -3.0060e-03,\n",
       "           -1.6845e-02, -6.0777e-03, -9.7494e-03,  2.0627e-02,  2.8902e-02,\n",
       "           -6.0577e-03, -5.2790e-02, -6.9504e-03,  4.9198e-03, -7.0184e-02,\n",
       "            5.4290e-03, -5.6890e-03, -1.0247e-02,  7.1711e-03, -3.0276e-02,\n",
       "           -7.7929e-02, -2.2667e-02,  4.9459e-02,  2.4492e-02, -4.7207e-02,\n",
       "           -2.5849e-02, -8.8381e-03,  6.0006e-04, -3.8090e-02,  2.6916e-02,\n",
       "            4.3388e-02, -1.1771e-02,  7.6920e-03, -3.0978e-02,  2.0439e-04,\n",
       "            1.1356e-02,  3.5912e-02,  1.8490e-02,  2.5020e-02, -3.4820e-02,\n",
       "           -1.1904e-01, -1.3754e-02, -1.9593e-02, -6.5234e-03,  1.8696e-02,\n",
       "            8.5288e-03,  2.1111e-02,  2.9756e-02,  3.9474e-03, -1.0628e-02,\n",
       "           -1.2329e-02,  1.6522e-02,  1.0667e-01,  1.1038e-02, -2.9358e-02,\n",
       "            1.7776e-02, -2.6297e-02,  1.7669e-03, -2.0225e-02,  6.9246e-03,\n",
       "            2.9137e-02, -2.0449e-02, -1.8911e-02,  9.9971e-03, -5.3392e-02,\n",
       "           -3.3269e-02,  4.8827e-02, -1.0998e-02,  3.0601e-02, -9.0036e-03,\n",
       "            5.3477e-03, -1.2248e-02,  5.7179e-02, -6.3659e-03, -2.1258e-02,\n",
       "           -2.6377e-02, -1.5880e-02,  2.2227e-02,  1.1707e-02,  9.9757e-04,\n",
       "            2.1384e-02, -2.1834e-02,  1.0302e-02, -8.6090e-03, -1.4487e-02,\n",
       "            3.3804e-02], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0211,  0.4296,  0.1592,  ...,  0.0026, -0.1061, -0.1298],\n",
       "           [ 0.0241,  0.5568, -0.0079,  ...,  0.0247, -0.2375, -0.1376],\n",
       "           [ 0.3130,  0.3502,  0.0998,  ...,  0.0779,  0.0631, -0.1461],\n",
       "           ...,\n",
       "           [-0.2015,  0.6264,  0.3453,  ...,  0.0356, -0.0092, -0.0735],\n",
       "           [ 0.2287,  0.4729,  0.2223,  ...,  0.0778,  0.0341,  0.2472],\n",
       "           [-0.1587,  0.3307,  0.1818,  ...,  0.1795, -0.1786,  0.0691]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.5280, -0.6943, -0.6538, -0.5516, -0.6556, -0.6568, -0.4306, -0.5877,\n",
       "           -0.5582, -0.6091, -0.4743, -0.6675, -0.5781, -0.4244, -0.7899, -0.7778,\n",
       "           -0.5594, -0.6358, -0.7673, -0.6355, -0.6702, -0.5965, -0.4614, -0.7000,\n",
       "           -0.5255, -0.3332, -0.7037, -0.6665, -0.6131, -0.6869, -0.5560, -0.6233,\n",
       "           -0.4158, -0.6862, -0.6694, -0.5118, -0.5773, -0.6005, -0.4581, -0.6518,\n",
       "           -0.6023, -0.4705, -0.7336, -0.7900, -1.4498, -0.5754, -0.6399, -0.6969,\n",
       "           -0.5959, -0.4789, -0.6956, -0.5059, -0.6277, -0.5916, -0.5523, -1.2596,\n",
       "           -0.7195, -0.7948, -0.6704, -0.7387, -0.5394, -0.7013, -0.6682, -0.3962],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0853,  0.1667,  0.1732,  ..., -0.2456,  0.0809,  0.0139],\n",
       "           [-0.1483,  0.0310, -0.1197,  ..., -0.1654, -0.0417, -0.0051],\n",
       "           [-0.2769,  0.1430, -0.2184,  ...,  0.0916, -0.0287, -0.2102],\n",
       "           ...,\n",
       "           [-0.1126, -0.0871, -0.1665,  ..., -0.5025, -0.3731, -0.1983],\n",
       "           [-0.0243,  0.1094, -0.0176,  ...,  0.1660,  0.0190,  0.1290],\n",
       "           [ 0.0446, -0.2680,  0.0245,  ...,  0.3113,  0.0996, -0.1046]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-7.0715e-03,  5.1108e-02,  7.1118e-02, -1.5270e-01, -1.7467e-01,\n",
       "           -2.1165e-01, -4.9334e-02,  5.8713e-02,  1.9944e-01,  1.1674e-01,\n",
       "           -1.5104e-01,  4.3781e-02, -9.6538e-02, -3.2680e-02, -1.5984e-04,\n",
       "            6.0359e-02, -1.7151e-02,  1.8791e-01,  1.0110e-01, -7.9689e-02,\n",
       "           -2.1992e-03,  1.6840e-03, -4.4871e-02, -8.5153e-02,  2.3021e-01,\n",
       "            4.2561e-02,  7.2099e-02, -2.6053e-02, -2.0298e-02,  1.3559e-01,\n",
       "            4.0590e-02,  4.5423e-02,  2.5019e-03, -3.3333e-02, -3.9254e-02,\n",
       "           -5.8896e-02,  1.0476e-01,  9.6809e-03,  3.3319e-02, -1.5614e-02,\n",
       "            1.7665e-01,  2.1785e-02,  3.9360e-02,  2.2189e-02, -5.9185e-03,\n",
       "            7.9865e-02,  3.8202e-02,  5.7548e-02, -3.7505e-03, -3.4617e-02,\n",
       "            3.1034e-02,  1.6224e-02, -1.4721e-02,  6.8730e-02,  4.0288e-02,\n",
       "            5.2194e-02, -1.0341e-04, -1.9954e-02, -1.0999e-01,  4.4567e-03,\n",
       "            3.5402e-02, -3.8626e-02, -8.7090e-02,  4.2419e-02, -4.8703e-02,\n",
       "            4.2493e-03, -1.6542e-02, -2.2381e-02, -4.7405e-02,  4.0856e-02,\n",
       "           -4.7075e-03, -4.6265e-02,  2.3883e-02, -5.0633e-02, -1.9657e-02,\n",
       "           -7.7949e-04, -4.7594e-02,  2.2470e-02,  5.0191e-02, -4.1804e-02,\n",
       "           -2.2123e-02,  1.0680e-02, -2.3486e-04, -9.9047e-03, -1.0047e-01,\n",
       "           -1.9209e-03, -9.0073e-03, -1.9819e-02, -6.3176e-04,  3.7883e-02,\n",
       "           -5.0535e-03,  2.0064e-02,  5.5999e-02,  2.5121e-02,  2.6982e-02,\n",
       "           -5.5803e-02,  1.5763e-02,  4.8260e-03, -1.2731e-01,  1.6306e-02,\n",
       "           -1.6314e-02, -1.2219e-02,  1.4032e-05,  1.0372e-01,  2.1366e-03,\n",
       "           -3.3782e-02,  2.9619e-02,  3.0841e-02, -4.4915e-02, -2.7263e-02,\n",
       "           -1.6058e-02,  4.6835e-02,  8.4414e-03, -5.1485e-02, -7.8484e-02,\n",
       "           -6.1778e-04,  6.6679e-03, -2.8590e-02, -4.7541e-02, -1.2707e-02,\n",
       "            5.8717e-02, -7.7658e-03,  9.1878e-02,  1.0312e-02, -5.3760e-02,\n",
       "           -3.0500e-02,  2.6357e-02,  9.0270e-02, -5.5685e-02,  9.3798e-04,\n",
       "           -7.2392e-02,  8.8333e-03, -4.2072e-02,  3.0412e-02, -4.1428e-01,\n",
       "            9.2471e-04,  5.5386e-03, -2.8869e-02, -2.9265e-02,  4.4496e-02,\n",
       "            7.9897e-02,  2.5940e-02,  3.3296e-02,  1.5161e-02, -2.0935e-02,\n",
       "           -3.4803e-02,  4.0364e-02, -3.2729e-02,  1.2548e-02,  8.7585e-03,\n",
       "            4.4023e-02,  1.2122e-02,  4.5736e-02,  1.4796e-02, -5.2252e-03,\n",
       "           -5.8441e-02,  6.4167e-02, -2.2733e-02, -5.0464e-02,  2.6380e-02,\n",
       "           -9.4677e-03, -7.2154e-02,  3.5425e-02, -8.2056e-02, -5.4921e-02,\n",
       "           -8.2082e-02,  1.2698e-03,  4.0047e-02,  1.2822e-03, -2.3815e-02,\n",
       "           -1.4364e-02, -1.3202e-02,  7.5073e-02,  3.2456e-02,  4.2019e-03,\n",
       "            1.6044e-02,  1.2824e-01, -2.7542e-02,  9.0319e-03,  3.3766e-02,\n",
       "            3.4332e-02, -7.8095e-02,  3.3627e-02, -1.6469e-02, -4.6155e-02,\n",
       "           -3.6163e-02,  1.3133e-02, -1.5534e-02, -4.5005e-02, -4.9289e-02,\n",
       "           -3.5576e-01, -3.4658e-02,  1.2888e-01,  6.4374e-03, -3.3126e-02,\n",
       "            2.2685e-02, -2.0028e-05, -1.9409e-02,  1.2373e-02, -2.1469e-02,\n",
       "           -3.8087e-02, -9.8166e-03, -2.5978e-02, -3.5179e-02, -2.6495e-02,\n",
       "           -6.2637e-03,  4.7609e-02, -2.0573e-02, -2.4477e-03, -4.2092e-03,\n",
       "           -1.0472e-01, -1.5647e-02,  9.2251e-02, -1.9127e-03,  4.2487e-02,\n",
       "           -2.5317e-02, -5.6081e-02,  1.7446e-03,  4.3263e-04,  1.4499e-01,\n",
       "            4.9455e-03, -2.8661e-02,  1.8196e-01,  1.3017e-02, -2.9081e-02,\n",
       "           -5.1819e-02,  5.9448e-02,  7.7459e-03, -1.7039e-02, -4.8472e-02,\n",
       "            7.0563e-02, -1.8576e-02,  2.8677e-03,  1.5958e-02, -2.5783e-02,\n",
       "           -4.0963e-02,  1.0733e-02,  1.3390e-03, -2.0705e-02, -2.5065e-02,\n",
       "            4.3847e-02, -2.3883e-03, -1.9566e-02, -5.5800e-02,  1.1926e-02,\n",
       "           -3.7745e-02,  8.2299e-02, -5.6446e-02,  5.4140e-02, -5.5649e-02,\n",
       "            4.3510e-02, -2.8173e-02, -6.0984e-02,  1.5498e-02,  1.5595e-02,\n",
       "           -3.7527e-02], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([1.3817, 0.4567, 1.1352, 1.2931, 1.1192, 1.0150, 1.1204, 1.2465, 1.2630,\n",
       "           1.2772, 1.2405, 1.3511, 1.0415, 1.4028, 1.3669, 1.3034, 1.2928, 1.2621,\n",
       "           1.3990, 1.2820, 1.6562, 1.2743, 1.3516, 1.2957, 1.1275, 1.2967, 1.3540,\n",
       "           1.4360, 1.5045, 1.2258, 1.4237, 1.2974, 1.3684, 1.3587, 1.4219, 1.2505,\n",
       "           1.3510, 1.4186, 1.9456, 1.3896, 1.1793, 1.3011, 1.3494, 1.3768, 1.4000,\n",
       "           1.3864, 1.3857, 1.3756, 1.4303, 1.4126, 1.4132, 1.3099, 1.3267, 1.3615,\n",
       "           1.3519, 1.3674, 1.2994, 1.3643, 1.3759, 1.4341, 1.3439, 1.3372, 1.4087,\n",
       "           1.3637, 1.3362, 1.3724, 1.5225, 1.3357, 1.3558, 1.4037, 1.3937, 1.4077,\n",
       "           1.3430, 1.3675, 1.5583, 1.4392, 1.3848, 1.4204, 1.3798, 1.4207, 1.3863,\n",
       "           1.3806, 1.4309, 1.3730, 1.8693, 1.3821, 1.3246, 1.3666, 1.3664, 2.0898,\n",
       "           1.5399, 1.4042, 1.4359, 1.3666, 1.4029, 1.3518, 1.3472, 1.4621, 1.3900,\n",
       "           1.3521, 1.5074, 1.6096, 1.3277, 1.4281, 1.4277, 1.5256, 1.4218, 1.3666,\n",
       "           1.4244, 1.3224, 1.3437, 1.5415, 1.3996, 1.3532, 1.3574, 1.4682, 1.3695,\n",
       "           1.3614, 1.2886, 1.3968, 1.2707, 1.4425, 1.3677, 1.5132, 1.4644, 1.4274,\n",
       "           1.3663, 1.3679, 1.6089, 1.3813, 1.3273, 1.3269, 1.4010, 1.4615, 0.8359,\n",
       "           1.3922, 1.3520, 1.3787, 1.3259, 1.4878, 1.8642, 1.4533, 1.6327, 1.4002,\n",
       "           1.3973, 1.3362, 1.5100, 1.4793, 1.3341, 1.3792, 1.3576, 1.3463, 1.5388,\n",
       "           1.3607, 1.4175, 1.4469, 1.6016, 1.3262, 1.3094, 1.3898, 1.4694, 1.3339,\n",
       "           1.6737, 1.3358, 1.6504, 1.3918, 1.5537, 1.3965, 1.3323, 1.3981, 1.4100,\n",
       "           1.3618, 1.2415, 1.4376, 1.4343, 1.6455, 1.6579, 1.3263, 1.3037, 1.3793,\n",
       "           1.4837, 1.3715, 1.3738, 1.4374, 1.3430, 1.4420, 1.3868, 1.3772, 1.3962,\n",
       "           1.3989, 2.3992, 1.3813, 1.2841, 1.3462, 1.3928, 1.5020, 1.5955, 1.4325,\n",
       "           1.3074, 1.4433, 1.3930, 1.3922, 1.5175, 1.4202, 1.4782, 1.3803, 1.4615,\n",
       "           1.3680, 1.3712, 1.5262, 2.8660, 1.4192, 1.2510, 1.5312, 1.4631, 1.4778,\n",
       "           1.3959, 1.4006, 1.3589, 1.1584, 1.3228, 1.4750, 2.7037, 1.4331, 1.4618,\n",
       "           1.3185, 1.4780, 1.5238, 1.4689, 1.4515, 1.3551, 1.2519, 1.5448, 1.4514,\n",
       "           1.7518, 1.4303, 1.3319, 1.5743, 1.5025, 1.2960, 1.3217, 1.3401, 1.4815,\n",
       "           1.3360, 1.4617, 1.5464, 1.3194, 1.5096, 1.6497, 1.7409, 1.1250, 1.5818,\n",
       "           1.4247, 1.2290, 1.4737, 1.4677], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 1.4950e-01, -9.8402e-02,  1.4988e-01,  1.3794e-01,  1.4664e-01,\n",
       "           -1.4424e-01,  9.6659e-02, -4.5200e-02,  4.7170e-03,  2.1916e-02,\n",
       "            6.7111e-02,  3.5526e-01,  8.0614e-02,  9.1310e-02,  3.5977e-02,\n",
       "            5.8482e-02, -4.8932e-02,  4.7598e-02, -1.4486e-02, -1.9275e-03,\n",
       "            1.1218e-01,  3.9006e-01,  1.3169e-02,  2.2769e-01,  6.1969e-02,\n",
       "           -4.0620e-02, -1.0971e-01,  1.0185e-01, -8.1815e-02, -5.0612e-03,\n",
       "           -5.1996e-02,  2.2539e-02, -7.8496e-02,  1.0673e-01,  1.5055e-01,\n",
       "           -1.3875e-02, -5.6240e-02,  6.0228e-02, -5.8109e-01, -2.5891e-02,\n",
       "           -3.6898e-01,  4.0814e-02,  2.4545e-01,  9.2204e-02, -1.7727e-02,\n",
       "            4.1062e-02,  2.3716e-02, -1.3840e-01,  7.2425e-02, -1.9048e-02,\n",
       "           -1.3989e-01,  9.3546e-02, -1.4228e-01, -4.4929e-02, -7.0680e-02,\n",
       "           -2.8408e-02, -1.4381e-01,  9.6827e-02,  7.8219e-02,  4.0874e-02,\n",
       "            1.3908e-01,  1.1214e-01,  8.0736e-02, -2.6236e-02, -5.0392e-02,\n",
       "           -1.3050e-02,  1.3119e-01, -2.3848e-02,  1.0835e-01, -2.1633e-01,\n",
       "           -3.0573e-02,  2.2190e-01,  1.0629e-01,  8.6452e-02,  2.2028e-01,\n",
       "            3.4322e-02, -2.8415e-01, -2.9587e-02, -1.7289e-02,  3.6908e-02,\n",
       "            1.7663e-01, -1.3982e-01,  4.2491e-02, -1.7006e-01,  1.4050e+00,\n",
       "            1.4943e-01,  6.2716e-02,  1.9665e-01,  9.5524e-02, -1.8953e-01,\n",
       "            8.1605e-02, -9.3951e-02, -5.8830e-02, -3.7226e-02,  6.5253e-02,\n",
       "           -8.0276e-02, -1.2029e-03,  5.3973e-02,  7.2058e-02,  2.3921e-02,\n",
       "            1.5681e-01, -2.0941e-01, -9.2056e-02,  6.7635e-02,  2.5781e-01,\n",
       "            5.7187e-02, -1.8658e-01, -1.5348e-01,  1.2690e-01,  1.0473e-01,\n",
       "            1.2815e-01, -2.1277e-01, -1.5921e-01,  1.5501e-01, -2.7055e-01,\n",
       "            3.6408e-02,  2.7086e-01, -7.8935e-02, -5.0899e-02,  1.0717e-01,\n",
       "            8.1164e-02, -1.7124e-01,  7.3811e-02, -5.2692e-02,  2.0105e-01,\n",
       "            1.6520e-01,  1.1363e-01,  4.9978e-02, -6.1099e-02, -1.3754e-01,\n",
       "            2.6514e-01, -1.0772e-01,  1.5319e-01, -5.0679e-03, -1.3049e+00,\n",
       "            3.5595e-03,  9.7186e-02, -2.9034e-02,  2.0370e-01, -8.9717e-02,\n",
       "           -1.5820e+00, -2.8578e-01, -1.1563e-01,  1.5438e-01,  1.8802e-02,\n",
       "            2.0976e-01,  8.4369e-02, -1.1596e-01,  1.0476e-01,  3.2441e-01,\n",
       "           -1.8445e-01,  6.6877e-02,  8.4475e-02, -9.5550e-02,  2.9389e-01,\n",
       "           -7.8326e-05, -1.5580e-01, -2.5934e-01,  2.9751e-01, -3.6735e-03,\n",
       "            7.3355e-02,  2.9378e-01,  3.1230e-01,  4.2066e-02,  2.0429e-01,\n",
       "            1.1957e-01, -1.3124e-01,  8.2878e-02,  1.9976e-01,  8.2461e-02,\n",
       "            1.5806e-01,  6.3748e-02,  1.5378e-01, -6.3705e-02, -2.1522e-01,\n",
       "            1.0521e-01, -7.1071e-02, -2.1987e-03, -2.1068e-01, -5.5762e-02,\n",
       "           -8.4988e-02,  7.4334e-03,  1.0316e-01,  2.6458e-01, -3.5147e-02,\n",
       "            4.9119e-02,  1.1874e-01,  9.9597e-04,  1.4709e-01, -2.3470e-02,\n",
       "           -1.0009e+00, -1.2943e-02,  1.9980e-01, -1.6269e-01,  7.5632e-02,\n",
       "           -1.1603e-01, -1.4340e-01, -1.5823e-01,  9.4348e-02, -3.9023e-02,\n",
       "            6.4072e-02, -2.0075e-02, -2.0704e-01,  1.0333e-01,  3.5316e-02,\n",
       "            7.5809e-02,  1.4733e-01, -5.6869e-02, -4.5553e-03,  1.9166e-01,\n",
       "           -4.6164e-01,  1.1492e-01,  7.9373e-02,  1.0786e-02, -2.0022e-01,\n",
       "            2.1856e-01,  1.7088e-01, -1.7315e-02,  2.1835e-01, -6.2435e-02,\n",
       "            1.5682e-01, -9.1992e-02, -5.0238e-01, -1.5529e-01,  7.7913e-02,\n",
       "            5.2491e-02,  5.3625e-02, -1.7134e-01,  7.2476e-02, -1.6096e-01,\n",
       "           -2.3411e-01, -2.4164e-01,  1.5438e-01,  1.0954e-01, -6.3782e-02,\n",
       "            1.0504e-02,  5.6444e-02,  9.8260e-02,  4.2838e-02,  2.8891e-02,\n",
       "            5.8772e-02, -9.5841e-02,  1.1602e-01,  3.0119e-01, -8.8834e-04,\n",
       "            1.6140e-01,  5.7643e-03, -2.8984e-02, -3.2448e-02,  2.5413e-01,\n",
       "           -2.5374e-01, -7.2773e-02,  8.6532e-02, -1.0708e-01,  1.4300e-01,\n",
       "            1.6037e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([1.0355, 0.7905, 0.8378, 0.9015, 0.8256, 0.8520, 0.8390, 0.8916, 0.9165,\n",
       "           0.9282, 0.9084, 0.9470, 1.0663, 1.0201, 1.0475, 0.9651, 0.9948, 0.9349,\n",
       "           1.0251, 0.9222, 1.5696, 0.9677, 1.0093, 0.9617, 0.9593, 0.8899, 1.0000,\n",
       "           0.9479, 1.1330, 0.9593, 0.9592, 1.0183, 0.9708, 0.9889, 0.9394, 0.9046,\n",
       "           0.8531, 1.0476, 2.0240, 1.0187, 0.9512, 0.9821, 1.0194, 0.9723, 0.9591,\n",
       "           1.0387, 0.9563, 1.0535, 1.0651, 1.0408, 0.9796, 0.9711, 0.9501, 0.9208,\n",
       "           1.0194, 0.9324, 0.9630, 0.9372, 1.0090, 0.9818, 0.9552, 0.9307, 0.9832,\n",
       "           0.9683, 0.9029, 0.9846, 0.9436, 0.9319, 0.9656, 1.0013, 1.0301, 1.0493,\n",
       "           0.9058, 1.0383, 1.2668, 1.0120, 0.9057, 1.0940, 1.0136, 1.0310, 1.0214,\n",
       "           1.1182, 0.9524, 0.9628, 2.3473, 0.9668, 0.9152, 0.9219, 0.9525, 2.0943,\n",
       "           1.1415, 0.9832, 0.9609, 0.9572, 1.0733, 0.9252, 0.9997, 0.9592, 1.0018,\n",
       "           0.9760, 1.1722, 1.2569, 1.0117, 0.9826, 1.0335, 1.0840, 1.0291, 0.9237,\n",
       "           1.0361, 1.0337, 1.0172, 1.0784, 0.8920, 0.9248, 1.0262, 1.0999, 1.0139,\n",
       "           0.9853, 0.9537, 1.0116, 0.8715, 1.1306, 0.9060, 0.9401, 1.0830, 1.1022,\n",
       "           0.9691, 0.9774, 1.2595, 0.9214, 1.0057, 1.0050, 0.9424, 1.0088, 2.1871,\n",
       "           1.0047, 0.9593, 0.9516, 0.9711, 1.0945, 2.4664, 1.0205, 1.2810, 1.0309,\n",
       "           0.8364, 0.9185, 0.9620, 0.9846, 1.0477, 1.0270, 0.9403, 0.9118, 0.9592,\n",
       "           1.0076, 1.0303, 0.9825, 1.1804, 1.0771, 0.9593, 0.9424, 1.0867, 0.9851,\n",
       "           1.1747, 0.9340, 1.2977, 0.9428, 1.4022, 1.0617, 1.0194, 1.0942, 0.9459,\n",
       "           1.0200, 0.9758, 1.0619, 0.9498, 1.2728, 1.3421, 0.9078, 0.9363, 1.0521,\n",
       "           1.0223, 0.9732, 0.9967, 0.9886, 1.0031, 0.9834, 1.0655, 1.0091, 1.0335,\n",
       "           0.9049, 2.6991, 1.0327, 0.9543, 0.8886, 0.9719, 0.9491, 1.2590, 1.0162,\n",
       "           0.9928, 1.1182, 0.9763, 1.0542, 1.2032, 1.0113, 1.1152, 0.9917, 1.1604,\n",
       "           0.9149, 0.9520, 1.1332, 2.7596, 1.0202, 0.9952, 1.1081, 1.1365, 1.0979,\n",
       "           0.9936, 1.1026, 1.0029, 0.9050, 1.0052, 1.0045, 2.6638, 0.9741, 1.1976,\n",
       "           0.9554, 1.0531, 1.0631, 1.1553, 1.0659, 0.9483, 0.9326, 1.0344, 0.9843,\n",
       "           1.6646, 1.0165, 0.9042, 1.0694, 1.3107, 0.9479, 1.0183, 0.9617, 1.0965,\n",
       "           0.9662, 1.0185, 1.0910, 1.0057, 0.9856, 1.3753, 1.6121, 0.9339, 1.1247,\n",
       "           1.0163, 1.0080, 1.0567, 1.1127], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 9.5382e-03, -4.1205e-01, -3.2838e-02,  3.8946e-01,  1.4744e-01,\n",
       "            6.2222e-02, -1.6107e-01,  2.2182e-01, -1.1017e-01, -1.2992e-01,\n",
       "            1.6971e-02,  1.8966e-01,  5.6163e-01,  2.5865e-01,  1.8858e-01,\n",
       "            2.0169e-01, -3.1391e-02,  2.1525e-01, -2.0432e-01, -3.0596e-01,\n",
       "            4.4132e-01,  3.9007e-01, -1.8110e-01,  2.1430e-01, -1.8358e-03,\n",
       "            1.1703e-01, -2.3922e-01,  2.7674e-01, -2.0765e-01,  8.0039e-02,\n",
       "           -2.6356e-01,  3.7017e-02,  6.9315e-02,  1.8347e-01,  3.0466e-01,\n",
       "           -1.6166e-01, -1.6927e-01, -1.4132e-01, -1.2933e+00, -2.3745e-01,\n",
       "           -5.0277e-01, -1.2598e-02,  2.4352e-01,  1.8450e-01,  1.8221e-01,\n",
       "           -5.9965e-02,  3.1109e-02, -1.0800e-01,  4.1374e-01,  4.4594e-02,\n",
       "           -2.7172e-01, -2.3529e-01,  3.8357e-01, -3.6224e-01, -3.4189e-01,\n",
       "           -3.6391e-01,  1.9418e-01,  1.3617e-01, -1.3964e-01, -1.6188e-01,\n",
       "            3.1933e-01,  1.5945e-01,  2.4463e-01, -1.7123e-01, -2.4314e-02,\n",
       "            1.1577e-01, -2.8542e-01,  1.5991e-01, -4.1710e-02, -1.7695e-01,\n",
       "           -1.8416e-01,  2.2241e-01, -3.1965e-02, -1.8759e-02,  5.5540e-01,\n",
       "           -1.6994e-01, -4.3142e-01,  4.7420e-02, -2.0441e-01,  3.3113e-01,\n",
       "            4.1277e-02, -4.1235e-02,  1.0216e-01,  3.0223e-01,  1.7844e+00,\n",
       "           -8.5458e-02, -4.1518e-01,  1.5637e-01, -8.2121e-02, -6.9682e-02,\n",
       "            2.3189e-01, -3.5519e-01, -2.1073e-01, -2.5544e-01, -2.3850e-01,\n",
       "           -4.8677e-01, -6.1627e-02, -6.4397e-02,  2.7380e-01, -1.8089e-02,\n",
       "            2.7881e-01, -1.2844e-01,  1.3426e-01,  1.3460e-01,  1.1209e-01,\n",
       "            1.5408e-01,  2.9172e-02, -3.4753e-01,  2.5159e-01,  2.4576e-01,\n",
       "           -2.9035e-02, -3.2412e-01, -1.4715e-01,  3.2809e-01, -2.0371e-01,\n",
       "            3.7805e-02,  1.7539e-01, -2.1535e-02,  1.6999e-01,  1.7667e-01,\n",
       "           -4.2380e-01,  8.6454e-02,  2.0194e-01, -3.9286e-01,  2.3180e-01,\n",
       "            1.2602e-01,  2.7142e-01,  1.5203e-02, -2.9903e-01,  1.9597e-02,\n",
       "            2.2649e-01,  1.6549e-01, -1.2472e-01, -1.9313e-02, -1.7185e+00,\n",
       "           -1.7963e-01,  4.5689e-02, -1.9293e-01,  9.5957e-02, -1.7215e-02,\n",
       "           -1.8936e+00, -2.0331e-01, -1.8564e-01, -3.3900e-01, -8.2258e-02,\n",
       "            9.9611e-02,  3.0374e-01, -2.0102e-01,  8.5514e-02,  2.5590e-01,\n",
       "           -1.0803e-01,  2.1347e-02, -4.2860e-01, -3.0184e-01,  1.7496e-01,\n",
       "           -2.4779e-01, -5.7268e-01, -1.7128e-01,  2.4856e-01,  2.3400e-01,\n",
       "            2.5423e-02,  1.3540e-01,  6.2737e-01,  6.5274e-02,  5.5543e-01,\n",
       "           -3.7458e-01,  3.2415e-03,  4.3722e-02, -1.7576e-01,  1.6095e-01,\n",
       "            2.0671e-01, -6.9907e-02, -1.6939e-01, -3.2604e-01, -2.1489e-01,\n",
       "            3.9190e-01, -3.5298e-01,  1.6504e-01, -2.1889e-01, -2.8210e-01,\n",
       "            1.6816e-01, -1.6849e-01, -8.1778e-02,  2.5648e-01, -1.7436e-03,\n",
       "            1.0639e-02,  3.1525e-01, -1.4036e-01,  1.0694e-01,  4.6478e-01,\n",
       "           -1.7332e+00,  3.7489e-02,  2.3149e-01,  1.5302e-01,  5.6758e-01,\n",
       "           -2.3535e-01, -1.3301e-01, -2.2321e-03, -9.6236e-02, -3.5823e-01,\n",
       "            3.2747e-02,  1.1233e-01, -4.2573e-01,  4.0420e-01,  2.6304e-01,\n",
       "            2.0183e-01, -2.9515e-01, -3.2089e-01, -2.3824e-01,  5.7493e-01,\n",
       "           -9.7340e-01, -3.2234e-01,  1.9186e-01, -8.7145e-02, -3.3986e-01,\n",
       "            2.6434e-01,  1.4928e-01,  1.0728e-01,  2.4209e-01,  2.7934e-01,\n",
       "            1.9112e-01,  1.5904e-02, -3.7756e-01,  9.6129e-02,  1.6655e-01,\n",
       "            1.2224e-01, -2.9553e-01, -2.0896e-01,  2.7512e-02, -1.3141e-01,\n",
       "           -1.8465e-01,  1.0953e-01,  3.7321e-01, -1.7090e-01, -6.0326e-01,\n",
       "            4.1510e-02,  5.4113e-02,  3.4505e-01,  5.5004e-03, -1.4203e-01,\n",
       "            8.8049e-02, -2.3041e-01, -2.5118e-03,  1.4367e-01,  2.0920e-01,\n",
       "            1.7582e-01, -1.6438e-01, -2.6730e-01,  3.8835e-01,  7.0281e-01,\n",
       "           -8.8498e-02, -1.8145e-01,  6.6364e-02, -4.8997e-01,  1.7313e-01,\n",
       "            5.5111e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([0.5887, 0.3725, 0.5666, 0.5782, 0.4677, 0.5242, 0.4643, 0.5649, 0.6012,\n",
       "           0.5780, 0.6471, 0.5389, 0.4236, 0.5804, 0.5727, 0.5944, 0.5877, 0.5722,\n",
       "           0.5348, 0.6136, 0.3924, 0.5945, 0.5909, 0.5423, 0.5355, 0.6354, 0.5570,\n",
       "           0.6584, 0.5028, 0.5517, 0.5804, 0.5551, 0.6024, 0.6204, 0.5584, 0.6138,\n",
       "           0.6190, 0.5370, 0.4023, 0.5894, 0.4537, 0.6722, 0.5951, 0.5913, 0.5812,\n",
       "           0.5618, 0.6458, 0.5907, 0.4901, 0.5912, 0.5597, 0.6446, 0.6524, 0.5726,\n",
       "           0.5787, 0.5932, 0.5744, 0.6689, 0.5518, 0.5962, 0.5744, 0.5629, 0.5702,\n",
       "           0.5579, 0.7017, 0.6247, 0.6143, 0.5781, 0.5926, 0.6034, 0.6309, 0.5458,\n",
       "           0.6520, 0.6304, 0.4419, 0.6246, 0.5644, 0.6101, 0.5643, 0.5130, 0.6151,\n",
       "           0.6060, 0.6049, 0.6230, 0.1992, 0.6245, 0.4987, 0.6164, 0.6590, 0.2043,\n",
       "           0.4865, 0.5339, 0.6649, 0.5560, 0.5538, 0.5076, 0.6728, 0.6028, 0.5439,\n",
       "           0.6610, 0.5413, 0.4354, 0.6502, 0.6153, 0.5679, 0.5976, 0.5875, 0.6812,\n",
       "           0.5746, 0.5444, 0.6527, 0.5458, 0.6179, 0.5281, 0.6167, 0.5622, 0.6238,\n",
       "           0.6399, 0.7072, 0.5774, 0.5133, 0.5405, 0.6021, 0.5287, 0.6039, 0.5772,\n",
       "           0.5834, 0.6014, 0.4921, 0.5417, 0.6088, 0.6417, 0.6060, 0.6332, 0.1742,\n",
       "           0.6129, 0.6464, 0.6155, 0.6060, 0.5765, 0.1292, 0.5946, 0.4263, 0.5910,\n",
       "           0.6257, 0.6038, 0.5527, 0.5615, 0.6769, 0.6228, 0.6402, 0.6011, 0.5347,\n",
       "           0.5859, 0.5959, 0.6771, 0.4709, 0.5731, 0.6132, 0.6462, 0.5804, 0.5434,\n",
       "           0.5071, 0.6374, 0.4238, 0.4812, 0.4737, 0.6110, 0.6739, 0.5901, 0.6559,\n",
       "           0.6697, 0.5982, 0.5622, 0.6390, 0.4482, 0.4355, 0.5935, 0.6136, 0.6415,\n",
       "           0.5403, 0.6323, 0.6496, 0.6131, 0.5692, 0.6562, 0.6251, 0.6601, 0.6651,\n",
       "           0.5614, 0.2613, 0.6429, 0.5858, 0.5971, 0.5351, 0.5845, 0.4464, 0.5672,\n",
       "           0.5664, 0.5690, 0.6247, 0.6702, 0.4242, 0.6036, 0.5806, 0.6202, 0.5613,\n",
       "           0.5877, 0.6444, 0.4634, 0.1550, 0.6143, 0.5847, 0.5172, 0.5294, 0.5344,\n",
       "           0.5987, 0.5814, 0.6025, 0.5333, 0.6334, 0.6230, 0.1889, 0.6226, 0.5068,\n",
       "           0.6666, 0.5291, 0.5417, 0.5798, 0.5834, 0.6279, 0.6121, 0.5798, 0.6002,\n",
       "           0.4421, 0.5861, 0.6661, 0.5320, 0.4745, 0.6003, 0.6000, 0.6093, 0.5923,\n",
       "           0.5573, 0.5746, 0.5477, 0.5818, 0.6021, 0.4361, 0.3276, 0.4763, 0.5709,\n",
       "           0.6041, 0.5333, 0.5728, 0.4802], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-7.8450e-02,  4.3069e-02, -2.6423e-02, -1.4422e-01, -5.4534e-02,\n",
       "           -3.5002e-02, -3.5204e-02, -7.4677e-02,  1.3654e-02, -1.0787e-02,\n",
       "           -1.3236e-01, -3.9808e-02, -1.4104e-01, -7.4068e-02, -7.1785e-02,\n",
       "           -1.2148e-02, -2.0678e-02, -7.9474e-02,  2.2276e-02, -5.4357e-03,\n",
       "           -5.8138e-02, -1.2145e-01, -5.4591e-02, -1.0371e-01, -1.6610e-03,\n",
       "           -6.8239e-02,  3.3095e-02, -1.0937e-01, -1.7018e-02, -4.1574e-02,\n",
       "            7.2155e-02, -9.2078e-02, -3.0115e-02, -9.5556e-02, -1.0116e-01,\n",
       "           -1.5496e-02,  2.2613e-02, -1.2701e-02,  1.6578e-01, -1.5668e-02,\n",
       "            1.4858e-01, -2.3018e-02, -1.0568e-01, -6.8585e-02, -6.5903e-02,\n",
       "            1.0898e-02,  1.0456e-03, -4.5094e-03, -8.3185e-02, -1.0438e-01,\n",
       "            4.0943e-02, -4.9420e-02, -8.0787e-02,  2.1665e-02,  5.4280e-02,\n",
       "            5.4283e-03, -1.2121e-02, -4.5656e-02, -5.5843e-02, -4.2677e-02,\n",
       "           -5.9526e-02, -1.0781e-01, -1.1726e-01, -1.3635e-02, -3.4136e-02,\n",
       "           -2.4358e-02, -4.4579e-02, -1.1908e-01,  2.3107e-02, -2.4227e-03,\n",
       "            2.1276e-02, -2.2855e-01, -1.8773e-02, -1.0258e-01, -1.5918e-01,\n",
       "           -1.1513e-02,  8.6181e-02, -6.9982e-02,  3.3232e-02, -1.5591e-01,\n",
       "           -2.4020e-03,  1.1489e-02, -9.0815e-03, -9.9614e-02, -4.2577e-01,\n",
       "           -7.4873e-02,  5.1779e-02, -1.1309e-01, -2.2713e-02, -1.1452e-02,\n",
       "           -5.9053e-02,  8.5984e-03,  5.6076e-02,  2.2347e-02,  3.1328e-02,\n",
       "           -1.7128e-02, -3.0228e-02, -6.8426e-02, -8.6711e-02, -4.8355e-02,\n",
       "           -8.9249e-02, -6.6675e-02,  1.1136e-02, -5.1855e-02, -3.4139e-02,\n",
       "           -1.0430e-01,  5.1525e-02,  8.1698e-02, -1.1163e-01, -3.7729e-02,\n",
       "           -8.4197e-02,  2.8958e-04,  7.0619e-02, -1.1912e-01,  2.2549e-02,\n",
       "           -7.2838e-02, -4.9370e-02, -6.9666e-02, -3.9546e-02, -8.4471e-02,\n",
       "            6.2952e-02, -9.5478e-02, -1.5220e-02, -9.1464e-03, -6.7360e-02,\n",
       "           -9.8610e-02, -5.7035e-02, -5.6806e-02, -3.1931e-02, -6.6259e-02,\n",
       "           -1.4420e-01, -8.1929e-03, -3.5871e-02,  3.5064e-02,  3.1748e-01,\n",
       "           -5.2782e-02,  4.4397e-03, -2.2753e-02, -8.9944e-02,  7.2484e-03,\n",
       "            6.7385e-01, -1.4386e-03, -8.0303e-02, -1.9878e-02, -2.1469e-02,\n",
       "           -1.0061e-01, -3.7061e-02, -4.4905e-02,  1.9145e-03, -1.4478e-01,\n",
       "            4.9870e-02, -3.2720e-02,  4.2820e-02,  2.9061e-02, -1.2453e-02,\n",
       "           -2.8506e-02,  9.2164e-02,  9.7813e-03, -1.0079e-01, -7.7509e-02,\n",
       "           -5.3491e-03, -1.1705e-01, -1.0887e-01, -7.4441e-02, -1.4795e-01,\n",
       "            8.1472e-03,  3.1874e-02, -6.6766e-02,  2.6420e-02, -8.0609e-02,\n",
       "           -8.9084e-02, -4.2326e-02,  3.2340e-02,  2.6647e-02, -2.1115e-02,\n",
       "           -9.3695e-02,  1.9974e-01, -6.1039e-02,  3.6842e-02,  5.7815e-02,\n",
       "           -1.4706e-02, -2.3790e-02, -3.7623e-02, -6.1088e-02, -6.5961e-02,\n",
       "           -6.3246e-02, -9.8961e-02,  1.5849e-02, -4.8502e-02, -1.2495e-01,\n",
       "           -1.8860e-01,  5.5148e-03, -3.2637e-02, -7.4406e-02, -1.2902e-01,\n",
       "            1.2341e-02, -3.7353e-02, -4.5644e-02,  2.2642e-02, -1.6029e-03,\n",
       "           -2.8782e-02, -5.1579e-02,  9.0297e-02, -1.1003e-01,  6.4500e-03,\n",
       "           -6.4023e-02,  6.7118e-02, -1.2533e-02,  1.8841e-02, -1.6918e-01,\n",
       "           -1.1753e-01, -4.5523e-02, -1.8840e-02, -4.4103e-02,  3.9222e-02,\n",
       "           -1.4622e-01, -5.7881e-02, -4.4306e-02, -9.1644e-02, -1.0257e-01,\n",
       "           -1.2719e-01, -7.5947e-02,  7.2178e-01, -4.1231e-04, -2.5702e-02,\n",
       "           -9.5122e-02,  9.3556e-02,  2.4904e-02, -4.3801e-02, -7.4300e-02,\n",
       "            6.5060e-02, -4.3308e-02, -1.0233e-01, -6.1255e-02,  3.7237e-02,\n",
       "           -3.8012e-02, -1.1311e-02, -7.1141e-02,  1.0126e-01, -2.9905e-02,\n",
       "           -1.9250e-02, -3.5612e-02,  9.6598e-03, -9.2547e-02, -5.9392e-02,\n",
       "           -7.0487e-02,  7.9781e-02, -3.5813e-02, -4.9247e-02, -1.6924e-01,\n",
       "           -2.1228e-02, -8.0615e-03, -6.4669e-02,  8.0112e-02, -5.5841e-02,\n",
       "           -1.4932e-01], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.2639,  0.0187,  0.3347,  ..., -0.3927,  0.1541, -0.2304],\n",
       "           [ 0.1368,  0.0328, -0.0361,  ..., -0.2979,  0.2294,  0.0264],\n",
       "           [-0.2308,  0.2196,  0.1566,  ..., -0.3390,  0.0272, -0.0478],\n",
       "           ...,\n",
       "           [ 0.3397, -0.2665,  0.2308,  ..., -0.0815, -0.0117,  0.0784],\n",
       "           [-0.0216, -0.4559, -0.0472,  ...,  0.1844,  0.3039, -0.0388],\n",
       "           [-0.3538,  0.0646,  0.0337,  ..., -0.0351, -0.0101, -0.2164]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.2826,  0.1023,  0.1605, -0.2337,  0.3009,  0.3282,  0.6447, -0.4800,\n",
       "           -0.0896, -0.3130, -1.1327,  1.0216, -1.9266,  0.1283,  0.1597, -0.3722,\n",
       "            0.5180, -0.9636,  0.0873,  0.2219,  0.3390,  0.7355, -0.2384, -0.0829,\n",
       "           -0.3083,  0.6466,  0.1520,  0.0256, -0.3314, -0.2981, -0.0299, -0.8302,\n",
       "            0.8633, -1.0149, -0.6809,  0.7061,  0.2658,  0.6403, -0.0154,  0.6313,\n",
       "            0.9583,  0.5694, -0.7050, -1.1070, -0.6850, -0.7499, -0.5239, -0.4876,\n",
       "           -1.8689, -0.1715,  0.3910, -0.6038,  0.8397,  0.1470,  0.7100, -0.0091,\n",
       "            0.5738,  0.4822, -0.1475,  0.4758,  0.1622,  0.7013,  0.2819,  0.3519,\n",
       "            0.0611,  0.2916,  0.8657, -0.3522,  0.7144,  0.1977,  1.6146, -1.2116,\n",
       "            0.4791, -0.7294, -0.2169,  0.0239,  0.7026,  0.1760,  0.0998, -0.2806,\n",
       "            0.4329,  0.2888, -0.1523,  1.1434,  0.2627, -0.9415,  0.7568,  1.0295,\n",
       "            0.0844,  0.8987,  0.3851, -0.1078, -0.0612, -0.6748, -0.0432, -0.3752,\n",
       "           -0.4783,  0.2983, -0.3970,  0.8325, -0.0645,  0.7397,  0.2696,  0.9814,\n",
       "            0.6622,  0.5073, -0.1543,  0.3886, -0.9611, -1.3164,  0.8497, -1.0280,\n",
       "            0.4811, -0.5828, -0.4631, -0.7839, -0.1023,  1.2476, -0.8123, -0.5242,\n",
       "            0.0232,  0.0174, -0.1645, -0.4369,  0.4210, -0.5630, -0.1950, -0.1305,\n",
       "            0.6472,  0.3814,  0.7622, -0.3503, -0.5594, -0.7244,  0.3129, -1.0989,\n",
       "            0.5447,  0.6388,  0.3298, -0.2452,  0.1214,  0.6243,  0.0912,  0.0037,\n",
       "            0.4714,  0.0415, -0.1690, -0.5787,  0.5856, -0.6660, -0.7043, -0.3091,\n",
       "           -0.4030,  0.5415,  0.0981, -0.0880, -0.5140,  0.8588,  1.0026, -0.8888,\n",
       "           -0.2704,  0.7268, -0.5908,  0.0219,  1.0621,  0.3022, -0.2598, -0.4402,\n",
       "           -0.2508, -0.3213, -0.3713,  0.0064,  0.2276,  1.0269, -0.3261,  0.0045,\n",
       "           -0.2173,  0.5219,  0.4349, -0.0467, -1.1012, -0.8630, -0.1898, -0.2075,\n",
       "            0.4076, -0.4157, -1.5513,  0.1949,  0.6172, -0.7915, -1.0226, -1.4829,\n",
       "            0.4604, -0.5586, -0.4611, -0.9163, -2.2063,  1.3731,  0.0423,  0.6902,\n",
       "            0.2863,  0.1470,  0.8240, -0.3514, -0.2246,  0.4264, -0.1954,  0.3178,\n",
       "            0.1476, -0.5447,  0.3719, -0.7206, -0.2750,  0.1484,  0.1456,  0.6233,\n",
       "           -0.8687, -0.3469,  0.6388,  0.5901,  0.1665, -0.9394, -0.1086,  0.0476,\n",
       "            0.8652, -0.7380, -0.8645, -0.1781,  0.5451, -0.1746, -0.3752,  0.5989,\n",
       "            0.3287, -0.7230, -0.6114, -0.0072,  1.2985, -0.2610,  0.5213,  1.0266,\n",
       "            1.1279, -0.5227, -0.7021, -0.7469, -0.5032,  0.1773,  0.8446,  0.6513,\n",
       "            0.2163, -0.1892, -0.9686, -0.5755, -0.8887,  0.5075,  1.0708, -0.2709],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.3310,  0.0532,  0.3456,  ...,  0.1788, -0.2047, -0.0147],\n",
       "           [-0.0788, -0.0076, -0.1821,  ..., -0.1984,  0.1430, -0.0637],\n",
       "           [ 0.3356, -0.3026,  0.0693,  ..., -0.0995, -0.1508, -0.0359],\n",
       "           ...,\n",
       "           [ 0.1032,  0.5126,  0.3741,  ..., -0.1944, -0.0359, -0.1099],\n",
       "           [ 0.0243,  1.1293,  0.2802,  ..., -0.0534,  0.1700,  0.1533],\n",
       "           [-0.0618, -0.0214, -0.4047,  ..., -0.3771, -0.2001,  0.2291]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-2.3608e-03, -1.7743e-03,  1.9229e-03,  4.7186e-03,  2.8401e-03,\n",
       "           -2.7810e-03, -3.6267e-05,  7.1188e-04,  2.9089e-03,  1.2811e-04,\n",
       "            2.9963e-03, -4.2577e-03,  7.8369e-03,  1.3905e-03,  3.7838e-03,\n",
       "            1.1541e-03, -7.2066e-04,  1.8932e-03,  2.3019e-03, -2.8995e-03,\n",
       "           -1.3596e-03, -1.7629e-03,  9.7217e-04,  3.8184e-03, -5.5193e-03,\n",
       "           -1.8059e-03, -2.7794e-03,  1.1469e-03,  1.7488e-03, -1.9315e-03,\n",
       "            8.4402e-03,  9.2950e-03, -4.3631e-04, -8.2873e-04, -2.0044e-03,\n",
       "           -2.9701e-03,  6.5442e-04,  6.4296e-03,  1.1990e-03, -3.4208e-04,\n",
       "            4.6774e-03, -1.1168e-03, -1.6760e-03,  2.7076e-03,  7.9646e-04,\n",
       "            7.2368e-03,  8.9111e-04, -1.3038e-04, -1.4656e-03, -5.2413e-04,\n",
       "            4.4679e-03, -1.2276e-03, -4.0929e-04, -2.4646e-04, -1.5480e-03,\n",
       "           -5.7367e-04, -5.8703e-04, -2.4509e-03, -3.1891e-03, -2.3283e-03,\n",
       "           -8.6300e-04,  1.4800e-03,  8.1449e-04,  5.8702e-03, -1.7209e-03,\n",
       "            1.5952e-04, -8.0790e-04,  7.3294e-04,  4.4010e-04, -1.0503e-05,\n",
       "           -1.6982e-04,  2.0096e-03, -3.1410e-04, -5.9751e-05,  8.8547e-04,\n",
       "           -2.7967e-03,  9.8877e-04,  2.7094e-04, -1.1087e-03, -4.1788e-06,\n",
       "            1.4588e-03, -1.3915e-03, -1.2818e-03, -3.2872e-03,  1.3779e-03,\n",
       "            1.1656e-03, -4.8963e-04, -6.3054e-03, -1.1425e-03, -1.3934e-03,\n",
       "            4.8133e-04,  2.6131e-04,  2.5088e-03,  9.6694e-04,  1.2354e-04,\n",
       "            1.0461e-03,  3.9086e-04, -1.0383e-04, -3.9798e-03,  2.1291e-03,\n",
       "            1.8090e-03,  2.3951e-03, -2.9052e-04, -2.4143e-04,  1.2179e-03,\n",
       "            2.2261e-03,  1.5420e-03,  1.4987e-03, -1.2359e-03, -5.9901e-04,\n",
       "           -1.0060e-03,  2.1419e-04,  7.3880e-04, -7.1012e-04, -1.2975e-03,\n",
       "            7.2303e-04,  2.1331e-03,  1.6462e-03, -1.6189e-03, -3.2194e-03,\n",
       "           -6.2742e-04,  6.5153e-04,  1.2425e-03,  1.1226e-03,  2.3721e-06,\n",
       "            3.3892e-04,  2.1816e-03,  6.1969e-04,  3.6883e-03,  8.0799e-05,\n",
       "            3.4020e-03, -7.1202e-04, -4.0570e-04, -6.3930e-04,  2.9288e-03,\n",
       "           -5.5728e-03,  3.0527e-03,  3.2826e-03, -1.9860e-03, -1.1040e-03,\n",
       "            2.7941e-03,  2.0789e-03, -1.4815e-03,  7.1575e-04,  5.7588e-04,\n",
       "           -1.7544e-04, -3.2429e-04, -1.7358e-03,  3.2004e-03, -3.1221e-03,\n",
       "           -2.2253e-03, -1.4720e-03, -1.3729e-03,  3.3695e-03,  5.3954e-04,\n",
       "            2.1352e-03, -2.3795e-03,  6.0166e-03,  2.9714e-03, -5.8166e-03,\n",
       "           -1.4597e-03,  9.5366e-04,  1.3543e-03, -5.0453e-04, -1.1356e-03,\n",
       "           -4.1075e-04,  6.3805e-04, -1.5796e-03,  2.9195e-03, -1.6447e-03,\n",
       "           -1.2000e-03,  2.0065e-03,  4.6434e-03, -1.2002e-03,  5.8285e-04,\n",
       "           -1.4059e-03,  2.1927e-03, -6.6712e-04,  1.6803e-03,  1.9019e-03,\n",
       "            3.5197e-04,  4.1503e-03,  1.9868e-03, -4.0431e-03, -2.9270e-03,\n",
       "            1.0045e-03,  6.1986e-03,  5.3874e-04,  1.4401e-03, -7.7994e-04,\n",
       "            1.0336e-03, -2.6498e-03, -2.5203e-03, -4.2042e-04,  1.5783e-03,\n",
       "            1.7493e-03,  1.5282e-03, -8.5331e-04,  8.5263e-04, -4.0199e-03,\n",
       "            5.3752e-04, -2.7542e-03, -1.8751e-03, -7.4001e-04,  1.7096e-03,\n",
       "            2.7352e-03,  2.4616e-04, -2.0379e-03,  4.4623e-03,  3.3391e-03,\n",
       "            1.7891e-03,  3.4087e-03,  2.4555e-03,  1.7993e-03,  5.7911e-03,\n",
       "            3.0320e-03,  1.8861e-03, -4.6489e-03,  3.1456e-03,  3.3559e-03,\n",
       "            1.5697e-03,  1.0796e-03, -2.3691e-03,  1.1178e-03,  4.3686e-04,\n",
       "           -1.8548e-03, -8.0708e-04, -6.2282e-04,  2.0224e-04, -1.0637e-03,\n",
       "            1.1445e-03, -2.5854e-04,  1.5092e-03, -1.0006e-03,  1.8968e-03,\n",
       "           -1.4580e-03, -5.0161e-03, -2.5084e-05,  8.0048e-05,  1.7820e-03,\n",
       "            4.1364e-03,  8.5739e-04, -1.5817e-03, -1.0684e-04,  2.0283e-03,\n",
       "            1.4264e-03,  2.1394e-03,  2.0615e-04,  6.8304e-04,  6.3504e-04,\n",
       "            2.9885e-03,  2.0333e-03, -1.9278e-03,  3.9308e-04,  6.2097e-04,\n",
       "            6.1802e-04], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 1.6667e-01,  9.4874e-03,  1.2382e-01,  ...,  1.6067e-01,\n",
       "            -9.7074e-02, -2.2997e-01],\n",
       "           [-8.9529e-02,  4.1885e-02,  2.8162e-01,  ..., -8.4348e-02,\n",
       "             2.6894e-01, -1.9187e-01],\n",
       "           [ 6.0976e-02, -8.5751e-02,  2.4037e-02,  ..., -2.4909e-02,\n",
       "             2.0289e-02,  6.7808e-02],\n",
       "           ...,\n",
       "           [ 4.3149e-02,  4.8592e-02,  4.4326e-02,  ...,  1.1353e-01,\n",
       "            -7.4460e-02,  1.3884e-02],\n",
       "           [ 6.3217e-02, -2.0929e-02,  2.6474e-01,  ..., -3.6431e-03,\n",
       "             2.9216e-02,  3.0274e-01],\n",
       "           [ 3.8662e-01, -2.3032e-04,  2.1287e-01,  ..., -3.5508e-01,\n",
       "            -1.8331e-01, -5.1517e-02]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 4.7465e-03, -8.8325e-04, -8.3938e-03, -6.5910e-03, -4.9087e-03,\n",
       "           -1.8665e-04, -5.9160e-03, -2.7105e-03,  6.0163e-03,  4.8389e-03,\n",
       "            7.9077e-03,  6.2263e-03, -5.9625e-03,  1.6186e-03, -3.1952e-03,\n",
       "            1.3777e-02,  5.6687e-03,  3.5889e-03, -9.7292e-03,  4.3237e-03,\n",
       "            1.4147e-02, -1.2146e-02, -1.0312e-02,  5.3683e-03,  2.1988e-03,\n",
       "            7.6168e-03,  1.9535e-03,  3.5340e-03,  7.3104e-03,  5.4005e-03,\n",
       "           -8.5236e-03,  7.1774e-03, -1.5420e-03,  1.0680e-02, -1.2755e-03,\n",
       "            6.5496e-03, -3.0816e-03,  1.6993e-02,  4.8645e-03,  1.9333e-04,\n",
       "            3.1230e-03, -3.5150e-03, -2.8523e-03,  8.2472e-03,  1.0876e-03,\n",
       "           -4.5778e-03, -7.9986e-03,  6.4793e-04, -1.1593e-02, -2.0890e-03,\n",
       "           -3.1099e-03,  2.8932e-03, -9.7089e-04,  1.1285e-04,  2.2072e-03,\n",
       "           -8.1205e-03, -1.4224e-03,  3.3830e-03,  1.1236e-02, -4.0654e-03,\n",
       "           -8.2928e-04, -9.1168e-03, -1.9534e-03, -1.6187e-03,  8.9237e-03,\n",
       "            1.4854e-03,  3.8834e-03, -1.7482e-03,  3.3838e-03,  3.4936e-03,\n",
       "           -3.1996e-03,  1.5314e-03, -3.9581e-04, -2.9983e-03,  5.5060e-03,\n",
       "            4.8635e-03,  2.6038e-04, -4.7460e-03,  3.4793e-03,  1.2924e-02,\n",
       "           -4.0357e-03, -1.6252e-03, -2.5359e-03,  4.3294e-03, -5.6172e-03,\n",
       "            9.6621e-03, -1.2652e-03, -9.4297e-05, -6.8079e-03,  4.4180e-04,\n",
       "           -7.0237e-04,  3.1219e-03, -3.5063e-03,  4.6244e-03,  2.4687e-04,\n",
       "            5.4187e-03,  4.2096e-03,  6.6868e-03, -5.6403e-03, -1.2423e-02,\n",
       "           -6.5869e-03,  1.1082e-02, -7.6709e-03, -7.0059e-03,  8.0211e-03,\n",
       "            1.4674e-02,  6.9200e-03, -1.2213e-02,  2.3975e-03, -3.3708e-03,\n",
       "           -4.5343e-03, -2.1953e-03, -5.7115e-03,  1.4041e-03,  1.1428e-03,\n",
       "           -1.1077e-03,  7.0626e-03,  4.2280e-03,  1.3630e-03, -5.3510e-03,\n",
       "           -2.7323e-03, -2.4541e-03, -1.0799e-02,  8.9230e-03,  8.2428e-04,\n",
       "            1.4546e-02, -5.3735e-03,  3.3720e-03, -4.7852e-03, -1.5794e-02,\n",
       "           -7.9620e-04, -2.1188e-03,  1.6071e-02, -1.0329e-02, -9.3018e-03,\n",
       "           -2.1334e-04, -7.0587e-03, -1.0471e-02,  6.7677e-03, -5.2074e-04,\n",
       "            6.1461e-03, -1.3619e-02, -2.1429e-02,  3.4854e-03,  1.7004e-03,\n",
       "            1.5740e-02, -1.6990e-03, -7.6969e-03,  8.4334e-03,  1.0714e-02,\n",
       "           -2.5341e-02,  1.8500e-03, -5.8181e-03,  2.2629e-03, -5.9092e-03,\n",
       "           -8.7752e-03,  2.3967e-03, -8.9828e-03,  8.5226e-03,  9.1624e-03,\n",
       "           -2.3430e-03,  6.6033e-03, -5.4026e-03, -8.1200e-03,  7.4705e-04,\n",
       "           -2.5788e-03,  3.4707e-03, -1.2994e-02,  6.5407e-03, -5.8132e-03,\n",
       "           -7.4172e-03, -5.9772e-03, -1.0955e-02, -1.3795e-03,  1.0518e-02,\n",
       "            7.1656e-04,  4.0472e-03, -2.6328e-03,  1.4341e-03, -7.7110e-03,\n",
       "            3.8079e-03, -2.4961e-03, -3.6558e-03,  1.2053e-02, -2.0465e-03,\n",
       "           -6.5300e-03,  5.3360e-03, -5.2126e-03,  1.3771e-02, -8.5266e-03,\n",
       "           -8.8745e-04, -1.2518e-02, -9.7683e-03,  6.3954e-03,  5.1233e-04,\n",
       "           -2.0266e-02,  3.1972e-03, -1.0688e-02, -3.2478e-03, -3.4997e-02,\n",
       "           -1.9697e-03,  2.4764e-03, -1.1068e-02, -1.9138e-03, -3.4721e-03,\n",
       "            3.0131e-03,  5.2432e-03, -4.7837e-03, -9.0210e-03,  8.9010e-04,\n",
       "           -1.2171e-02, -2.4889e-03,  3.9447e-03,  7.2811e-03, -2.9392e-02,\n",
       "            6.0408e-03,  1.3307e-02,  8.4778e-03, -3.7808e-03, -6.8260e-03,\n",
       "            2.4769e-02,  2.0260e-03, -1.1963e-02,  2.9207e-03,  4.2567e-03,\n",
       "           -5.4919e-03,  4.2809e-03, -1.9045e-03, -8.0282e-04, -2.3730e-03,\n",
       "            1.1285e-03, -1.1000e-03,  1.0242e-02,  9.6368e-04, -1.4591e-02,\n",
       "            1.5200e-02,  2.2358e-02, -6.1089e-03, -2.7177e-03, -6.1214e-03,\n",
       "           -8.4963e-03, -3.8340e-03,  3.8736e-03, -5.1660e-03,  1.2234e-02,\n",
       "            1.1202e-02,  1.7087e-03,  8.9061e-03, -1.1641e-02, -6.0663e-03,\n",
       "            5.2421e-03,  5.1230e-03, -8.3035e-03, -6.2609e-03,  5.0970e-03,\n",
       "           -7.6108e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-1.7918e-02, -1.4796e-01, -3.8830e-02,  ..., -6.1507e-02,\n",
       "             3.4014e-02,  2.0763e-02],\n",
       "           [-2.0264e-01,  3.9425e-01,  5.0233e-01,  ...,  1.2283e-01,\n",
       "            -2.4148e-01, -9.3274e-01],\n",
       "           [ 4.3415e-01,  1.9188e-01,  6.1390e-01,  ..., -2.2244e-01,\n",
       "            -8.1545e-04, -8.9246e-02],\n",
       "           ...,\n",
       "           [ 3.2460e-01,  2.5197e-02, -6.1253e-02,  ..., -1.3876e-01,\n",
       "            -5.5203e-02,  4.6604e-02],\n",
       "           [-6.0541e-02, -1.3006e-01, -2.1378e-02,  ..., -9.5440e-03,\n",
       "             1.7420e-01, -2.8989e-03],\n",
       "           [ 2.0862e-01,  1.4611e-01, -6.4076e-02,  ...,  1.6685e-02,\n",
       "            -4.2744e-02,  2.9728e-02]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 1.6097e-02,  8.6132e-01,  1.0631e-02, -4.8556e-03, -5.9550e-02,\n",
       "            4.8857e-02,  2.7459e-02, -3.0670e-02,  2.0495e-02,  2.7562e-02,\n",
       "           -8.2841e-02, -3.5493e-02, -2.3683e-02,  1.2777e-02,  2.0278e-02,\n",
       "            1.8083e-02, -1.0098e-02, -1.1832e-02,  1.0264e-02,  2.2039e-02,\n",
       "           -3.8667e-02, -1.5183e-02,  1.1161e-02, -9.8899e-03,  6.1725e-02,\n",
       "           -1.1943e-02,  9.7371e-03, -1.7618e-02, -5.9742e-03,  3.7811e-02,\n",
       "           -3.0400e-03,  2.4994e-02,  1.1649e-02, -3.4561e-02,  1.0876e-02,\n",
       "            1.1153e-02,  2.3268e-02,  3.2754e-02, -1.7954e-02,  2.2960e-02,\n",
       "            2.9287e-02,  2.9374e-02,  1.3604e-02,  2.8500e-02,  2.0664e-02,\n",
       "            7.7822e-03,  5.3785e-03,  1.3852e-02,  6.0412e-03, -2.9635e-03,\n",
       "           -6.1396e-03,  1.5006e-02, -1.6794e-02,  5.6874e-02, -9.8376e-03,\n",
       "            4.1447e-03, -2.7544e-02,  9.9189e-03, -4.8380e-02,  1.3783e-02,\n",
       "           -2.7384e-02, -8.9212e-03, -2.8370e-02,  3.9193e-02, -3.9448e-02,\n",
       "            1.7242e-02, -3.5176e-03,  2.0466e-02, -2.0781e-02,  3.0884e-02,\n",
       "            8.4266e-03, -1.0283e-02, -3.4145e-02, -1.5621e-02, -2.2706e-02,\n",
       "            2.6429e-03, -1.0258e-02,  4.9261e-02, -1.0302e-03, -6.6789e-03,\n",
       "           -2.4627e-02,  1.2647e-02, -4.4437e-02,  3.0751e-02,  5.8099e-02,\n",
       "           -1.2674e-02,  3.0944e-02, -3.7148e-02, -7.4874e-03,  6.7273e-02,\n",
       "           -9.1342e-03,  1.6088e-02,  9.4097e-03,  3.2150e-02,  2.3574e-02,\n",
       "           -2.1196e-02,  1.3347e-02, -3.8814e-03, -3.3677e-02, -1.0880e-02,\n",
       "           -2.7484e-02,  2.6346e-02,  3.3901e-02,  3.4402e-02, -1.8694e-02,\n",
       "           -8.2891e-03,  5.7817e-03,  2.3472e-02, -3.2313e-02, -3.5906e-02,\n",
       "           -1.0102e-02,  4.7329e-02,  1.4688e-02, -3.2467e-03,  4.0374e-03,\n",
       "           -1.0296e-03, -1.8645e-02,  1.9793e-02,  2.5033e-02, -1.4369e-02,\n",
       "            1.1080e-02,  1.3837e-02, -7.1524e-03,  1.4461e-02, -1.6181e-02,\n",
       "           -2.4668e-02, -1.3248e-02,  2.0893e-02, -3.2826e-03,  3.2449e-02,\n",
       "           -3.4146e-02,  1.4152e-02, -5.2605e-02,  3.0349e-02, -2.8391e-01,\n",
       "            1.6451e-02,  1.0603e-02, -4.1705e-04, -4.4928e-02,  4.9146e-02,\n",
       "           -2.6211e-02,  1.8666e-03,  7.3595e-03,  3.0743e-02,  1.1073e-03,\n",
       "           -1.8269e-02, -4.6599e-03,  1.6487e-02,  1.7260e-02, -1.6228e-02,\n",
       "            8.6208e-03,  2.8517e-02,  2.3747e-02, -6.6891e-03, -1.2051e-02,\n",
       "            9.7143e-03,  1.5141e-03,  1.5045e-02, -1.9753e-02,  2.5311e-02,\n",
       "            2.7316e-03, -3.0092e-02, -1.1545e-03,  5.7171e-03, -1.7094e-02,\n",
       "           -2.1070e-02, -8.3601e-03,  3.9974e-03, -2.0438e-02,  1.3594e-02,\n",
       "           -1.8235e-02, -3.1689e-03,  1.1808e-02,  6.1487e-02,  9.1708e-03,\n",
       "           -9.9585e-04,  1.1128e-02,  3.0692e-02,  5.3670e-02, -8.5815e-03,\n",
       "            2.5246e-03,  6.4052e-03,  5.4052e-03,  3.3415e-03,  1.1299e-02,\n",
       "            1.9912e-03, -1.1298e-02, -3.5435e-03,  1.4989e-03, -2.4862e-02,\n",
       "           -4.5551e-02,  1.1450e-02,  3.2496e-02,  2.0501e-02,  2.3808e-04,\n",
       "            1.0734e-02,  1.2334e-02,  3.6146e-02, -2.3664e-02, -1.4854e-02,\n",
       "           -1.4136e-03, -2.7613e-02,  1.1938e-03,  5.1656e-03, -2.0175e-03,\n",
       "            1.2296e-03, -2.2089e-03,  5.8142e-04, -1.9238e-02,  1.8902e-02,\n",
       "           -9.6547e-02,  5.7163e-03,  2.2947e-02,  2.6841e-03,  5.3257e-02,\n",
       "           -1.0596e-02, -2.3954e-02,  1.6000e-02, -6.0070e-02,  6.0780e-02,\n",
       "           -1.9546e-03, -4.1269e-03,  3.7764e-02,  1.1766e-02,  2.3142e-03,\n",
       "           -4.9540e-03,  1.5234e-02,  3.8126e-02, -3.5034e-02,  2.0240e-02,\n",
       "            2.6891e-02, -2.7140e-02, -9.8065e-04,  1.2847e-02,  1.2669e-02,\n",
       "           -1.1956e-02, -3.3164e-03, -1.1938e-02, -9.2110e-03, -2.6000e-02,\n",
       "           -1.4454e-02,  2.3153e-02,  9.0956e-03, -3.0840e-02, -1.7473e-02,\n",
       "           -2.5954e-02,  1.0522e-02,  1.5984e-02,  4.0186e-02, -1.5349e-02,\n",
       "            3.3249e-02, -1.0215e-02, -3.7784e-02, -2.0150e-02, -9.1433e-03,\n",
       "           -5.1449e-04], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0964,  0.0897,  0.0784,  ...,  0.5196, -0.1787, -0.4560],\n",
       "           [ 0.2262, -0.0620, -0.1351,  ..., -0.4241,  0.4671, -0.7886],\n",
       "           [-0.3911, -0.0949,  0.4970,  ..., -0.1146,  0.3358,  0.1884],\n",
       "           ...,\n",
       "           [ 0.1123,  0.5499,  0.8080,  ..., -0.3582,  0.1793, -0.3010],\n",
       "           [-0.1019,  0.1314, -0.3470,  ...,  0.3375, -0.2373, -0.7059],\n",
       "           [-0.0848, -0.3152, -0.1667,  ..., -0.2025,  0.1047, -0.0332]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.9824,  0.1268, -0.0297,  0.9372,  0.9059,  1.0366, -0.1534,  1.0702,\n",
       "            1.1746,  0.9524, -0.8364,  1.2783, -0.6237,  0.2330,  0.1227,  1.7037,\n",
       "           -0.4500,  0.6792, -0.6364, -1.0144,  1.0579, -0.3425,  0.8840,  0.8708,\n",
       "            0.2884, -0.8856, -0.8433,  0.6456,  0.1466, -1.0281,  0.7218, -0.8389,\n",
       "            2.4362, -0.3977,  0.0977,  0.3306,  0.3534,  1.4106,  1.3387, -1.6528,\n",
       "           -2.6255, -0.0927, -1.0735, -2.1495, -0.3197, -0.6192,  0.3719, -1.6481,\n",
       "            0.0036, -0.2995, -0.8287, -1.6116, -0.2790,  2.2718, -1.2430,  0.1896,\n",
       "           -0.0252,  1.6061, -1.4933,  0.1975,  0.2273,  1.1415,  1.7812, -1.4153,\n",
       "           -0.3823, -0.4758,  0.8493,  0.8640,  0.8289, -0.2299, -0.8627, -0.4700,\n",
       "            0.4635, -0.1867, -0.6826, -0.5255, -0.8041, -0.0348,  0.2265,  0.7264,\n",
       "           -0.9109, -0.7601, -0.5043, -0.5435, -0.4734,  0.8443,  0.5251, -0.7200,\n",
       "           -0.1027, -0.6959,  0.1953,  0.3587,  0.8468,  0.5125, -0.5186, -0.4227,\n",
       "            0.5752, -0.7305,  0.4654,  0.2382, -0.3746, -0.1898, -0.7845, -0.3262,\n",
       "            0.1015,  0.1911, -0.6628, -0.1377,  0.1419, -0.2002,  0.3756, -0.3191,\n",
       "            0.5023, -0.0458,  0.5732, -0.5639, -0.2104,  0.2201,  0.7246, -0.3739,\n",
       "           -0.7297, -0.1015, -0.5172,  0.2744, -0.7691,  0.2822, -0.2843, -0.4284,\n",
       "            0.3264, -0.0061, -0.4990, -0.8609, -0.3598,  0.2751,  0.5069,  0.2496,\n",
       "            0.4310, -0.6644,  0.7287,  0.5979, -0.2978,  0.3827, -0.3086,  0.5849,\n",
       "            0.0345, -0.0797, -0.3767,  0.6529, -0.2269,  0.5494, -0.2710,  0.8863,\n",
       "           -0.6310, -0.2303,  0.7101,  0.5978,  0.2406, -0.4850, -0.4786, -0.4064,\n",
       "           -0.0116,  0.7322, -0.2796,  1.0688, -1.1895, -0.6642,  0.4988,  0.7897,\n",
       "            0.0099,  0.3103, -0.0487,  0.1578,  0.4817, -1.1977, -1.0994, -0.4367,\n",
       "            0.1150, -0.4598,  0.0886,  0.1789,  0.6217,  0.1926,  0.6319, -1.0277,\n",
       "            0.0661,  0.3129, -0.6676,  0.0773,  0.3812,  0.4908,  0.7230, -0.7176,\n",
       "           -0.0669,  0.7154, -1.0566, -0.8869,  0.9772,  0.2973,  0.0157,  0.3427,\n",
       "            1.3833,  0.3261, -0.8178, -0.2463,  1.1928, -0.4666,  0.7861,  0.4458,\n",
       "            0.6696, -1.2201,  0.1931, -0.8681, -0.8500, -1.2204,  0.7666,  0.7149,\n",
       "           -0.9441,  1.1200, -0.5862,  0.8420, -0.2520, -0.8425,  1.0413,  1.2749,\n",
       "           -1.5307,  1.2142,  1.0607, -0.2377, -0.0674,  1.0063, -1.2628, -0.7445,\n",
       "           -0.5929, -1.1196,  0.2398, -1.0804,  0.4811,  1.3062, -0.8912, -0.9923,\n",
       "           -0.0721, -0.8448, -0.3360, -1.2297, -1.1866, -0.6713,  1.1860, -1.5234,\n",
       "           -1.1324,  1.0575,  0.8652,  0.5770, -0.6504,  0.9173,  0.5876, -0.9416],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0532,  0.1433, -0.0972,  ..., -0.2125, -0.1553,  0.2724],\n",
       "           [ 0.2465,  0.0683,  0.1605,  ...,  0.2554, -0.0393, -0.2552],\n",
       "           [-0.0866,  0.0555,  0.0581,  ..., -0.0567, -0.1431,  0.3149],\n",
       "           ...,\n",
       "           [-0.0565, -0.0204,  0.0501,  ...,  0.1404,  0.0778, -0.2888],\n",
       "           [ 0.2526,  0.2251,  0.0531,  ...,  0.1742,  0.2525, -0.2281],\n",
       "           [ 0.2880, -0.0824,  0.1975,  ..., -0.0147,  0.0603,  0.3490]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-2.7806e-03,  3.4692e-03, -3.6477e-03, -2.6824e-03,  1.9195e-03,\n",
       "           -1.9025e-03, -1.9983e-03,  2.7418e-03, -6.4854e-04,  3.0013e-03,\n",
       "            9.3073e-04, -3.5356e-03, -2.1606e-03, -5.0362e-03, -5.2065e-03,\n",
       "           -1.6574e-03,  2.5087e-03,  2.4445e-04, -3.9222e-04,  1.4598e-03,\n",
       "            8.1114e-04,  2.5501e-03, -1.6821e-03, -3.2731e-03,  5.2458e-03,\n",
       "            5.1224e-03, -1.7163e-04,  7.7537e-04,  3.5601e-03,  4.1828e-03,\n",
       "           -3.9588e-03,  1.3547e-03,  1.7482e-03, -3.9386e-03,  2.0401e-03,\n",
       "           -3.7042e-03,  4.7865e-03, -2.5859e-03, -6.3925e-03, -5.7016e-05,\n",
       "           -1.9455e-04, -3.5059e-03,  4.9149e-03,  2.8310e-03,  6.0546e-03,\n",
       "           -4.5145e-03,  2.8133e-03,  4.5842e-03,  4.7043e-03,  4.7028e-03,\n",
       "            3.2112e-03, -1.7049e-03,  2.8284e-03,  6.7605e-03,  6.3121e-04,\n",
       "           -8.5945e-04, -6.5628e-04, -6.6558e-04, -1.5038e-03, -4.6251e-03,\n",
       "            4.9865e-03,  6.1039e-03, -2.8738e-03,  4.2516e-03, -2.9979e-02,\n",
       "           -2.0386e-02, -2.0577e-02,  3.6870e-02,  2.4169e-02,  3.3928e-02,\n",
       "           -3.7440e-02, -2.4745e-02, -3.9846e-03,  3.8325e-02, -6.5329e-02,\n",
       "            4.5033e-03, -2.1215e-02,  6.7483e-02,  1.0753e-02,  4.4412e-02,\n",
       "           -3.4564e-02, -2.7565e-02, -2.2564e-02, -4.6502e-02, -4.5351e-02,\n",
       "            3.2050e-02, -1.4683e-02, -6.3900e-02,  1.8793e-03, -3.2860e-02,\n",
       "           -4.6971e-02,  6.6768e-02,  5.0032e-02,  3.1088e-02, -5.2254e-02,\n",
       "           -1.1813e-02, -6.5431e-03,  8.2998e-03, -4.9185e-03, -4.7115e-03,\n",
       "            4.5000e-03,  5.9550e-03,  4.5424e-03,  6.1784e-03, -3.2035e-03,\n",
       "           -3.5018e-03,  6.7296e-03,  3.5348e-03,  3.0283e-03,  4.3560e-03,\n",
       "           -5.0391e-03,  6.1052e-03, -7.2045e-03, -3.2594e-03, -2.5222e-03,\n",
       "            5.2771e-03, -6.5938e-05, -3.2390e-03, -3.4243e-03,  3.9069e-03,\n",
       "            6.4965e-03,  4.6138e-03,  4.2424e-03, -5.6321e-03,  6.8086e-03,\n",
       "           -1.9136e-03,  6.3275e-04,  6.9418e-03,  2.8787e-02, -3.3363e-02,\n",
       "           -2.0145e-02, -3.4928e-02, -1.1424e-02, -9.3383e-03,  2.6739e-02,\n",
       "            3.5866e-02,  2.8370e-02, -5.2429e-02,  3.7093e-02,  5.4307e-02,\n",
       "           -2.6502e-02,  3.0315e-02, -3.2987e-02,  4.5376e-02, -2.4951e-02,\n",
       "           -2.3374e-03, -2.3622e-02,  3.7161e-02, -4.7401e-02,  5.4256e-02,\n",
       "           -1.3184e-02,  2.7689e-02, -3.5236e-02, -2.4242e-02,  3.0454e-02,\n",
       "            4.1770e-02, -2.1190e-02, -2.7534e-02, -1.1777e-02, -2.7756e-02,\n",
       "            5.8417e-03,  1.7753e-03, -1.2331e-04,  3.5854e-03,  1.2358e-03,\n",
       "            2.4334e-03, -2.3831e-03, -3.1224e-03, -5.7096e-03,  7.5919e-04,\n",
       "            2.3602e-03,  4.6705e-03, -3.1166e-03,  7.9928e-06, -8.5778e-04,\n",
       "           -3.1966e-03, -9.1018e-04,  4.5597e-04,  1.1074e-03, -9.9112e-04,\n",
       "            2.1081e-03, -5.5171e-03, -7.3330e-03, -1.0002e-04, -4.8866e-03,\n",
       "            9.3188e-04, -4.5687e-04,  2.5019e-03, -4.6671e-03, -7.2607e-04,\n",
       "            3.0355e-03, -3.1285e-04,  3.5413e-02,  2.0342e-02, -7.7104e-02,\n",
       "           -6.2561e-02,  3.9315e-02,  5.1310e-02,  3.5564e-02,  3.1409e-02,\n",
       "            6.1194e-02,  3.8077e-02, -5.8758e-02,  1.4237e-02,  7.0092e-02,\n",
       "           -2.5790e-02,  7.6686e-02,  1.7179e-02,  4.8759e-02, -7.7032e-02,\n",
       "            1.9911e-03, -4.0267e-02, -4.6219e-02, -7.7405e-02,  1.3865e-02,\n",
       "           -4.0088e-03, -3.6060e-02,  6.0793e-02, -1.3844e-02,  6.1233e-02,\n",
       "           -3.0519e-02, -3.1940e-02,  7.7430e-02,  7.2249e-02, -5.1429e-03,\n",
       "            2.3568e-03, -7.7828e-03,  1.9343e-04,  1.1018e-03, -1.7250e-03,\n",
       "            1.2137e-03, -4.3623e-03,  1.5238e-03,  2.4281e-04,  1.3939e-02,\n",
       "            2.8223e-03,  1.0964e-03,  1.1526e-04, -4.9254e-03, -2.9843e-03,\n",
       "            2.7378e-03,  1.6866e-03,  1.0567e-04, -2.3616e-03,  2.5758e-03,\n",
       "            7.5311e-03, -1.5365e-03,  1.1372e-03,  4.6434e-03, -2.6189e-03,\n",
       "            1.1273e-03, -1.5964e-03, -2.6034e-03, -9.2843e-04, -7.7340e-03,\n",
       "           -9.1853e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0284, -0.0108, -0.0996,  ..., -0.0479, -0.0807, -0.0692],\n",
       "           [ 0.1154, -0.0506,  0.0754,  ...,  0.0943, -0.0763, -0.0306],\n",
       "           [ 0.1006, -0.0099,  0.0405,  ..., -0.0213,  0.0244,  0.1419],\n",
       "           ...,\n",
       "           [ 0.0941,  0.1058, -0.0020,  ..., -0.0335,  0.0002, -0.0276],\n",
       "           [ 0.0670,  0.0930,  0.0187,  ...,  0.0882, -0.0859,  0.0050],\n",
       "           [-0.0745, -0.0334,  0.0323,  ...,  0.1360,  0.0645,  0.0635]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0057,  0.0029,  0.0076,  0.0011,  0.0071,  0.0055, -0.0051,  0.0012,\n",
       "           -0.0002, -0.0083, -0.0114,  0.0049,  0.0075, -0.0032,  0.0072, -0.0085,\n",
       "           -0.0097, -0.0109,  0.0040, -0.0012, -0.0043, -0.0067,  0.0051, -0.0076,\n",
       "           -0.0029,  0.0021,  0.0004, -0.0046, -0.0382, -0.0109,  0.0307, -0.0020,\n",
       "           -0.0282,  0.0015, -0.0013,  0.0006,  0.0020,  0.0003, -0.0038, -0.0071,\n",
       "            0.0068, -0.0043, -0.0038,  0.0125, -0.0060, -0.0012, -0.0030, -0.0040,\n",
       "           -0.0021, -0.0038,  0.0078,  0.0213,  0.0158,  0.0004, -0.0054, -0.0008,\n",
       "            0.0012,  0.0034, -0.0025,  0.0003,  0.0004, -0.0056, -0.0009, -0.0032,\n",
       "           -0.0095, -0.0035,  0.0064,  0.0111,  0.0093, -0.0025, -0.0011,  0.0009,\n",
       "            0.0197, -0.0036, -0.0066, -0.0080,  0.0026,  0.0014,  0.0283,  0.0010,\n",
       "           -0.0022,  0.0006, -0.0030,  0.0049,  0.0078,  0.0100,  0.0349, -0.0018,\n",
       "            0.0027,  0.0024, -0.0052,  0.0019, -0.0024, -0.0049, -0.0062,  0.0025,\n",
       "            0.0080, -0.0034,  0.0054, -0.0031, -0.0038,  0.0078,  0.0042,  0.0072,\n",
       "            0.0055,  0.0123,  0.0057,  0.0010,  0.0018, -0.0033, -0.0002,  0.0097,\n",
       "           -0.0231, -0.0102,  0.0060, -0.0018, -0.0071,  0.0028, -0.0130,  0.0038,\n",
       "           -0.0004,  0.0015, -0.0086, -0.0035, -0.0004,  0.0028, -0.0117,  0.0002,\n",
       "            0.0009,  0.0036,  0.0007, -0.0100, -0.0112,  0.0061,  0.0033,  0.0048,\n",
       "           -0.0064,  0.0056,  0.0005,  0.0050,  0.0028, -0.0046, -0.0170,  0.0186,\n",
       "           -0.0003,  0.0046, -0.0038, -0.0134,  0.0044, -0.0021, -0.0015, -0.0055,\n",
       "            0.0086,  0.0095,  0.0031,  0.0356,  0.0004, -0.0061,  0.0018,  0.0022,\n",
       "            0.0140,  0.0046,  0.0006,  0.0218,  0.0026,  0.0162,  0.0129,  0.0252,\n",
       "           -0.0172, -0.0025,  0.0178, -0.0014,  0.0039, -0.0145, -0.0131,  0.0284,\n",
       "            0.0019,  0.0047,  0.0015, -0.0863, -0.0106,  0.0028, -0.0776, -0.0008,\n",
       "           -0.0150,  0.0563,  0.0072,  0.0110, -0.0081,  0.0191, -0.0050,  0.0078,\n",
       "           -0.0060,  0.0038,  0.0054, -0.0164, -0.0201, -0.0051, -0.0069, -0.0046,\n",
       "            0.0174,  0.0055,  0.0037, -0.0066, -0.0049,  0.0089,  0.0018,  0.0036,\n",
       "           -0.0129, -0.0084,  0.0053,  0.0134,  0.0086,  0.0083,  0.0019,  0.0146,\n",
       "            0.0049, -0.0091, -0.0040,  0.0056,  0.0003,  0.0045,  0.0063,  0.0222,\n",
       "           -0.0011, -0.0077,  0.0371,  0.0463, -0.0112, -0.0019, -0.0022, -0.0045,\n",
       "           -0.0034,  0.0070, -0.0003,  0.0103, -0.0048,  0.0135,  0.0052,  0.0514,\n",
       "           -0.0073, -0.0106,  0.0058,  0.0116, -0.0018, -0.0017, -0.0040, -0.0087,\n",
       "            0.0096, -0.0265,  0.0261,  0.0301, -0.0053, -0.0090, -0.0246,  0.0022],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.4429,  0.0153, -0.0611,  ..., -0.0418,  0.2841, -0.0090],\n",
       "           [-0.2145, -0.0603, -0.0655,  ...,  0.0335, -0.7082,  0.0395],\n",
       "           [ 0.3497,  0.0821, -0.2318,  ..., -0.1170, -0.3454, -0.2125],\n",
       "           ...,\n",
       "           [ 0.0466,  0.2199,  0.3198,  ..., -0.0034, -0.0133,  0.0607],\n",
       "           [-0.0887, -0.0533,  0.0088,  ...,  0.2539,  0.2134, -0.0921],\n",
       "           [ 0.0106, -0.0340, -0.0206,  ..., -0.1850, -0.0525,  0.1141]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 2.3096e-02, -1.1342e-02, -4.7049e-02,  9.5470e-02, -1.6520e-02,\n",
       "            4.4828e-02,  3.1899e-02, -1.2893e-02, -1.4846e-02,  1.8550e-02,\n",
       "            3.3377e-02,  2.9193e-02,  1.7451e-01, -3.7920e-03,  3.1650e-02,\n",
       "            5.6291e-03, -1.7909e-02,  2.9474e-02, -2.4092e-02, -5.2355e-02,\n",
       "            8.6285e-03, -1.4801e-02,  1.8132e-03,  1.9168e-02, -9.0369e-03,\n",
       "            2.1428e-02, -1.6445e-02,  2.2186e-02,  2.5725e-02, -3.6424e-02,\n",
       "           -3.1592e-03,  7.8960e-03, -2.7684e-02, -2.2808e-02,  1.6889e-02,\n",
       "            1.0065e-02, -7.9538e-03, -1.7052e-02, -9.1132e-02, -4.5470e-02,\n",
       "           -6.1601e-02,  3.7351e-03,  2.7515e-02,  1.7170e-02, -5.2884e-04,\n",
       "           -2.0380e-03, -2.1837e-03,  2.9243e-02, -1.0230e-02,  1.4063e-02,\n",
       "           -4.1299e-02, -2.4772e-04,  6.4072e-02, -2.3373e-02,  2.1971e-02,\n",
       "           -9.1629e-03, -1.3014e-02, -4.1983e-02, -3.6362e-02, -1.7582e-02,\n",
       "            9.3517e-02,  4.2419e-02,  4.8502e-02, -2.9852e-02,  2.0007e-02,\n",
       "           -1.1702e-02,  2.8875e-02, -4.6133e-02, -9.0327e-03,  4.5070e-03,\n",
       "           -1.9181e-02, -2.4560e-02, -6.0427e-03,  7.7359e-03,  2.9876e-03,\n",
       "            1.4457e-02, -4.3056e-02, -9.0036e-03, -1.7452e-02,  1.1924e-02,\n",
       "           -4.0755e-02, -1.5735e-02,  9.7509e-03,  4.0634e-02,  1.8782e-01,\n",
       "           -1.2686e-02,  1.6743e-02, -1.9131e-02, -2.7527e-02,  1.5863e-02,\n",
       "            5.8480e-02, -1.1102e-02, -1.6519e-02, -7.7033e-03, -1.4667e-02,\n",
       "           -1.2082e-01, -1.0271e-02, -1.0302e-02,  2.8145e-02, -1.7573e-02,\n",
       "           -1.7662e-03,  9.8854e-03, -6.2748e-04,  3.2343e-02, -1.0110e-02,\n",
       "           -5.0212e-02,  1.4706e-04, -2.1429e-02,  3.9694e-03,  5.4593e-02,\n",
       "            1.2664e-02, -7.3661e-02, -7.9737e-03,  1.0928e-03, -2.8009e-03,\n",
       "            2.1157e-02,  2.1141e-02,  8.5238e-04,  9.7218e-03,  3.5424e-02,\n",
       "            1.6616e-02, -6.4136e-03,  2.6020e-02, -1.5444e-02, -1.0932e-02,\n",
       "            1.7206e-02, -4.1306e-03, -1.9794e-02, -9.3872e-03, -1.0598e-02,\n",
       "            1.4169e-02,  8.4875e-03, -3.2409e-02,  2.3347e-02, -1.5293e-01,\n",
       "            2.8729e-02, -3.9296e-02, -1.3742e-04, -1.5559e-02,  6.4761e-03,\n",
       "           -1.5530e-01, -2.7712e-02, -4.9749e-02, -3.8585e-02,  2.2215e-02,\n",
       "           -3.4229e-02,  8.7260e-05,  1.1745e-02, -5.2252e-03,  1.3633e-02,\n",
       "            4.2528e-02,  3.3887e-02, -5.9468e-02, -2.2121e-02, -2.3874e-02,\n",
       "           -6.1794e-02,  8.7893e-03,  3.1348e-02, -4.4422e-03,  1.9209e-02,\n",
       "            3.1360e-04, -5.7634e-02,  1.1928e-02,  1.1381e-02, -1.5298e-02,\n",
       "           -6.1976e-02,  3.2124e-02,  1.5029e-02, -1.3660e-02,  3.6113e-02,\n",
       "            1.1039e-02, -4.1348e-03, -2.9559e-02,  2.8946e-02,  4.8092e-02,\n",
       "           -1.2382e-03, -3.5794e-03, -2.4089e-03, -1.9178e-02, -1.8296e-02,\n",
       "           -1.7796e-02, -3.6913e-02, -3.6433e-02,  2.9666e-02,  3.9874e-02,\n",
       "            2.2342e-03, -7.9168e-03, -4.6407e-02, -6.8710e-03,  2.2412e-02,\n",
       "           -1.7237e-01, -6.7444e-03,  2.5824e-02,  3.5736e-02,  6.8536e-04,\n",
       "            3.7472e-02, -1.8641e-05, -1.1467e-02, -3.2437e-02, -1.4341e-02,\n",
       "           -7.9895e-03, -2.5147e-02,  2.1839e-02, -8.2751e-03, -1.0695e-02,\n",
       "            2.3276e-02,  1.8181e-02,  3.0136e-03, -1.4794e-02,  4.0401e-02,\n",
       "           -1.2651e-01, -2.9702e-03,  1.9625e-02, -1.0284e-02,  4.6738e-02,\n",
       "           -7.1989e-02, -4.9054e-02, -2.8568e-02,  1.8834e-03,  2.4219e-02,\n",
       "           -9.2878e-03, -4.4445e-03,  1.0066e-01, -7.2012e-03, -1.7948e-02,\n",
       "           -5.1508e-03, -2.3521e-02,  1.5713e-02,  3.3901e-03, -2.5470e-02,\n",
       "            3.9338e-03, -1.6154e-02,  4.0961e-03,  2.3823e-02, -1.3158e-02,\n",
       "           -1.3461e-02, -1.1410e-02,  2.0108e-02, -1.4486e-02, -5.2483e-02,\n",
       "            1.3386e-02,  4.2768e-03,  4.1989e-02,  1.6694e-02,  1.0903e-02,\n",
       "           -4.4305e-02,  1.7258e-02,  3.1868e-02,  2.4399e-02,  3.5768e-02,\n",
       "            3.1601e-02, -3.5264e-02, -1.8132e-02, -2.0251e-02, -4.1735e-02,\n",
       "           -4.8909e-03], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0936,  0.2124,  0.4084,  ...,  0.1928,  0.1552, -0.0394],\n",
       "           [ 0.1760,  0.0372,  0.1787,  ...,  0.4627, -0.2013, -0.0873],\n",
       "           [ 0.0314,  0.1123,  0.1478,  ...,  0.2100, -0.3068, -0.1499],\n",
       "           ...,\n",
       "           [-0.0448,  0.1374,  0.3529,  ...,  0.0145, -0.0168, -0.1436],\n",
       "           [ 0.2369,  0.0370,  0.1564,  ..., -0.0224, -0.0165, -0.1838],\n",
       "           [ 0.1472,  0.2970,  0.0723,  ...,  0.0141,  0.1666, -0.0499]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.4448, -0.3994, -0.4989, -0.3587, -0.4668, -0.3872, -0.6136, -0.3844,\n",
       "           -0.5335, -0.3240, -0.3221, -0.4835, -0.4463, -0.4047, -0.3772, -0.3877,\n",
       "           -0.3081, -0.4122, -0.3604, -0.4127, -0.2987, -0.5447, -0.2464, -0.4743,\n",
       "           -0.4768, -0.2527, -0.3109, -0.4356, -0.4670, -0.3609, -0.5264, -0.4097,\n",
       "           -0.4697, -0.4202, -0.4358, -0.4369, -0.3595, -0.3510, -0.3072, -0.3638,\n",
       "           -0.4063, -0.3854, -0.4143, -0.3588, -0.3533, -0.4494, -0.2840, -0.4348,\n",
       "           -0.3249, -0.4156, -0.4048, -0.3159, -0.3886, -0.4169, -0.3927, -0.2882,\n",
       "           -0.3247, -0.5156, -0.4566, -0.2967, -0.3972, -0.3243, -0.4382, -0.3593],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.0718,  0.1957, -0.0176,  ...,  0.1188, -0.1603,  0.0134],\n",
       "           [ 0.0700,  0.4238,  0.0405,  ..., -0.2533,  0.2375, -0.3262],\n",
       "           [-0.5635, -0.3423,  0.0724,  ..., -0.1347, -0.2449, -0.1223],\n",
       "           ...,\n",
       "           [-0.0351, -0.1734, -0.0690,  ..., -0.2209, -0.3653, -0.0018],\n",
       "           [-0.0206, -0.3539, -0.1614,  ...,  0.2754,  0.6510,  0.0468],\n",
       "           [-0.2012,  0.1203, -0.0310,  ...,  0.1275, -0.0408,  0.0817]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0205,  0.0352,  0.0174,  0.0052,  0.0449,  0.0489,  0.0463,  0.0096,\n",
       "           -0.0105, -0.0270, -0.0017,  0.0518,  0.0176, -0.0118, -0.0137,  0.0315,\n",
       "           -0.0095,  0.0035,  0.0103,  0.0209, -0.0371, -0.0247,  0.0174,  0.0212,\n",
       "            0.0062, -0.0235,  0.0255,  0.0255, -0.0459, -0.0008, -0.0047, -0.0107,\n",
       "           -0.0244, -0.0399,  0.0050, -0.0140,  0.0059,  0.0308,  0.0403,  0.0125,\n",
       "            0.0252,  0.0045,  0.0119,  0.0074, -0.0486, -0.0252,  0.0150, -0.0098,\n",
       "           -0.0434, -0.0273, -0.0143, -0.0385,  0.0406,  0.0407, -0.0023,  0.0037,\n",
       "            0.0006, -0.0307, -0.0356, -0.0092, -0.0008,  0.0145, -0.0295,  0.0004,\n",
       "           -0.0060,  0.0162, -0.0537,  0.0189, -0.0276,  0.0152,  0.0067, -0.0312,\n",
       "            0.0218, -0.0207,  0.0068,  0.0083, -0.0134, -0.0288, -0.0105, -0.0080,\n",
       "            0.0063, -0.0046,  0.0042,  0.0261,  0.1209, -0.0054, -0.0067, -0.0494,\n",
       "           -0.0147,  0.0067, -0.0260,  0.0213, -0.0174,  0.0539, -0.0180,  0.0192,\n",
       "            0.0032,  0.0352, -0.0199,  0.0056,  0.0097, -0.0188, -0.0043, -0.0332,\n",
       "           -0.0104,  0.0042,  0.0302, -0.0465, -0.0023, -0.0376, -0.0182,  0.0269,\n",
       "            0.0318, -0.0249, -0.0407,  0.0185,  0.0138, -0.0332,  0.0230,  0.0222,\n",
       "           -0.0258, -0.0257, -0.0331,  0.0445,  0.0310, -0.0225, -0.0058, -0.0078,\n",
       "           -0.0364,  0.0116, -0.0137,  0.0306,  0.0134, -0.0087,  0.0085,  0.0146,\n",
       "            0.0016,  0.0180, -0.0129, -0.0024, -0.1035, -0.0128, -0.0183, -0.0109,\n",
       "            0.0045, -0.0356, -0.0476,  0.0276,  0.0166,  0.0177,  0.0030,  0.0198,\n",
       "           -0.0109, -0.0219,  0.0053,  0.0316,  0.0235,  0.0179, -0.0145,  0.0056,\n",
       "           -0.0096, -0.0224,  0.0192,  0.0076, -0.0129,  0.0163, -0.0113, -0.0025,\n",
       "           -0.0114,  0.0020,  0.0143,  0.0126, -0.0041, -0.0135,  0.0109,  0.0282,\n",
       "            0.0297,  0.0246,  0.0100, -0.0212, -0.0350, -0.0074,  0.0009, -0.0444,\n",
       "            0.0049, -0.0382, -0.0050, -0.0177,  0.0172,  0.0162,  0.0165, -0.0182,\n",
       "            0.0052,  0.0218,  0.0132,  0.0299,  0.0609, -0.0343,  0.0271, -0.0443,\n",
       "            0.0203, -0.0248,  0.0063, -0.0091, -0.0061, -0.0062,  0.0297,  0.0197,\n",
       "           -0.0260,  0.0184,  0.0941,  0.0008, -0.0095,  0.0335,  0.0263, -0.0140,\n",
       "            0.0125, -0.0300, -0.0114, -0.0009,  0.0205,  0.0243, -0.1554, -0.0070,\n",
       "           -0.0224,  0.0179,  0.0164, -0.0045,  0.0040, -0.0196, -0.0027, -0.0036,\n",
       "            0.0192,  0.0263,  0.0507,  0.0095, -0.0124, -0.0044,  0.0391, -0.0123,\n",
       "           -0.0304,  0.0478, -0.0191, -0.0097,  0.0179, -0.0184,  0.0497,  0.0215,\n",
       "           -0.0116,  0.0176,  0.0511,  0.0217, -0.0242,  0.0057,  0.0101, -0.0169],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.1300,  0.1232,  0.1258,  ...,  0.5885, -0.3221, -0.5832],\n",
       "           [ 0.1323,  0.1546,  0.1265,  ...,  0.5432, -0.2853, -0.5446],\n",
       "           [ 0.0997,  0.1126,  0.1223,  ...,  0.5662, -0.2835, -0.5765],\n",
       "           ...,\n",
       "           [ 0.1771,  0.2381, -0.0373,  ...,  0.2266, -0.0545,  0.1039],\n",
       "           [ 0.3849,  0.2473, -0.1130,  ...,  0.5477, -0.0268, -0.4056],\n",
       "           [ 0.1132,  0.2903,  0.3165,  ...,  0.2827, -0.5250, -0.6312]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-3.1386, -3.1510, -3.1393,  ..., -0.0873, -0.1018, -0.4111],\n",
       "          device='cuda:0', requires_grad=True)],\n",
       "  'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0,\n",
       "  'amsgrad': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'capturable': False,\n",
       "  'differentiable': False,\n",
       "  'fused': False}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer1 2 раза сократился lr до 0.000125, при продолжении обучения выставить его таким"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:33:14.293726Z",
     "iopub.status.busy": "2023-03-28T13:33:14.292801Z",
     "iopub.status.idle": "2023-03-28T14:31:51.718120Z",
     "shell.execute_reply": "2023-03-28T14:31:51.716245Z",
     "shell.execute_reply.started": "2023-03-28T13:33:14.293684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m     24\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 26\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLIP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_history\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_data_loader, criterion)\n\u001b[0;32m     29\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[71], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, clip, train_history, valid_history)\u001b[0m\n\u001b[0;32m     16\u001b[0m src, src_len, trg, trg_len \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 20\u001b[0m output, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#output = [batch size, trg len - 1, output dim]\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#trg = [batch size, trg len]\u001b[39;00m\n\u001b[0;32m     25\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mD:\\Dev\\jupyter\\projects\\Data Science\\ds_stuff\\Different courses\\Нейронные сети и обработка текста\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[55], line 57\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[1;34m(self, src, trg)\u001b[0m\n\u001b[0;32m     52\u001b[0m trg_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_trg_mask(trg)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#src_mask = [batch size, 1, 1, src len]\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#trg_mask = [batch size, 1, trg len, trg len]\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m enc_src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m#enc_src = [batch size, src len, hid dim]\u001b[39;00m\n\u001b[0;32m     61\u001b[0m output, attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(trg, enc_src, trg_mask, src_mask)\n",
      "File \u001b[1;32mD:\\Dev\\jupyter\\projects\\Data Science\\ds_stuff\\Different courses\\Нейронные сети и обработка текста\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[49], line 51\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, src, src_mask)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#src = [batch size, src len, hid dim]\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 51\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#src = [batch size, src len, hid dim]\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m src\n",
      "File \u001b[1;32mD:\\Dev\\jupyter\\projects\\Data Science\\ds_stuff\\Different courses\\Нейронные сети и обработка текста\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[50], line 24\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[1;34m(self, src, src_mask)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, src_mask):\n\u001b[0;32m     19\u001b[0m     \n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m#src = [batch size, src len, hid dim]\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m#src_mask = [batch size, 1, 1, src len] \u001b[39;00m\n\u001b[0;32m     22\u001b[0m             \n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#self attention\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     _src, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#dropout, residual connection and layer norm\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn_layer_norm(src \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(_src))\n",
      "File \u001b[1;32mD:\\Dev\\jupyter\\projects\\Data Science\\ds_stuff\\Different courses\\Нейронные сети и обработка текста\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[51], line 30\u001b[0m, in \u001b[0;36mMultiHeadAttentionLayer.forward\u001b[1;34m(self, query, key, value, mask)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#query = [batch size, query len, hid dim]\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#key = [batch size, key len, hid dim]\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#value = [batch size, value len, hid dim]\u001b[39;00m\n\u001b[0;32m     29\u001b[0m Q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_q(query)\n\u001b[1;32m---> 30\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_v(value)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#Q = [batch size, query len, hid dim]\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#K = [batch size, key len, hid dim]\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#V = [batch size, value len, hid dim]\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Dev\\jupyter\\projects\\Data Science\\ds_stuff\\Different courses\\Нейронные сети и обработка текста\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Dev\\jupyter\\projects\\Data Science\\ds_stuff\\Different courses\\Нейронные сети и обработка текста\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(MODEL_NAME, map_location=torch.device('cuda')))\n",
    "# model.load_state_dict(torch.load(f'{MODELS_PATH}/transformer_yttm_100_more_cleaning.pt', map_location=torch.device('cuda')))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "N_EPOCHS = 100\n",
    "CLIP = 1\n",
    "\n",
    "train_data_loader = BatchSizeDataloader(\n",
    "    arx_dataset_train, batch_size=16, device=device, batch_first=True, pad_value=PAD_IDX)\n",
    "\n",
    "val_data_loader = BatchSizeDataloader(\n",
    "    arx_dataset_val, batch_size=16, device=device, batch_first=True, pad_value=PAD_IDX)\n",
    "\n",
    "# test_data_loader = BatchSizeDataloader(\n",
    "#     arx_dataset_test, batch_size=32, device=device, batch_first=True, pad_value=PAD_IDX)\n",
    "\n",
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_data_loader, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, val_data_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), MODEL_NAME)\n",
    "        \n",
    "    if lr_sched is not None:\n",
    "        lr_sched.step(valid_loss)\n",
    "        \n",
    "        \n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del test_data_loader\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:31:58.292783Z",
     "iopub.status.busy": "2023-03-28T14:31:58.292401Z",
     "iopub.status.idle": "2023-03-28T14:31:58.302335Z",
     "shell.execute_reply": "2023-03-28T14:31:58.301055Z",
     "shell.execute_reply.started": "2023-03-28T14:31:58.292748Z"
    }
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:32:03.691360Z",
     "iopub.status.busy": "2023-03-28T14:32:03.690417Z",
     "iopub.status.idle": "2023-03-28T14:32:04.904842Z",
     "shell.execute_reply": "2023-03-28T14:32:04.903604Z",
     "shell.execute_reply.started": "2023-03-28T14:32:03.691288Z"
    }
   },
   "outputs": [],
   "source": [
    "# for cpu usage\n",
    "model.load_state_dict(torch.load(MODEL_NAME, map_location=torch.device('cuda')))\n",
    "\n",
    "test_data_loader = BatchSizeDataloader(\n",
    "    arx_dataset_test, batch_size=32, device=device, batch_first=True, pad_value=PAD_IDX)\n",
    "test_loss = evaluate(model, test_data_loader, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:32:09.299132Z",
     "iopub.status.busy": "2023-03-28T14:32:09.298757Z",
     "iopub.status.idle": "2023-03-28T14:32:09.304183Z",
     "shell.execute_reply": "2023-03-28T14:32:09.302413Z",
     "shell.execute_reply.started": "2023-03-28T14:32:09.299098Z"
    }
   },
   "outputs": [],
   "source": [
    "# id2word = {value: key for key, value in vocabulary.items()}\n",
    "# id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:32:09.608219Z",
     "iopub.status.busy": "2023-03-28T14:32:09.607331Z",
     "iopub.status.idle": "2023-03-28T14:32:09.614556Z",
     "shell.execute_reply": "2023-03-28T14:32:09.613355Z",
     "shell.execute_reply.started": "2023-03-28T14:32:09.608181Z"
    }
   },
   "outputs": [],
   "source": [
    "# def translate_sentence(sentence, word2id, id2word, model, device, max_len = 50):\n",
    "    \n",
    "#     model.eval()\n",
    "#     src_tensor = torch.LongTensor(sentence).unsqueeze(0).to(device)\n",
    "    \n",
    "#     src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "#     trg_indexes = [word2id['<SOS>']]\n",
    "\n",
    "#     for i in range(max_len):\n",
    "\n",
    "#         trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "#         trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "\n",
    "#         pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "#         trg_indexes.append(pred_token)\n",
    "\n",
    "#         if pred_token == word2id['<EOS>']:\n",
    "#             break\n",
    "    \n",
    "#     trg_tokens = [id2word[i] for i in trg_indexes]\n",
    "    \n",
    "#     return trg_tokens[1:], attention\n",
    "\n",
    "# def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
    "    \n",
    "#     assert n_rows * n_cols == n_heads\n",
    "    \n",
    "#     fig = plt.figure(figsize=(15,25))\n",
    "    \n",
    "#     for i in range(n_heads):\n",
    "        \n",
    "#         ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        \n",
    "#         _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
    "\n",
    "#         cax = ax.matshow(_attention, cmap='bone')\n",
    "\n",
    "#         ax.tick_params(labelsize=12)\n",
    "#         ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "#                            rotation=90)\n",
    "#         ax.set_yticklabels(['']+translation)\n",
    "\n",
    "#         ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "#         ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "#     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:32:10.271682Z",
     "iopub.status.busy": "2023-03-28T14:32:10.270869Z",
     "iopub.status.idle": "2023-03-28T14:32:10.286275Z",
     "shell.execute_reply": "2023-03-28T14:32:10.284886Z",
     "shell.execute_reply.started": "2023-03-28T14:32:10.271642Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, tokenizer, model, device, max_len = 50):\n",
    "    \n",
    "    model.eval()\n",
    "    src_tensor = torch.LongTensor(sentence).unsqueeze(0).to(device)\n",
    "    \n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    trg_indexes = [tokenizer.subword_to_id('<BOS>')]\n",
    "\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "\n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == tokenizer.subword_to_id('<EOS>'):\n",
    "            break\n",
    "    \n",
    "    trg_tokens = tokenizer.decode(trg_indexes)\n",
    "\n",
    "    return trg_tokens, attention\n",
    "\n",
    "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
    "    \n",
    "    assert n_rows * n_cols == n_heads\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,25))\n",
    "    \n",
    "    for i in range(n_heads):\n",
    "        \n",
    "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        \n",
    "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
    "\n",
    "        cax = ax.matshow(_attention, cmap='bone')\n",
    "\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                           rotation=90)\n",
    "        ax.set_yticklabels(['']+translation)\n",
    "\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:32:11.528618Z",
     "iopub.status.busy": "2023-03-28T14:32:11.527843Z",
     "iopub.status.idle": "2023-03-28T14:32:11.535307Z",
     "shell.execute_reply": "2023-03-28T14:32:11.534048Z",
     "shell.execute_reply.started": "2023-03-28T14:32:11.528576Z"
    }
   },
   "outputs": [],
   "source": [
    "example_idx = 100000\n",
    "\n",
    "src, trg = arx_dataset_train[example_idx]\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:32:12.673348Z",
     "iopub.status.busy": "2023-03-28T14:32:12.672966Z",
     "iopub.status.idle": "2023-03-28T14:32:12.731537Z",
     "shell.execute_reply": "2023-03-28T14:32:12.730454Z",
     "shell.execute_reply.started": "2023-03-28T14:32:12.673304Z"
    }
   },
   "outputs": [],
   "source": [
    "translation, attention = translate_sentence(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    sentence=src,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(f'predicted trg = {translation}')\n",
    "print(f'true trg = {tokenizer.decode(trg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:32:19.488452Z",
     "iopub.status.busy": "2023-03-28T14:32:19.487688Z",
     "iopub.status.idle": "2023-03-28T14:32:19.493636Z",
     "shell.execute_reply": "2023-03-28T14:32:19.492448Z",
     "shell.execute_reply.started": "2023-03-28T14:32:19.488397Z"
    }
   },
   "outputs": [],
   "source": [
    "# translation, attention = translate_sentence(\n",
    "#     model=model,\n",
    "#     sentence=src,\n",
    "#     device=device,\n",
    "#     word2id=vocabulary,\n",
    "#     id2word=id2word\n",
    "# )\n",
    "\n",
    "# print(f'predicted trg = {translation}')\n",
    "# print(f'true trg = {[id2word[word] for word in trg]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:32:20.004545Z",
     "iopub.status.busy": "2023-03-28T14:32:20.004031Z",
     "iopub.status.idle": "2023-03-28T14:32:20.012487Z",
     "shell.execute_reply": "2023-03-28T14:32:20.011316Z",
     "shell.execute_reply.started": "2023-03-28T14:32:20.004494Z"
    }
   },
   "outputs": [],
   "source": [
    "# display_attention([id2word[word] for word in src], translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:32:20.266086Z",
     "iopub.status.busy": "2023-03-28T14:32:20.265705Z",
     "iopub.status.idle": "2023-03-28T14:32:20.271715Z",
     "shell.execute_reply": "2023-03-28T14:32:20.270507Z",
     "shell.execute_reply.started": "2023-03-28T14:32:20.266050Z"
    }
   },
   "outputs": [],
   "source": [
    "# for example_idx in range(100):\n",
    "#     src, trg = arx_dataset_test[example_idx]\n",
    "# #     src = [id2word[word] for word in src]\n",
    "#     trg = [id2word[word] for word in trg]\n",
    "#     translation, attention = translate_sentence(\n",
    "#         model=model,\n",
    "#         sentence=src,\n",
    "#         device=device,\n",
    "#         word2id=vocabulary,\n",
    "#         id2word=id2word)\n",
    "\n",
    "#     print('Оригинальный заголовок: ', ' '.join(trg))\n",
    "#     print('Предсказанный заголовок: ', ' '.join(translation))\n",
    "#     print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:32:21.237872Z",
     "iopub.status.busy": "2023-03-28T14:32:21.237106Z",
     "iopub.status.idle": "2023-03-28T14:32:25.983174Z",
     "shell.execute_reply": "2023-03-28T14:32:25.981978Z",
     "shell.execute_reply.started": "2023-03-28T14:32:21.237816Z"
    }
   },
   "outputs": [],
   "source": [
    "for example_idx in range(100):\n",
    "    src, trg = arx_dataset_test[example_idx]\n",
    "#     src = [id2word[word] for word in src]\n",
    "    trg = tokenizer.decode(trg)\n",
    "    translation, attention = translate_sentence(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        sentence=src,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    print('Оригинальный заголовок: ', ' '.join(trg))\n",
    "    print('Предсказанный заголовок: ', ' '.join(translation))\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:01.867873Z",
     "iopub.status.busy": "2023-03-28T14:33:01.867505Z",
     "iopub.status.idle": "2023-03-28T14:33:01.875730Z",
     "shell.execute_reply": "2023-03-28T14:33:01.874521Z",
     "shell.execute_reply.started": "2023-03-28T14:33:01.867838Z"
    }
   },
   "outputs": [],
   "source": [
    "# class BeamGenerator:\n",
    "#     def __init__(self, model, word2id, id2word, device, eos_token_id):\n",
    "#         self.model = model\n",
    "#         self.word2id = word2id\n",
    "#         self.id2word = id2word\n",
    "#         self.device = device\n",
    "#         self.model.to(self.device)\n",
    "#         self.eos_token_id = eos_token_id\n",
    "\n",
    "#     def __call__(self, sentence, max_steps_n=40, return_hypotheses_n=5, beamsize=5):\n",
    "#         self.model.eval()\n",
    "#         src_tensor = torch.LongTensor(sentence).unsqueeze(0).to(device)\n",
    "\n",
    "#         src_mask = self.model.make_src_mask(src_tensor)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             enc_src = self.model.encoder(src_tensor, src_mask)\n",
    "        \n",
    "#         initial_length = 1\n",
    "\n",
    "#         partial_hypotheses = [(0, [self.word2id['<SOS>']])]\n",
    "#         final_hypotheses = []\n",
    "\n",
    "#         while len(partial_hypotheses) > 0:\n",
    "#             cur_partial_score, cur_partial_hypothesis = heapq.heappop(partial_hypotheses)\n",
    "            \n",
    "#             trg_tensor = torch.LongTensor(cur_partial_hypothesis).unsqueeze(0).to(device)\n",
    "#             trg_mask = self.model.make_trg_mask(trg_tensor)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 output, attention = self.model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "\n",
    "#             next_tokens_logproba = F.log_softmax(output, dim=2)\n",
    "#             topk_continuations = next_tokens_logproba[0, -1].topk(beamsize)\n",
    "\n",
    "#             for token_score, token_idx in zip(topk_continuations.values, topk_continuations.indices):\n",
    "#                 token_score = float(token_score)\n",
    "#                 token_idx = int(token_idx)\n",
    "\n",
    "#                 old_denorm_score = cur_partial_score * np.sqrt(len(cur_partial_hypothesis))\n",
    "#                 new_score = (old_denorm_score - token_score) / np.sqrt(len(cur_partial_hypothesis) + 1)\n",
    "\n",
    "#                 new_hypothesis = cur_partial_hypothesis + [token_idx]\n",
    "#                 new_item = (new_score, new_hypothesis)\n",
    "\n",
    "#                 if token_idx == self.eos_token_id or len(new_hypothesis) - initial_length >= max_steps_n:\n",
    "#                     final_hypotheses.append(new_item)\n",
    "#                 else:\n",
    "#                     heapq.heappush(partial_hypotheses, new_item)\n",
    "\n",
    "#             if len(partial_hypotheses) > beamsize:\n",
    "#                 partial_hypotheses = heapq.nsmallest(beamsize, partial_hypotheses)\n",
    "#                 heapq.heapify(partial_hypotheses)\n",
    "\n",
    "#         final_scores, final_token_lists = zip(*final_hypotheses)\n",
    "#         final_texts = [[self.id2word[id_] for id_ in variant] for variant in (list(final_token_lists))]\n",
    "\n",
    "#         result = list(zip(final_scores, final_texts))\n",
    "#         result.sort()\n",
    "#         result = result[:return_hypotheses_n]\n",
    "\n",
    "#         return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:02.389141Z",
     "iopub.status.busy": "2023-03-28T14:33:02.388778Z",
     "iopub.status.idle": "2023-03-28T14:33:02.393948Z",
     "shell.execute_reply": "2023-03-28T14:33:02.392762Z",
     "shell.execute_reply.started": "2023-03-28T14:33:02.389109Z"
    }
   },
   "outputs": [],
   "source": [
    "# beam_generator = BeamGenerator(model, vocabulary, id2word, device, EOS_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:02.726978Z",
     "iopub.status.busy": "2023-03-28T14:33:02.726245Z",
     "iopub.status.idle": "2023-03-28T14:33:02.731727Z",
     "shell.execute_reply": "2023-03-28T14:33:02.730468Z",
     "shell.execute_reply.started": "2023-03-28T14:33:02.726938Z"
    }
   },
   "outputs": [],
   "source": [
    "# example_idx = 10000\n",
    "\n",
    "# src, trg = arx_dataset_train[example_idx]\n",
    "\n",
    "# print(f'src = {src}')\n",
    "# print(f'trg = {[id2word[id_] for id_ in trg]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:03.491187Z",
     "iopub.status.busy": "2023-03-28T14:33:03.490818Z",
     "iopub.status.idle": "2023-03-28T14:33:03.496444Z",
     "shell.execute_reply": "2023-03-28T14:33:03.495208Z",
     "shell.execute_reply.started": "2023-03-28T14:33:03.491153Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# beam_gen_variants = beam_generator(src,\n",
    "#                                    beamsize=10,\n",
    "#                                    return_hypotheses_n=5)\n",
    "\n",
    "# for score, pred_txt in beam_gen_variants:\n",
    "#     print('****')\n",
    "#     print(score)\n",
    "#     print(pred_txt)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:03.969793Z",
     "iopub.status.busy": "2023-03-28T14:33:03.969221Z",
     "iopub.status.idle": "2023-03-28T14:33:03.979983Z",
     "shell.execute_reply": "2023-03-28T14:33:03.979007Z",
     "shell.execute_reply.started": "2023-03-28T14:33:03.969749Z"
    }
   },
   "outputs": [],
   "source": [
    "# for example_idx in range(100):\n",
    "#     src, trg = arx_dataset_test[example_idx]\n",
    "#     trg = [id2word[word] for word in trg]\n",
    "#     beam_gen_variants = beam_generator(src,\n",
    "#                                        beamsize=20,\n",
    "#                                        return_hypotheses_n=5)\n",
    "\n",
    "#     print('Оригинальный заголовок: ', ' '.join(trg))\n",
    "#     print('Предсказанный заголовок: ', ' '.join(beam_gen_variants[-1][-1]))\n",
    "#     print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:04.597346Z",
     "iopub.status.busy": "2023-03-28T14:33:04.596960Z",
     "iopub.status.idle": "2023-03-28T14:33:04.610244Z",
     "shell.execute_reply": "2023-03-28T14:33:04.609164Z",
     "shell.execute_reply.started": "2023-03-28T14:33:04.597287Z"
    }
   },
   "outputs": [],
   "source": [
    "class BeamGenerator:\n",
    "    def __init__(self, model, tokenizer, device, eos_token_id):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.eos_token_id = eos_token_id\n",
    "\n",
    "    def __call__(self, sentence, max_steps_n=40, return_hypotheses_n=5, beamsize=5):\n",
    "        sentence = self.tokenizer.encode(sentence)\n",
    "        self.model.eval()\n",
    "        src_tensor = torch.LongTensor(sentence).unsqueeze(0).to(device)\n",
    "\n",
    "        src_mask = self.model.make_src_mask(src_tensor)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            enc_src = self.model.encoder(src_tensor, src_mask)\n",
    "        \n",
    "        initial_length = 1\n",
    "\n",
    "        partial_hypotheses = [(0, [self.tokenizer.subword_to_id('<BOS>')])]\n",
    "        final_hypotheses = []\n",
    "\n",
    "        while len(partial_hypotheses) > 0:\n",
    "            cur_partial_score, cur_partial_hypothesis = heapq.heappop(partial_hypotheses)\n",
    "            \n",
    "            trg_tensor = torch.LongTensor(cur_partial_hypothesis).unsqueeze(0).to(device)\n",
    "            trg_mask = self.model.make_trg_mask(trg_tensor)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output, attention = self.model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "\n",
    "            next_tokens_logproba = F.log_softmax(output, dim=2)\n",
    "            topk_continuations = next_tokens_logproba[0, -1].topk(beamsize)\n",
    "\n",
    "            for token_score, token_idx in zip(topk_continuations.values, topk_continuations.indices):\n",
    "                token_score = float(token_score)\n",
    "                token_idx = int(token_idx)\n",
    "\n",
    "                old_denorm_score = cur_partial_score * np.sqrt(len(cur_partial_hypothesis))\n",
    "                new_score = (old_denorm_score - token_score) / np.sqrt(len(cur_partial_hypothesis) + 1)\n",
    "\n",
    "                new_hypothesis = cur_partial_hypothesis + [token_idx]\n",
    "                new_item = (new_score, new_hypothesis)\n",
    "\n",
    "                if token_idx == self.eos_token_id or len(new_hypothesis) - initial_length >= max_steps_n:\n",
    "                    final_hypotheses.append(new_item)\n",
    "                else:\n",
    "                    heapq.heappush(partial_hypotheses, new_item)\n",
    "\n",
    "            if len(partial_hypotheses) > beamsize:\n",
    "                partial_hypotheses = heapq.nsmallest(beamsize, partial_hypotheses)\n",
    "                heapq.heapify(partial_hypotheses)\n",
    "\n",
    "        final_scores, final_token_lists = zip(*final_hypotheses)\n",
    "        final_texts = self.tokenizer.decode(list(final_token_lists))\n",
    "\n",
    "        result = list(zip(final_scores, final_texts))\n",
    "        result.sort()\n",
    "        result = result[:return_hypotheses_n]\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:05.319945Z",
     "iopub.status.busy": "2023-03-28T14:33:05.319583Z",
     "iopub.status.idle": "2023-03-28T14:33:05.335353Z",
     "shell.execute_reply": "2023-03-28T14:33:05.334288Z",
     "shell.execute_reply.started": "2023-03-28T14:33:05.319912Z"
    }
   },
   "outputs": [],
   "source": [
    "beam_generator = BeamGenerator(model, tokenizer, device, EOS_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:06.427753Z",
     "iopub.status.busy": "2023-03-28T14:33:06.426948Z",
     "iopub.status.idle": "2023-03-28T14:33:06.433877Z",
     "shell.execute_reply": "2023-03-28T14:33:06.432769Z",
     "shell.execute_reply.started": "2023-03-28T14:33:06.427714Z"
    }
   },
   "outputs": [],
   "source": [
    "example_idx = 0\n",
    "\n",
    "src, trg = arx_dataset_test[example_idx]\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {tokenizer.decode(trg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:10.138872Z",
     "iopub.status.busy": "2023-03-28T14:33:10.138503Z",
     "iopub.status.idle": "2023-03-28T14:33:34.592906Z",
     "shell.execute_reply": "2023-03-28T14:33:34.591690Z",
     "shell.execute_reply.started": "2023-03-28T14:33:10.138837Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "beam_gen_variants = beam_generator(tokenizer.decode(src)[0],\n",
    "                                   beamsize=100,\n",
    "                                   return_hypotheses_n=5)\n",
    "\n",
    "for score, pred_txt in beam_gen_variants:\n",
    "    print('****')\n",
    "    print(score)\n",
    "    print(pred_txt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T14:51:17.526843Z",
     "iopub.status.busy": "2023-03-25T14:51:17.526227Z",
     "iopub.status.idle": "2023-03-25T14:51:17.535542Z",
     "shell.execute_reply": "2023-03-25T14:51:17.533691Z",
     "shell.execute_reply.started": "2023-03-25T14:51:17.526774Z"
    }
   },
   "source": [
    "# Считаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:48.714504Z",
     "iopub.status.busy": "2023-03-28T14:33:48.713679Z",
     "iopub.status.idle": "2023-03-28T14:33:48.721130Z",
     "shell.execute_reply": "2023-03-28T14:33:48.719804Z",
     "shell.execute_reply.started": "2023-03-28T14:33:48.714463Z"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "\n",
    "# n_gram_weights = [0.3334, 0.3333, 0.3333]\n",
    "# test_len = len(arx_dataset_test)\n",
    "\n",
    "# original_texts = []\n",
    "# generated_texts = []\n",
    "# macro_bleu = 0\n",
    "\n",
    "# for example_idx in range(test_len):\n",
    "#     src, trg = arx_dataset_test[example_idx]\n",
    "\n",
    "#     trg = [id2word[word] for word in trg]\n",
    "#     translation, _ = translate_sentence(\n",
    "#         model=model,\n",
    "#         sentence=src,\n",
    "#         device=device,\n",
    "#         word2id=vocabulary,\n",
    "#         id2word=id2word)\n",
    "\n",
    "#     original_texts.append(trg)\n",
    "#     generated_texts.append(translation)\n",
    "\n",
    "#     bleu_score = nltk.translate.bleu_score.sentence_bleu(\n",
    "#         [trg[1:]],\n",
    "#         translation,\n",
    "#         weights = n_gram_weights\n",
    "#     )    \n",
    "#     macro_bleu += bleu_score\n",
    "\n",
    "# macro_bleu /= test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:33:53.821276Z",
     "iopub.status.busy": "2023-03-28T14:33:53.820366Z",
     "iopub.status.idle": "2023-03-28T14:34:41.523385Z",
     "shell.execute_reply": "2023-03-28T14:34:41.522306Z",
     "shell.execute_reply.started": "2023-03-28T14:33:53.821237Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "n_gram_weights = [0.3334, 0.3333, 0.3333]\n",
    "test_len = len(arx_dataset_test)\n",
    "\n",
    "original_texts = []\n",
    "generated_texts = []\n",
    "macro_bleu = 0\n",
    "\n",
    "for example_idx in range(test_len):\n",
    "    src, trg = arx_dataset_test[example_idx]\n",
    "\n",
    "    trg = tokenizer.decode(trg)[0]\n",
    "    trg = trg.replace('<BOS> ', '').replace('<EOS>', '').split(' ')\n",
    "    translation, _ = translate_sentence(\n",
    "        model=model,\n",
    "        sentence=src,\n",
    "        device=device,\n",
    "        tokenizer=tokenizer)\n",
    "    \n",
    "    translation = translation[0].replace('<BOS> ', '').replace('<EOS>', '').split(' ')\n",
    "\n",
    "    original_texts.append(trg)\n",
    "    generated_texts.append(translation)\n",
    "    print(trg, translation)\n",
    "\n",
    "    bleu_score = nltk.translate.bleu_score.sentence_bleu(\n",
    "        trg,\n",
    "        translation,\n",
    "        weights = n_gram_weights\n",
    "    )    \n",
    "    macro_bleu += bleu_score\n",
    "\n",
    "macro_bleu /= test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:34:41.525515Z",
     "iopub.status.busy": "2023-03-28T14:34:41.525121Z",
     "iopub.status.idle": "2023-03-28T14:34:41.533475Z",
     "shell.execute_reply": "2023-03-28T14:34:41.532343Z",
     "shell.execute_reply.started": "2023-03-28T14:34:41.525471Z"
    }
   },
   "outputs": [],
   "source": [
    "# averaging sentence-level BLEU (i.e. macro-average precision)\n",
    "print('Macro-average BLEU: {0:.5f}'.format(macro_bleu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:34:47.099658Z",
     "iopub.status.busy": "2023-03-28T14:34:47.099254Z",
     "iopub.status.idle": "2023-03-28T14:34:47.148532Z",
     "shell.execute_reply": "2023-03-28T14:34:47.147408Z",
     "shell.execute_reply.started": "2023-03-28T14:34:47.099623Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_data = pd.read_csv(f'{DATA_PATH}/test.csv')\n",
    "abstracts = submission_data['abstract'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:34:48.878573Z",
     "iopub.status.busy": "2023-03-28T14:34:48.877826Z",
     "iopub.status.idle": "2023-03-28T14:34:48.967198Z",
     "shell.execute_reply": "2023-03-28T14:34:48.965869Z",
     "shell.execute_reply.started": "2023-03-28T14:34:48.878533Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# tokenized_abstracts = [tokenize(sentence) for sentence in abstracts]\n",
    "tokenized_abstracts = tokenizer.encode(abstracts.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:34:51.463910Z",
     "iopub.status.busy": "2023-03-28T14:34:51.463065Z",
     "iopub.status.idle": "2023-03-28T14:35:35.947037Z",
     "shell.execute_reply": "2023-03-28T14:35:35.945944Z",
     "shell.execute_reply.started": "2023-03-28T14:34:51.463870Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# titles = []\n",
    "# for abstract in tokenized_abstracts:\n",
    "#     title, _ = translate_sentence(\n",
    "#         model=model,\n",
    "#         sentence=abstract,\n",
    "#         device=device,\n",
    "#         word2id=vocabulary,\n",
    "#         id2word=id2word)\n",
    "#     titles.append(' '.join(title).replace('<UNK>', ''))\n",
    "\n",
    "# titles = []\n",
    "# for abstract in tokenized_abstracts:\n",
    "#     abstract = [tokenizer.subword_to_id('<BOS>')] + abstract + [tokenizer.subword_to_id('<EOS>')]\n",
    "#     title, _ = translate_sentence(\n",
    "#         model=model,\n",
    "#         sentence=abstract,\n",
    "#         device=device,\n",
    "#         tokenizer=tokenizer)\n",
    "#     titles.append(' '.join(title).replace('<BOS> ', '').replace('<EOS>', '').replace('<UNK>', ''))\n",
    "    \n",
    "titles = []\n",
    "for abstract in tqdm(tokenized_abstracts):\n",
    "    abstract = [tokenizer.subword_to_id('<BOS>')] + abstract + [tokenizer.subword_to_id('<EOS>')]\n",
    "    variants = beam_generator(tokenizer.decode(abstract)[0],\n",
    "                                   beamsize=10,\n",
    "                                   return_hypotheses_n=1)\n",
    "    titles.append(' '.join([variants[0][1]]).replace('<BOS> ', '').replace('<EOS>', '').replace('<UNK>', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:35:35.949277Z",
     "iopub.status.busy": "2023-03-28T14:35:35.948916Z",
     "iopub.status.idle": "2023-03-28T14:35:35.957023Z",
     "shell.execute_reply": "2023-03-28T14:35:35.955833Z",
     "shell.execute_reply.started": "2023-03-28T14:35:35.949246Z"
    }
   },
   "outputs": [],
   "source": [
    "titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:35:40.930894Z",
     "iopub.status.busy": "2023-03-28T14:35:40.930190Z",
     "iopub.status.idle": "2023-03-28T14:35:40.959325Z",
     "shell.execute_reply": "2023-03-28T14:35:40.958339Z",
     "shell.execute_reply.started": "2023-03-28T14:35:40.930856Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'abstract': abstracts, 'title': titles})\n",
    "submission_df.to_csv('predicted_titles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:35:42.562489Z",
     "iopub.status.busy": "2023-03-28T14:35:42.561510Z",
     "iopub.status.idle": "2023-03-28T14:35:43.484135Z",
     "shell.execute_reply": "2023-03-28T14:35:43.483079Z",
     "shell.execute_reply.started": "2023-03-28T14:35:42.562447Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "def generate_csv(input_file='predicted_titles.csv',\n",
    "                 output_file='submission.csv',\n",
    "                 voc_file=f'{DATA_PATH}/vocs.pkl'):\n",
    "    '''\n",
    "    Generates file in format required for submitting result to Kaggle\n",
    "    \n",
    "    Parameters:\n",
    "        input_file (str) : path to csv file with your predicted titles.\n",
    "                           Should have two fields: abstract and title\n",
    "        output_file (str) : path to output submission file\n",
    "        voc_file (str) : path to voc.pkl file\n",
    "    '''\n",
    "    data = pd.read_csv(input_file).fillna(' ')\n",
    "    with open(voc_file, 'rb') as voc_file:\n",
    "        vocs = pickle.load(voc_file)\n",
    "\n",
    "    with open(output_file, 'w') as res_file:\n",
    "        res_file.write('Id,Predict\\n')\n",
    "        \n",
    "    output_idx = 0\n",
    "    for row_idx, row in data.iterrows():\n",
    "        trg = row['title']\n",
    "        trg = trg.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "        if len(trg) > 1:\n",
    "            trg.extend(['_'.join(ngram) for ngram in list(ngrams(trg, 2)) + list(ngrams(trg, 3))])\n",
    "        \n",
    "        VOCAB_stoi = vocs[row_idx]\n",
    "        trg_intersection = set(VOCAB_stoi.keys()).intersection(set(trg))\n",
    "        trg_vec = np.zeros(len(VOCAB_stoi))    \n",
    "\n",
    "        for word in trg_intersection:\n",
    "            trg_vec[VOCAB_stoi[word]] = 1\n",
    "\n",
    "        with open(output_file, 'a') as res_file:\n",
    "            for is_word in trg_vec:\n",
    "                res_file.write('{0},{1}\\n'.format(output_idx, int(is_word)))\n",
    "                output_idx += 1\n",
    "\n",
    "\n",
    "generate_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:35:43.486778Z",
     "iopub.status.busy": "2023-03-28T14:35:43.486072Z",
     "iopub.status.idle": "2023-03-28T14:35:43.543366Z",
     "shell.execute_reply": "2023-03-28T14:35:43.542286Z",
     "shell.execute_reply.started": "2023-03-28T14:35:43.486725Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(f'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T14:35:46.435381Z",
     "iopub.status.busy": "2023-03-28T14:35:46.434992Z",
     "iopub.status.idle": "2023-03-28T14:35:46.469474Z",
     "shell.execute_reply": "2023-03-28T14:35:46.468481Z",
     "shell.execute_reply.started": "2023-03-28T14:35:46.435343Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(f'predicted_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(f'{DATA_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung_nlp",
   "language": "python",
   "name": "samsung_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
